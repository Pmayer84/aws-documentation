{
  "url": "https://docs.aws.amazon.com/AmazonECR/latest/userguide/what-is-ecr.html",
  "pageType": "UserGuidePage",
  "title": "What is Amazon Elastic Container Registry? - Amazon ECR AWSDocumentationAmazon E\nCRUser Guide Features of Amazon ECRHow to get started with Amazon ECRPricing for\n Amazon ECR What is Amazon Elastic Container Registry? Amazon Elastic Container \nRegistry (Amazon ECR) is an AWS managed container image registry service that is\n secure, scalable, and reliable. Amazon ECR supports private repositories with r\nesource-based permissions using AWS IAM. This is so that specified users or Amaz\non EC2 instances can access your container repositories and images. You can use \nyour preferred CLI to push, pull, and manage Docker images, Open Container Initi\native (OCI) images, and OCI compatible artifacts. Note Amazon ECR supports publi\nc container image repositories as well. For more information, see What is Amazon\n ECR Public in the Amazon ECR Public User Guide. The AWS container services team\n maintains a public roadmap on GitHub. It contains information about what the te\nams are working on and allows all AWS customers the ability to give direct feedb\nack. For more information, see AWS Containers Roadmap. Features of Amazon ECR Am\nazon ECR provides the following features: Lifecycle policies help with managing \nthe lifecycle of the images in your repositories. You define rules that result i\nn the cleaning up of unused images. You can test rules before applying them to y\nour repository. For more information, see Automate the cleanup of images by usin\ng lifecycle policies in Amazon ECR. Image scanning helps in identifying software\n vulnerabilities in your container images. Each repository can be configured to \nscan on push. This ensures that each new image pushed to the repository is scann\ned. You can then retrieve the results of the image scan. For more information, s\nee Scan images for software vulnerabilities in Amazon ECR. Cross-Region and cros\ns-account replication makes it easier for you to have your images where you need\n them. This is configured as a registry setting and is on a per-Region basis. Fo\nr more information, see Private registry settings in Amazon ECR. Pull through ca\nche rules provide a way to cache repositories in an upstream registry in your pr\nivate Amazon ECR registry. Using a pull through cache rule, Amazon ECR will peri\nodically reach out to the upstream registry to ensure the cached image in your A\nmazon ECR private registry is up to date. For more information, see Sync an upst\nream registry with an Amazon ECR private registry. How to get started with Amazo\nn ECR If you are using Amazon Elastic Container Service (Amazon ECS) or Amazon E\nlastic Kubernetes Service (Amazon EKS), note that the setup for those two servic\nes is similar to the setup for Amazon ECR because Amazon ECR is an extension of \nboth services. When using the AWS Command Line Interface with Amazon ECR, use a \nversion of the AWS CLI that supports the latest Amazon ECR features. If you don'\nt see support for an Amazon ECR feature in the AWS CLI, upgrade to the latest ve\nrsion of the AWS CLI. For information about installing the latest version of the\n AWS CLI, see Install or update to the latest version of the AWS CLI in the AWS \nCommand Line Interface User Guide. To learn how to push a container image to a p\nrivate Amazon ECR repository using the AWS CLI and Docker, see Moving an image t\nhrough its lifecycle in Amazon ECR. Pricing for Amazon ECR With Amazon ECR, you \nonly pay for the amount of data you store in your repositories and for the data \ntransfer from your image pushes and pulls. For more information, see Amazon ECR \npricing. Javascript is disabled or is unavailable in your browser. To use the Am\nazon Web Services Documentation, Javascript must be enabled. Please refer to you\nr browser's Help pages for instructions. Document Conventions Concepts and compo\nnents Did this page help you? - Yes Thanks for letting us know we're doing a goo\nd job! If you've got a moment, please tell us what we did right so we can do mor\ne of it. Did this page help you? - No Thanks for letting us know this page needs\n work. We're sorry we let you down. If you've got a moment, please tell us how w\ne can make the documentation better.",
  "body": "",
  "code": "",
  "table": ""
}
{
  "url": "https://docs.aws.amazon.com/AmazonECR/latest/public/what-is-ecr.html",
  "pageType": "UserGuidePage",
  "title": "What Is Amazon Elastic Container Registry Public? - Amazon ECR Public AWSDocumen\ntationAmazon ECRUser Guide Components of Amazon ECR PublicHow to get started wit\nh Amazon ECR Public What Is Amazon Elastic Container Registry Public? Amazon Ela\nstic Container Registry Public is a managed AWS container image registry service\n that is secure, scalable, and reliable. Amazon ECR supports public image reposi\ntories with resource-based permissions using AWS IAM so that specific users can \naccess your public repositories to push images. Developers can use their preferr\ned CLI to push and manage Docker images, Open Container Initiative (OCI) images,\n and OCI compatible artifacts. Your images are publicly available to pull, eithe\nr anonymously or using an Amazon ECR Public authentication token. Note Amazon EC\nR supports private container image repositories as well. For more information, s\nee What is Amazon ECR in the Amazon Elastic Container Registry User Guide. The A\nWS container services team maintains a public roadmap on GitHub. It contains inf\normation about what the teams are working on and allows all AWS customers the ab\nility to give direct feedback. For more information, see AWS Containers Roadmap.\n Components of Amazon ECR Public Amazon ECR Public contains the following compon\nents: Amazon ECR Public Gallery The Amazon ECR Public Gallery is the public port\nal that lists all public repositories hosted on Amazon ECR Public. Visit the Ama\nzon ECR Public Gallery at https://gallery.ecr.aws. For more information, see Ama\nzon ECR Public Gallery. Registry A public registry is provided to each AWS accou\nnt; you can create public image repositories in your public registry and store i\nmages in them. For more information, see Amazon ECR public registries. Authoriza\ntion token Your client must authenticate to a public registry as an AWS user bef\nore it can push images to a public repository. For image pulls, Amazon ECR Publi\nc accepts both anonymous pulls and pulls using an authentication token. For more\n information, see Registry authentication in Amazon ECR public. Repository An Am\nazon ECR image repository contains your Docker images, Open Container Initiative\n (OCI) images, and OCI compatible artifacts. For more information, see Amazon EC\nR public repositories. Repository policy You can control access to your reposito\nries and the images within them with repository policies. For more information, \nsee Public repository policies in Amazon ECR Public. Image You can push and pull\n container images to your repositories. You can use these images locally on your\n development system, or you can use them in Amazon ECS task definitions and Amaz\non EKS pod specifications. How to get started with Amazon ECR Public If you've s\nigned up for AWS and have been using Amazon Elastic Container Service (Amazon EC\nS) or Amazon Elastic Kubernetes Service (Amazon EKS), you are close to being abl\ne to use Amazon ECR. The setup process for those two services is similar, as Ama\nzon ECR is an extension of both services. When using the AWS CLI with Amazon ECR\n, we recommend that you use a version of the AWS CLI that supports the latest Am\nazon ECR features. If you do not see support for an Amazon ECR feature in the AW\nS CLI, you should upgrade to the latest version. For more information, see http:\n//aws.amazon.com/cli/. For a quickstart guide on pushing a container image to Am\nazon ECR Public repository, see Moving an image through its lifecycle in Amazon \nECR Public. Javascript is disabled or is unavailable in your browser. To use the\n Amazon Web Services Documentation, Javascript must be enabled. Please refer to \nyour browser's Help pages for instructions. Document Conventions Amazon ECR Publ\nic Gallery Did this page help you? - Yes Thanks for letting us know we're doing \na good job! If you've got a moment, please tell us what we did right so we can d\no more of it. Did this page help you? - No Thanks for letting us know this page \nneeds work. We're sorry we let you down. If you've got a moment, please tell us \nhow we can make the documentation better.",
  "body": "",
  "code": "",
  "table": ""
}
{
  "url": "https://docs.aws.amazon.com/AmazonECS/latest/developerguide/Welcome.html",
  "pageType": "DevGuidePage",
  "title": "What is Amazon Elastic Container Service? - Amazon Elastic Container Service AWS\nDocumentationAmazon ECSDeveloper Guide Amazon ECS terminology and componentsAppl\nication lifecycle What is Amazon Elastic Container Service? Amazon Elastic Conta\niner Service (Amazon ECS) is a fully managed container orchestration service tha\nt helps you easily deploy, manage, and scale containerized applications. As a fu\nlly managed service, Amazon ECS comes with AWS configuration and operational bes\nt practices built-in. It's integrated with both AWS and third-party tools, such \nas Amazon Elastic Container Registry and Docker. This integration makes it easie\nr for teams to focus on building the applications, not the environment. You can \nrun and scale your container workloads across AWS Regions in the cloud, and on-p\nremises, without the complexity of managing a control plane. Amazon ECS terminol\nogy and components There are three layers in Amazon ECS: Capacity - The infrastr\nucture where your containers run Controller - Deploy and manage your application\ns that run on the containers Provisioning - The tools that you can use to interf\nace with the scheduler to deploy and manage your applications and containers The\n following diagram shows the Amazon ECS layers. Amazon ECS capacity Amazon ECS c\napacity is the infrastructure where your containers run. The following is an ove\nrview of the capacity options: Amazon EC2 instances in the AWS cloud You choose \nthe instance type, the number of instances, and manage the capacity. Serverless \n(AWS Fargate) in the AWS cloud Fargate is a serverless, pay-as-you-go compute en\ngine. With Fargate you don't need to manage servers, handle capacity planning, o\nr isolate container workloads for security. On-premises virtual machines (VM) or\n servers Amazon ECS Anywhere provides support for registering an external instan\nce such as an on-premises server or virtual machine (VM), to your Amazon ECS clu\nster. The capacity can be located in any of the following AWS resources: Availab\nility Zones Local Zones Wavelength Zones AWS Regions AWS Outposts Amazon ECS con\ntroller The Amazon ECS scheduler is the software that manages your applications.\n Amazon ECS provisioning There are multiple options for provisioning Amazon ECS:\n AWS Management Console  Provides a web interface that you can use to access you\nr Amazon ECS resources. AWS Command Line Interface (AWS CLI)  Provides commands \nfor a broad set of AWS services, including Amazon ECS. It's supported on Windows\n, Mac, and Linux. For more information, see AWS Command Line Interface. AWS SDKs\n  Provides language-specific APIs and takes care of many of the connection detai\nls. These include calculating signatures, handling request retries, and error ha\nndling. For more information, see AWS SDKs. Copilot  Provides an open-source too\nl for developers to build, release, and operate production ready containerized a\npplications on Amazon ECS. For more information, see Copilot on the GitHub websi\nte. AWS CDK  Provides an open-source software development framework that you can\n use to model and provision your cloud application resources using familiar prog\nramming languages. The AWS CDK provisions your resources in a safe, repeatable m\nanner through AWS CloudFormation. Application lifecycle The following diagram sh\nows the application lifecycle and how it works with the Amazon ECS components. Y\nou must architect your applications so that they can run on containers. A contai\nner is a standardized unit of software development that holds everything that yo\nur software application requires to run. This includes relevant code, runtime, s\nystem tools, and system libraries. Containers are created from a read-only templ\nate that's called an image. Images are typically built from a Dockerfile. A Dock\nerfile is a plaintext file that contains the instructions for building a contain\ner. After they're built, these images are stored in a registry such as Amazon EC\nR where they can be downloaded from. After you create and store your image, you \ncreate an Amazon ECS task definition. A task definition is a blueprint for your \napplication. It is a text file in JSON format that describes the parameters and \none or more containers that form your application. For example, you can use it t\no specify the image and parameters for the operating system, which containers to\n use, which ports to open for your application, and what data volumes to use wit\nh the containers in the task. The specific parameters available for your task de\nfinition depend on the needs of your specific application. After you define your\n task definition, you deploy it as either a service or a task on your cluster. A\n cluster is a logical grouping of tasks or services that runs on the capacity in\nfrastructure that is registered to a cluster. A task is the instantiation of a t\nask definition within a cluster. You can run a standalone task, or you can run a\n task as part of a service. You can use an Amazon ECS service to run and maintai\nn your desired number of tasks simultaneously in an Amazon ECS cluster. How it w\norks is that, if any of your tasks fail or stop for any reason, the Amazon ECS s\nervice scheduler launches another instance based on your task definition. It doe\ns this to replace it and thereby maintain your desired number of tasks in the se\nrvice. The container agent runs on each container instance within an Amazon ECS \ncluster. The agent sends information about the current running tasks and resourc\ne utilization of your containers to Amazon ECS. It starts and stops tasks whenev\ner it receives a request from Amazon ECS. After you deploy the task or service, \nyou can use any of the following tools to monitor your deployment and applicatio\nn: CloudWatch Runtime Monitoring Javascript is disabled or is unavailable in you\nr browser. To use the Amazon Web Services Documentation, Javascript must be enab\nled. Please refer to your browser's Help pages for instructions. Document Conven\ntions Related information Did this page help you? - Yes Thanks for letting us kn\now we're doing a good job! If you've got a moment, please tell us what we did ri\nght so we can do more of it. Did this page help you? - No Thanks for letting us \nknow this page needs work. We're sorry we let you down. If you've got a moment, \nplease tell us how we can make the documentation better.",
  "body": "",
  "code": "",
  "table": ""
}
{
  "url": "https://docs.aws.amazon.com/eks/latest/userguide/what-is-eks.html",
  "pageType": "UserGuidePage",
  "title": "What is Amazon EKS? - Amazon EKS AWSDocumentationAmazon EKSUser Guide Features o\nf Amazon EKSAmazon EKS Pricing Help improve this page Want to contribute to this\n user guide? Scroll to the bottom of this page and select Edit this page on GitH\nub. Your contributions will help make our user guide better for everyone. What i\ns Amazon EKS? Amazon Elastic Kubernetes Service (Amazon EKS) is a managed Kubern\netes service that eliminates the need to operate and maintain the availability a\nnd scalability of Kubernetes clusters in Amazon Web Services (AWS) and in your o\nwn data centers. Kubernetes is an open source system that automates the manageme\nnt, scaling, and deployment of containerized applications. To get started, see t\nhe Quickstart: Deploy a web app and store data page in the Amazon EKS User Guide\n. Features of Amazon EKS Fully Managed Kubernetes Amazon EKS provides a scalable\n and highly-available Kubernetes control plane running across multiple AWS Avail\nability Zones (AZs). Amazon EKS automatically manages availability and scalabili\nty of Kubernetes API servers and etcd persistence layer. Amazon EKS runs the Kub\nernetes control plane across multiple AZs to ensure high availability, and autom\natically detects and replaces unhealthy control plane nodes. Amazon EKS Auto Mod\ne fully automates Kubernetes cluster infrastructure management for compute, stor\nage, and networking on AWS. It simplifies Kubernetes management by automatically\n provisioning infrastructure, selecting optimal compute instances, dynamically s\ncaling resources, continuously optimizing costs, patching operating systems, and\n integrating with AWS security services. Kubernetes Compatibility and Support Am\nazon EKS runs upstream Kubernetes and is certified Kubernetes-conformant, so you\n can use all the existing plug-ins and tooling from the Kubernetes community. Ap\nplications running on Amazon EKS are fully compatible with applications running \non any standard Kubernetes environment, whether running in on-premises data cent\ners or public clouds. This means that you can easily migrate any standard Kubern\netes application to Amazon EKS without refactoring your code. Amazon EKS support\ns Kubernetes versions longer than they are supported upstream, with standard sup\nport for Kubernetes minor versions for 14 months from the time they are released\n in Amazon EKS, and extended support for Kubernetes minor versions for an additi\nonal 12 months of support (26 total months per version). See Understand the Kube\nrnetes version lifecycle on EKS for more information. Machine Learning Amazon EK\nS has become a cornerstone for deploying and managing AI/ML workloads in the clo\nud. With its ability to handle complex, resource-intensive tasks, Amazon EKS pro\nvides a scalable and flexible foundation for running AI/ML models, making it an \nideal choice for organizations aiming to harness the full potential of machine l\nearning. Whether youre training large language models that require vast amounts \nof compute power or deploying inference pipelines that need to handle unpredicta\nble traffic patterns, Amazon EKS scales up and down efficiently, optimizing reso\nurce use and cost. Amazon EKS supports a wide range of compute options including\n GPU-powered instances and AWS Neuron, allowing for high-performance training an\nd low-latency inference, ensuring that models run efficiently in production envi\nronments. See the Machine Learning on Amazon EKS Overview for more information. \nHybrid Deployments You can use the same Amazon EKS clusters to run nodes on AWS-\nhosted infrastructure in AWS Regions, AWS Local Zones, AWS Wavelength Zones, or \nin your own on-premises environments with AWS Outposts and Amazon EKS Hybrid Nod\nes. AWS Outposts is AWS-managed infrastructure that you run in your data centers\n or co-location facilities, whereas Amazon EKS Hybrid Nodes runs on virtual mach\nines or bare metal infrastructure that you manage in your on-premises or edge en\nvironments. If you need to run in isolated or air-gapped environments, you can u\nse Amazon EKS Anywhere, which is AWS-supported Kubernetes management software th\nat runs on infrastructure you manage. With Amazon EKS Anywhere, you are responsi\nble for cluster lifecycle operations and maintenance of your Amazon EKS Anywhere\n clusters. The Amazon EKS Connector can be used to view any Kubernetes cluster a\nnd their resources in the Amazon EKS console. Amazon EKS Distro is the AWS distr\nibution of the underlying Kubernetes components that power all Amazon EKS offeri\nngs. Compute You can use the full range of Amazon EC2 instance types and AWS inn\novations such as Nitro and Graviton with Amazon EKS for you to optimize the comp\nute for your workloads. You can use on-demand or Spot instances and your savings\n plans with compute you use with your Amazon EKS clusters. See Manage compute re\nsources by using nodes for more information. Networking Amazon EKS integrates wi\nth Amazon VPC allowing you to use your own Amazon VPC security groups and networ\nk access control lists (ACLs) with Amazon EKS clusters. Amazon EKS provides the \nAmazon VPC container network interface (CNI), allowing Kubernetes pods to receiv\ne IP addresses directly from the VPC. Amazon EKS supports IPv4 and IPv6 for work\nloads and dual-stack endpoints for the Amazon EKS APIs and Kubernetes API. You c\nan use Application Load Balancers (ALB) and Network Load Balancers (NLB) managed\n by the AWS Load Balancer Controller for application ingress and load balancing.\n You can also use Amazon VPC Lattice, a managed application networking service b\nuilt directly into the AWS networking infrastructure, for cross-cluster connecti\nvity with standard Kubernetes semantics in a simple and consistent manner. See C\nonfigure networking for Amazon EKS clusters for more information. Security Amazo\nn EKS integrates with AWS Identity and Access Management (IAM) for you to secure\n your clusters and applications. Amazon EKS makes it easy to map AWS IAM permiss\nions to Kubernetes Role Based Access Control (RBAC). You can use AWS IAM for clu\nster authentication and authorization with Amazon EKS Cluster Access Management,\n for access and permissions of operational software running on your clusters, an\nd for granular application access to other AWS services with Amazon EKS Pod Iden\ntity. Amazon EKS is certified by multiple compliance programs for regulated and \nsensitive applications. Amazon EKS is compliant with SOC, PCI, ISO, FedRAMP-Mode\nrate, IRAP, C5, K-ISMS, ENS High, OSPAR, HITRUST CSF, and is a HIPAA eligible se\nrvice. See Learn how access control works in Amazon EKS for more information. Ob\nservability Amazon EKS integrates with AWS Managed Service for Prometheus (AMP),\n Amazon CloudWatch, Amazon CloudTrail, and Amazon GuardDuty for monitoring, logg\ning, and auditing capabilities. You can also view performance insights for your \nAmazon EKS clusters directly in the Amazon EKS console. You can use AMP agent-le\nss scrapers or the AWS Distro for OpenTelemetry add-on to monitor and collect lo\ngs for your clusters, infrastructure, and applications. You can use Amazon Cloud\nWatch Container Insights, the CloudWatch Observability Agent add-on, and Amazon \nEKS control plane logging to monitor, collect logs, and analyze issues with your\n clusters, infrastructure, and applications. Amazon EKS also integrates with Ama\nzon CloudTrail for auditing cluster API activity, and Amazon GuardDuty for audit\n log threat analysis and runtime threat detection. See Monitor your cluster perf\normance and view logs for more information. Storage You can use a range of AWS s\ntorage services with Amazon EKS for the storage needs of your applications. Thro\nugh an AWS-supported breadth of Container Storage Interface (CSI) drivers, you c\nan easily use Amazon EBS, Amazon S3, Amazon EFS, Amazon FSX, and Amazon File Cac\nhe for the storage needs of your applications running on Amazon EKS. See Store a\npplication data for your cluster for more information. Add-ons Amazon EKS offers\n a curated set of AWS-vended Kubernetes software, also known as Amazon EKS add-o\nns, that provide key operational capabilities for Kubernetes clusters and integr\nation with various AWS services for cluster and pod networking, load balancing, \nstorage, observability, and security. Amazon EKS provides a unified management e\nxperience for finding, selecting, installing, managing, and configuring third-pa\nrty Kubernetes operational software (add-ons) from independent software vendors \non Amazon EKS clusters. See Amazon EKS add-ons for more information. Management \ninterfaces Amazon EKS supports a range of interfaces to provision, manage, and m\naintain clusters including the Amazon EKS console, Amazon EKS API/SDKs, CDK, AWS\n CLI, eksctl CLI, AWS CloudFormation, and Terraform. You can also use AWS Contro\nllers for Kubernetes (ACK) to provision and manage AWS services from within your\n Kubernetes environment using Kubernetes interfaces. ACK makes it simple to buil\nd scalable and highly available Kubernetes applications utilizing AWS services. \nSee Get started with Amazon EKS for more information. Operating systems Amazon E\nKS supports a range of operating systems and you can use pre-built, Amazon EKS-o\nptimized Amazon Machine Images (AMIs) for the base images of your compute nodes.\n Amazon EKS maintains optimized images for Amazon Linux 2, Amazon Linux 2023, Bo\nttlerocket, Windows, and there are Ubuntu images maintained by Canonical. You ca\nn also use your own custom AMIs for other operating system variants. The Amazon \nEKS AMIs for Amazon Linux have built-in support for NVIDIA and AWS Neuron accele\nrated instance types. See Create nodes with pre-built optimized images for more \ninformation. Amazon EKS Pricing Amazon EKS has per cluster pricing based on Kube\nrnetes cluster version support, pricing for Amazon EKS Auto Mode, and per vCPU p\nricing for Amazon EKS Hybrid Nodes. When using Amazon EKS, you pay separately fo\nr the AWS resources you use to run your applications on Kubernetes worker nodes.\n For example, if you are running Kubernetes worker nodes as Amazon EC2 instances\n with Amazon EBS volumes and public IPv4 addresses, you are charged for the inst\nance capacity through Amazon EC2, the volume capacity through Amazon EBS, and th\ne IPv4 address through Amazon VPC. Visit the respective pricing pages of the AWS\n services you are using with your Kubernetes applications for detailed pricing i\nnformation. For Amazon EKS cluster, Amazon EKS Auto Mode, and Amazon EKS Hybrid \nNodes pricing, see Amazon EKS Pricing. For Amazon EC2 pricing, see Amazon EC2 On\n-Demand Pricing and Amazon EC2 Spot Pricing. For AWS Fargate pricing, see AWS Fa\nrgate Pricing. You can use your savings plans for compute used in Amazon EKS clu\nsters. For more information, see Pricing with Savings Plans.  Edit this page on \nGitHub Javascript is disabled or is unavailable in your browser. To use the Amaz\non Web Services Documentation, Javascript must be enabled. Please refer to your \nbrowser's Help pages for instructions. Document Conventions Common use cases Did\n this page help you? - Yes Thanks for letting us know we're doing a good job! If\n you've got a moment, please tell us what we did right so we can do more of it. \nDid this page help you? - No Thanks for letting us know this page needs work. We\n're sorry we let you down. If you've got a moment, please tell us how we can mak\ne the documentation better.",
  "body": "",
  "code": "",
  "table": ""
}
{
  "url": "https://docs.aws.amazon.com/eks/latest/userguide/machine-learning-on-eks.html",
  "pageType": "UserGuidePage",
  "title": "Machine Learning on Amazon EKS Overview - Amazon EKS AWSDocumentationAmazon EKSU\nser Guide Advantages of Machine Learning on EKS and the AWS cloudWhy Choose Amaz\non EKS for AI/ML?Start using Machine Learning on EKS Help improve this page Want\n to contribute to this user guide? Scroll to the bottom of this page and select \nEdit this page on GitHub. Your contributions will help make our user guide bette\nr for everyone. Machine Learning on Amazon EKS Overview Machine Learning (ML) is\n an area of Artificial Intelligence (AI) where machines process large amounts of\n data to look for patterns and make connections between the data. This can expos\ne new relationships and help predict outcomes that might not have been apparent \notherwise. For large-scale ML projects, data centers must be able to store large\n amounts of data, process data quickly, and integrate data from many sources. Th\ne platforms running ML applications must be reliable and secure, but also offer \nresiliency to recover from data center outages and application failures. AWS Ela\nstic Kubernetes Service (EKS), running in the AWS cloud, is particularly suited \nfor ML workloads. The primary goal of this section of the EKS User Guide is to h\nelp you put together the hardware and software component to build platforms to r\nun Machine Learning workloads in an EKS cluster. We start by explaining the feat\nures and services available to you in EKS and the AWS cloud, then provide you wi\nth tutorials to help you work with ML platforms, frameworks, and models. Advanta\nges of Machine Learning on EKS and the AWS cloud Amazon Elastic Kubernetes Servi\nce (EKS) is a powerful, managed Kubernetes platform that has become a cornerston\ne for deploying and managing AI/ML workloads in the cloud. With its ability to h\nandle complex, resource-intensive tasks, Amazon EKS provides a scalable and flex\nible foundation for running AI/ML models, making it an ideal choice for organiza\ntions aiming to harness the full potential of machine learning. Key Advantages o\nf AI/ML Platforms on Amazon EKS include: Scalability and Flexibility Amazon EKS \nenables organizations to scale AI/ML workloads seamlessly. Whether youre trainin\ng large language models that require vast amounts of compute power or deploying \ninference pipelines that need to handle unpredictable traffic patterns, EKS scal\nes up and down efficiently, optimizing resource use and cost. High Performance w\nith GPUs and Neuron Instances Amazon EKS supports a wide range of compute option\ns, including GPUs and AWS} Neuron instances, which are essential for acceleratin\ng AI/ML workloads. This support allows for high-performance training and low-lat\nency inference, ensuring that models run efficiently in production environments.\n Integration with AI/ML Tools Amazon EKS integrates seamlessly with popular AI/M\nL tools and frameworks like TensorFlow, PyTorch, and Ray, providing a familiar a\nnd robust ecosystem for data scientists and engineers. These integrations enable\n users to leverage existing tools while benefiting from the scalability and mana\ngement capabilities of Kubernetes. Automation and Management Kubernetes on Amazo\nn EKS automates many of the operational tasks associated with managing AI/ML wor\nkloads. Features like automatic scaling, rolling updates, and self-healing ensur\ne that your applications remain highly available and resilient, reducing the ove\nrhead of manual intervention. Security and Compliance Running AI/ML workloads on\n Amazon EKS provides robust security features, including fine-grained IAM roles,\n encryption, and network policies, ensuring that sensitive data and models are p\nrotected. EKS also adheres to various compliance standards, making it suitable f\nor enterprises with strict regulatory requirements. Why Choose Amazon EKS for AI\n/ML? Amazon EKS offers a comprehensive, managed environment that simplifies the \ndeployment of AI/ML models while providing the performance, scalability, and sec\nurity needed for production workloads. With its ability to integrate with a vari\nety of AI/ML tools and its support for advanced compute resources, EKS empowers \norganizations to accelerate their AI/ML initiatives and deliver innovative solut\nions at scale. By choosing Amazon EKS, you gain access to a robust infrastructur\ne that can handle the complexities of modern AI/ML workloads, allowing you to fo\ncus on innovation and value creation rather than managing underlying systems. Wh\nether you are deploying simple models or complex AI systems, Amazon EKS provides\n the tools and capabilities needed to succeed in a competitive and rapidly evolv\ning field. Start using Machine Learning on EKS To begin planning for and using M\nachine Learning platforms and workloads on EKS on the AWS cloud, proceed to the \nGet started deploying Machine Learning tools on EKS section.  Edit this page on \nGitHub Javascript is disabled or is unavailable in your browser. To use the Amaz\non Web Services Documentation, Javascript must be enabled. Please refer to your \nbrowser's Help pages for instructions. Document Conventions Nodes Get started wi\nth ML Did this page help you? - Yes Thanks for letting us know we're doing a goo\nd job! If you've got a moment, please tell us what we did right so we can do mor\ne of it. Did this page help you? - No Thanks for letting us know this page needs\n work. We're sorry we let you down. If you've got a moment, please tell us how w\ne can make the documentation better.",
  "body": "",
  "code": "",
  "table": ""
}
{
  "url": "https://docs.aws.amazon.com/eks/latest/userguide/hybrid-nodes-overview.html",
  "pageType": "UserGuidePage",
  "title": "Amazon EKS Hybrid Nodes overview - Amazon EKS AWSDocumentationAmazon EKSUser Gui\nde General concepts of Amazon EKS Hybrid Nodes Help improve this page Want to co\nntribute to this user guide? Scroll to the bottom of this page and select Edit t\nhis page on GitHub. Your contributions will help make our user guide better for \neveryone. Amazon EKS Hybrid Nodes overview With Amazon EKS Hybrid Nodes, you can\n use your on-premises and edge infrastructure as nodes in Amazon EKS clusters. A\nWS manages the AWS-hosted Kubernetes control plane of the Amazon EKS cluster, an\nd you manage the hybrid nodes that run in your on-premises or edge environments.\n This unifies Kubernetes management across your environments and offloads Kubern\netes control plane management to AWS for your on-premises and edge applications.\n Amazon EKS Hybrid Nodes works with any on-premises hardware or virtual machines\n, bringing the efficiency, scalability, and availability of Amazon EKS to wherev\ner your applications need to run. You can use a wide range of Amazon EKS feature\ns with Amazon EKS Hybrid Nodes including Amazon EKS add-ons, Amazon EKS Pod Iden\ntity, cluster access entries, cluster insights, and extended Kubernetes version \nsupport. Amazon EKS Hybrid Nodes natively integrates with AWS services including\n AWS Systems Manager, AWS IAM Roles Anywhere, Amazon Managed Service for Prometh\neus, Amazon CloudWatch, and Amazon GuardDuty for centralized monitoring, logging\n, and identity management. With Amazon EKS Hybrid Nodes, there are no upfront co\nmmitments or minimum fees, and you are charged per hour for the vCPU resources o\nf your hybrid nodes when they are attached to your Amazon EKS clusters. For more\n pricing information, see Amazon EKS Pricing. For an overview of the other Amazo\nn EKS options for on-premises and edge deployments, see Deploy Amazon EKS cluste\nrs across cloud and on-premises environments. General concepts of Amazon EKS Hyb\nrid Nodes Amazon EKS Hybrid Nodes must have a reliable connection between your o\nn-premises environment and AWS. Amazon EKS Hybrid Nodes arent a fit for disconne\ncted, disrupted, intermittent or limited (DDIL) environments. If you are running\n in a DDIL environment, consider Amazon EKS Anywhere. Running Amazon EKS Hybrid \nNodes on cloud infrastructure, including AWS Regions, AWS Local Zones, AWS Outpo\nsts, or in other clouds, is not supported. Use Amazon EKS Auto Mode, Karpenter, \nAmazon EC2 managed node groups, self-managed nodes, or AWS Fargate when running \nin AWS Regions. Use Amazon EC2 managed node groups or Amazon EC2 self-managed no\ndes when running on AWS Local Zones. Only Amazon EC2 self-managed nodes can be u\nsed on AWS Outposts or AWS Wavelength Zones. A single Amazon EKS cluster can be \nused to run hybrid nodes and nodes in AWS Regions, AWS Local Zones, or AWS Outpo\nsts. Amazon EKS Hybrid Nodes is available in all AWS Regions, except the AWS Gov\nCloud (US) Regions and the AWS China Regions. You will be charged the hybrid nod\nes fee if you run hybrid nodes on Amazon EC2 instances. Billing for hybrid nodes\n starts when the nodes join the Amazon EKS cluster and stops when the nodes are \nremoved from the cluster. Be sure to remove your hybrid nodes from your Amazon E\nKS cluster if you are not using them. Infrastructure Management Amazon EKS Hybri\nd Nodes follows a bring your own infrastructure approach where it is your respon\nsibility to provision and manage the physical or virtual machines and the operat\ning system you use for hybrid nodes. Amazon EKS Hybrid Nodes are agnostic to the\n infrastructure they run on. You can run hybrid nodes on physical or virtual mac\nhines, and x86 and ARM architectures. Operating Systems for hybrid nodes Amazon \nLinux 2023 (AL2023): You can use Amazon Linux 2023 (AL2023) as the node operatin\ng system for hybrid nodes, but only in virtualized environments such as VMWare, \nKVM, and Hyper-V. AWS supports the integration of hybrid nodes with AL2023, but \nAL2023 isnt covered by the AWS Support Plans when you run it outside of Amazon E\nC2. Ubuntu: You can use Ubuntu 20.04, Ubuntu 22.04, and Ubuntu 24.04 as the node\n operating system for hybrid nodes. Red Hat Enterprise Linux (RHEL): You can use\n RHEL 8 and RHEL 9 as the node operating system for hybrid nodes. Kubernetes and\n platform versions Amazon EKS Hybrid Nodes supports the same Kubernetes versions\n and deprecation schedule as Amazon EKS, including standard and extended Kuberne\ntes version support. For more information on Kubernetes versions in Amazon EKS, \nsee Understand the Kubernetes version lifecycle on EKS. For more information abo\nut Amazon EKS platform versions, see View Amazon EKS platform versions for each \nKubernetes version. You must create new Amazon EKS clusters to use Amazon EKS Hy\nbrid Nodes. Hybrid nodes cant be used with existing Amazon EKS clusters. Network\ning The communication between the Amazon EKS control plane and hybrid nodes is r\nouted through the VPC and subnets you pass during cluster creation, which builds\n on the existing mechanism in Amazon EKS for control plane to node networking. A\nmazon EKS Hybrid Nodes is flexible to your preferred method of connecting your o\nn-premises networks to a VPC in AWS. There are several documented options availa\nble including AWS Site-to-Site VPN and AWS Direct Connect, and you can choose th\ne method that best fits your use case. IP address family: Hybrid nodes can be us\ned with Amazon EKS clusters configured with the IPv4 IP address family only. You\n cant use Amazon EKS clusters configured with the IPv6 IP address family. Simila\nrly, your on-premises node and Pod CIDRs must be IPv4 RFC1918 CIDR blocks. You m\nust enable the required domains, protocols, and ports for Amazon EKS Hybrid Node\ns in your on-premises environments and firewalls. For more information, includin\ng minimum networking requirements, see Prepare networking for hybrid nodes. Clus\nter endpoint access: You can use Public or Private cluster endpoint access. You \nshould not use Public and Private cluster endpoint access, as the endpoint DNS r\nesolution will always resolve to the public addresses for queries originating fr\nom your on-premises environment. For information and best practices during scena\nrios where there are network disconnections between hybrid nodes and the AWS Reg\nion, see the hybrid nodes section of the Amazon EKS Best Practices Guide. Applic\nation load balancing: Kubernetes has a Service object to define the names and do\nmain names for your applications and resolve and load balance to them. By defaul\nt, the type:LoadBalancer type of Service additionally creates an AWS Classic Loa\nd Balancer for traffic from outside the cluster. You can change this behavior wi\nth add-ons. Specifically, we recommend the AWS Application Load Balancer and AWS\n Network Load Balancer which are created by the AWS Load Balancer Controller, in\nstead of the AWS Classic Load Balancer. For steps to install the AWS Load Balanc\ner Controller in a hybrid environment, see AWS Load Balancer Controller. Securit\ny for hybrid nodes Amazon EKS Hybrid Nodes use temporary IAM credentials to auth\nenticate with your Amazon EKS cluster. You can use either AWS IAM Roles Anywhere\n or AWS Systems Manager (SSM) hybrid activations for provisioning the on-premise\ns IAM credentials for hybrid nodes. It is recommended to use AWS SSM hybrid acti\nvations if you do not have existing Public Key Infrastructure (PKI) with a Certi\nficate Authority (CA) and certificates for your on-premises environments. If you\n do have existing PKI and certificates on-premises, use AWS IAM Roles Anywhere. \nYou can use API or API_AND_CONFIG_MAP cluster authentication modes for your hybr\nid nodes-enabled Amazon EKS clusters. Use the cluster access entry type called H\nYBRID_LINUX with your hybrid nodes IAM role to enable hybrid nodes to join the A\nmazon EKS cluster. OIDC authentication is supported for hybrid nodes-enabled Ama\nzon EKS clusters. You can use Amazon EKS Pod Identities and IAM Roles for Servic\ne Accounts (IRSA) with applications running on hybrid nodes to enable granular a\nccess for your Pods running on hybrid nodes with other AWS services. You can use\n Amazon GuardDuty EKS Protection with hybrid nodes-enabled Amazon EKS clusters t\no analyze activities of users and applications accessing your cluster. Add-ons f\nor hybrid nodes For detailed information, see Configure common add-ons for hybri\nd nodes. Container Networking Interface (CNI): The AWS VPC CNI cant be used with\n hybrid nodes. The core capabilities of Cilium and Calico are supported for use \nwith hybrid nodes. You can manage your CNI with your choice of tooling such as H\nelm. For more information, see Configure a CNI for hybrid nodes. kube-proxy and \nCoreDNS: kube-proxy and CoreDNS are installed automatically when hybrid nodes jo\nin the Amazon EKS cluster. These add-ons can be managed as Amazon EKS add-ons af\nter cluster creation. Ingress and Load Balancing: You can use the AWS Load Balan\ncer Controller and Application Load Balancer (ALB) or Network Load Balancer (NLB\n) with the target type ip for workloads on hybrid nodes connected with AWS Direc\nt Connect or AWS Site-to-Site VPN. You can alternatively use your choice of Ingr\ness controller or load balancer for application traffic that stays local to your\n on-premises environment. Metrics: You can use Amazon Managed Prometheus (AMP) a\ngent-less scrapers, AWS Distro for Open Telemetry (ADOT), and the Amazon CloudWa\ntch Observability Agent with hybrid nodes. To use AMP agent-less scrapers for Po\nd metrics on hybrid nodes, your Pods must be accessible from the VPC that you us\ne for the Amazon EKS cluster. Logs: You can enable Amazon EKS control plane logg\ning for hybrid nodes-enabled clusters. You can use the ADOT EKS add-on and the A\nmazon CloudWatch Observability Agent EKS add-on for hybrid node and Pod logging.\n User interfaces Node management: The Amazon EKS Hybrid Nodes CLI is called node\nadm and is run on each on-premises host to simplify the installation, configurat\nion, registration, and uninstall of the hybrid nodes components. The hybrid node\ns nodeadm version is different than the nodeadm version used in the AL2023 Amazo\nn EKS-optimized AMIs. You should not use the hybrid nodes nodeadm version for no\ndes running in Amazon EC2. Cluster management: The Amazon EKS user interfaces fo\nr cluster management are the same with hybrid nodes-enabled Amazon EKS clusters.\n This includes the AWS Management Console, AWS API, AWS SDKs, AWS CLI, eksctl CL\nI, AWS CloudFormation, and Terraform.  Edit this page on GitHub Javascript is di\nsabled or is unavailable in your browser. To use the Amazon Web Services Documen\ntation, Javascript must be enabled. Please refer to your browser's Help pages fo\nr instructions. Document Conventions Get node logs Prerequisites Did this page h\nelp you? - Yes Thanks for letting us know we're doing a good job! If you've got \na moment, please tell us what we did right so we can do more of it. Did this pag\ne help you? - No Thanks for letting us know this page needs work. We're sorry we\n let you down. If you've got a moment, please tell us how we can make the docume\nntation better.",
  "body": "",
  "code": "Map(code -> IPv4, language -> code)Map(code -> IPv6, language -> code)Map(code -\n> IPv4, language -> code)Map(code -> type:LoadBalancer, language -> code)Map(cod\ne -> API, language -> code)Map(code -> API_AND_CONFIG_MAP, language -> code)Map(\ncode -> HYBRID_LINUX, language -> code)Map(code -> kube-proxy, language -> code)\nMap(code -> kube-proxy, language -> code)Map(code -> ip, language -> code)Map(co\nde -> nodeadm, language -> code)Map(code -> nodeadm, language -> code)Map(code -\n> nodeadm, language -> code)Map(code -> nodeadm, language -> code)",
  "table": ""
}
{
  "url": "https://docs.aws.amazon.com/vpc/latest/userguide/vpc-network-acls",
  "pageType": "UserGuidePage",
  "title": "Control subnet traffic with network access control lists - Amazon Virtual Privat\ne Cloud AWSDocumentationAmazon VPCUser Guide Control subnet traffic with network\n access control lists A network access control list (ACL) allows or denies speci\nfic inbound or outbound traffic at the subnet level. You can use the default net\nwork ACL for your VPC, or you can create a custom network ACL for your VPC with \nrules that are similar to the rules for your security groups in order to add an \nadditional layer of security to your VPC. There is no additional charge for usin\ng network ACLs. The following diagram shows a VPC with two subnets. Each subnet \nhas a network ACL. When traffic enters the VPC (for example, from a peered VPC, \nVPN connection, or the internet), the router sends the traffic to its destinatio\nn. Network ACL A determines which traffic destined for subnet 1 is allowed to en\nter subnet 1, and which traffic destined for a location outside subnet 1 is allo\nwed to leave subnet 1. Similarly, network ACL B determines which traffic is allo\nwed to enter and leave subnet 2. For information about the differences between s\necurity groups and network ACLs, see Compare security groups and network ACLs. C\nontents Network ACL basics Network ACL rules Default network ACL Custom network \nACLs Ephemeral ports Path MTU Discovery Work with network ACLs Example: Control \naccess to instances in a subnet Troubleshoot reachability issues Javascript is d\nisabled or is unavailable in your browser. To use the Amazon Web Services Docume\nntation, Javascript must be enabled. Please refer to your browser's Help pages f\nor instructions. Document Conventions Share security groups with AWS Organizatio\nns Network ACL basics Did this page help you? - Yes Thanks for letting us know w\ne're doing a good job! If you've got a moment, please tell us what we did right \nso we can do more of it. Did this page help you? - No Thanks for letting us know\n this page needs work. We're sorry we let you down. If you've got a moment, plea\nse tell us how we can make the documentation better.",
  "body": "",
  "code": "",
  "table": ""
}
{
  "url": "https://docs.aws.amazon.com/lightsail/latest/userguide/amazon-lightsail-container-services.html",
  "pageType": "UserGuidePage",
  "title": "Deploy and manage containers on Amazon Lightsail - Amazon Lightsail AWSDocumenta\ntionAmazon LightsailUser Guide ContainersLightsail container service elementsUse\n Lightsail container services Deploy and manage containers on Amazon Lightsail A\nn Amazon Lightsail container service is a highly scalable compute and networking\n resource on which you can deploy, run, and manage containers. A container is a \nstandard unit of software that packages code and its dependencies together so th\ne application runs quickly and reliably from one computing environment to anothe\nr. You can think of your Lightsail container service as a computing environment \nthat lets you run containers on AWS infrastructure by using images that you crea\nte on your local machine and push to your service, or images from an online repo\nsitory, like Amazon ECR Public Gallery. You can also run containers locally, on \nyour local machine, by installing software such as Docker. Amazon Elastic Contai\nner Service (Amazon ECS) and Amazon Elastic Compute Cloud (Amazon EC2) are other\n resources within the AWS infrastructure on which you can run containers. For mo\nre information, see the Amazon ECS Developer Guide. Contents Containers Lightsai\nl container service elements Lightsail container services Container service capa\ncity (scale and power) Pricing Deployments Deployment versions Container image s\nources Container service ARN Public endpoints and default domains Custom domains\n and SSL/TLS certificates Container logs Metrics Use Lightsail container service\ns Containers A container is a standard unit of software that packages code and i\nts dependencies together so the application runs quickly and reliably from one c\nomputing environment to another. You could run a container on your development e\nnvironment, deploy it to your pre-production environment, and then deploy it to \nyour production environment. Your containers will run reliably regardless of whe\nther your development environment is your local machine, your pre-production env\nironment is a physical server in a data center, or your production environment i\ns a virtual private server in the cloud. A container image is a lightweight, sta\nndalone, executable package of software that includes everything needed to run a\nn application: code, runtime, system tools, system libraries and settings. Conta\niner images become containers at runtime. By containerizing the application and \nits dependencies, you no longer have to worry about whether your software runs c\norrectly on the operating system and infrastructure that you deploy it on  you c\nan spend more time focusing on the code. For more information about containers, \nand container images, see What is a Container? in the Docker documentation. Ligh\ntsail container service elements The following are the key elements of Lightsail\n container services that you should understand before getting started. Lightsail\n container services A container service is the Lightsail compute resource that y\nou can create in any AWS Region in which Lightsail is available. You can create \nand delete container services at any time. For more information, see Create Ligh\ntsail container services and Delete Lightsail container services. Container serv\nice capacity (scale and power) You must choose the following capacity parameters\n when you first create your container service: Scale  The number of compute node\ns that you want your container workload to run in. Your container workload is co\npied across the compute nodes of your service. You can specify up to 20 compute \nnodes for a container service. You pick the scale based on the number of nodes y\nou want powering your service for better availability and higher capacity. Traff\nic to your containers will be load-balanced across all nodes. Power  The memory \nand vCPUs of each node in your container service. The powers that you can choose\n are Nano (Na), Micro (Mi), Small (Sm), Medium (Md), Large (Lg), and Xlarge (Xl)\n, each with a progressively greater amount of memory and vCPUs. If you specify t\nhe scale of your container service as more than 1, then your container workload \nis copied across the multiple compute nodes of your service. For example, if the\n scale of your service is 3 and the power is Nano, then there are three copies o\nf your container workload running on three compute resources each with 512 MB of\n RAM and 0.25 vCPUs. The incoming traffic is load-balanced between the three res\nources. The greater the capacity you specify for your container service, the mor\ne traffic it is able to handle. You can dynamically increase the power and scale\n of your container service at any time without any down-time if you find that it\n's under-provisioned, or decrease it if you find that it's over-provisioned. Lig\nhtsail automatically manages the capacity change along with your current deploym\nent. For more information, see Change the capacity of your container service. Pr\nicing The monthly price of your container service is calculated by multiplying t\nhe price of its power with the number of its compute nodes (the scale of your se\nrvice). For example, a service with a medium power, which has a price of $40 USD\n, and a scale of 3 compute nodes, will cost $120 USD per month. You are charged \nfor your container service whether it's enabled or disabled, and whether it has \na deployment or not. You must delete your container service to stop being charge\nd for it. Each container service, regardless of its configured capacity, include\ns a monthly data transfer quota of 500 GB. The data transfer quota does not chan\nge regardless of the power and scale that you choose for your service. Data tran\nsfer out to the internet in excess of the quota will result in an overage charge\n that varies by AWS Region and starts at $0.09 USD per GB. Data transfer in from\n the internet in excess of the quota does not incur an overage charge. For more \ninformation, see the Lightsail pricing page. Deployments You can create a deploy\nment in your Lightsail container service. A deployment is a set of specification\ns for the container workload that you wish to launch on your service. You can sp\necify the following parameters for each container entry in a deployment: The nam\ne of your container that will be launched The source container image to use for \nyour container The command to run when launching your container The environment \nvariables to apply to your container The network ports to open on your container\n The container in the deployment to make publicly accessible through the default\n domain of the container service Note Only one container in a deployment can be \nmade publicly accessible for each container service. The following health check \nparameters will apply to the public endpoint of a deployment after it's launched\n: The directory path on which to perform a health check. Advanced health check s\nettings, such as interval seconds, timeout seconds, success codes, healthy thres\nhold, and unhealthy threshold. Your container service can have one active deploy\nment at a time, and a deployment can have up to 10 container entries. You can cr\neate a deployment at the same time as you create your container service, or you \ncan create it after your service is up and running. For more information, see Cr\neate and manage container service deployments. Deployment versions Every deploym\nent that you create in your container service is saved as a deployment version. \nIf you modify the parameters of an existing deployment, the containers are re-de\nployed to your service and the modified deployment results in a new deployment v\nersion. The latest 50 deployment versions for each container service are saved. \nYou can use any of the 50 deployment versions to create a new deployment in the \nsame container service. For more information, see Create and manage container se\nrvice deployments. Container image sources When you create a deployment, you mus\nt specify a source container image for each container entry in your deployment. \nImmediately after you create your deployment, your container service pulls the i\nmages from the sources you specify and uses them to create your containers. The \nimages that you specify can originate from the following sources: A public regis\ntry, such as Amazon ECR Public Gallery, or some other public container image reg\nistry. For more information about Amazon ECR Public, see What Is Amazon Elastic \nContainer Registry Public? in the Amazon ECR Public User Guide. Images pushed fr\nom your local machine to your container service. If you create container images \non your local machine, you can push them to your container service to use them w\nhen creating a deployment. For more information, see Create container service im\nages and Push and manage container images. Lightsail container services support \nLinux-based container images. Windows-based container images are currently not s\nupported, but you can run Docker, the AWS Command Line Interface (AWS CLI), and \nthe Lightsail Control (lightsailctl) plugin on Windows to build and push your Li\nnux based images to your Lightsail container service. Container service ARN Amaz\non Resource Names (ARNs) uniquely identify AWS resources. We require an ARN when\n you need to specify a resource unambiguously across all of AWS, such as in IAM \npolicies, and API calls. To get the ARN for your container service, use the GetC\nontainerServices Lightsail API action, and specify the name of the container ser\nvice using the serviceName parameter. Your container service ARN will be listed \nin the results of that action as shown in the following example. For more inform\nation, see GetContainerServices in the Amazon Lightsail API Reference. You'll se\ne output similar to the following: {    \\\"containerServices\\\": [        {       \n     \\\"containerServiceName\\\": \\\"container-service-1\\\",            \\\"arn\\\": \\\"ar\nn:aws:lightsail: :111122223333:ContainerService/a1b2c3d4-5678-90ab-cdef-EXAMPLE1\n1111\\\",            \\\"createdAt\\\": \\\"2024-01-01T00:00:00+00:00\\\",            \\\"lo\ncation\\\": {                \\\"availabilityZone\\\": \\\"all\\\",                \\\"regio\nnName\\\": \\\"us-west-2\\\"        },        .....} Public endpoints and default doma\nins When you create a deployment, you can specify the container entry in the dep\nloyment that will serve as the public endpoint of your container service. The ap\nplication on the public endpoint container is publicly accessible on the interne\nt through a randomly generated default domain of your container service. The def\nault domain is formatted as https://<ServiceName>.<RandomGUID>.<AWSRegion>.cs.am\nazonlightsail.com, in which <ServiceName> is the name of your container service,\n <RandomGUID> is a randomly generated globally unique identifier of your contain\ner service in the AWS Region for your Lightsail account, and <AWSRegion> is the \nAWS Region in which the container service was created. The public endpoint of Li\nghtsail container services supports HTTPS only, and it does not support TCP or U\nDP traffic. Only one container can be the public endpoint for a service. So make\n sure that choose the container that is hosting the front-end of your applicatio\nn as the public endpoint while rest of the containers are internally accessible.\n You can use the default domain of your container service, or you can use your o\nwn custom domain (your registered domain name). For more information about using\n custom domains with your container services, see Enable and manage custom domai\nns for your container services. Private domain All container services also have \na private domain that is formatted as <ServiceName>.service.local, in which <Ser\nviceName> is the name of your container service. Use the private domain to acces\ns your container service from another one of your Lightsail resources in the sam\ne AWS Region as your service. The private domain is the only way to access your \ncontainer service if you don't specify a public endpoint in the deployment of yo\nur service. A default domain is generated for your container service even if you\n don't specify a public endpoint, but it will show a 404 No Such Service error m\nessage when you try to browse to it. To access a specific container using the pr\nivate domain of your container service, you must specify the open port of the co\nntainer that will accept your connection request. You do this by formatting the \ndomain of your request as <ServiceName>.service.local:<PortNumber>, in which <Se\nrviceName> is the name of your container service and <PortNumber> is the open po\nrt of the container that you wish to connect to. For example, if you create a de\nployment on your container service named container-service-1, and you specify a \nRedis container with port 6379 open, then you should format the domain of your r\nequest as container-service-1.service.local:6379. Custom domains and SSL/TLS cer\ntificates You can use up to 4 of your custom domains with your container service\n instead of using the default domain. For example, you can direct traffic for yo\nur custom domain, such as example.com, to the container in your deployment that \nis labeled as the public endpoint. To use your custom domains with your service,\n you must first request an SSL/TLS certificate for the domains that you want to \nuse. You must then validate the SSL/TLS certificate by adding a set of CNAME rec\nords to the DNS of your domains. After the SSL/TLS certificate is validated, you\n enable custom domains on your container service by attaching the valid SSL/TLS \ncertificate to your service. For more information see Create SSL/TLS certificate\ns for your Lightsail container services, Validate SSL/TLS certificates for your \nLightsail container services, and Enable and manage custom domains for your Ligh\ntsail container services. Container logs Every container in your container servi\nce generates a log that you can access to diagnose the operation of your contain\ners. The logs provide the stdout and stderr streams of processes that run inside\n the container. For more information, see View container service logs. Metrics M\nonitor the metrics of your container service to diagnose issues that may be a re\nsult of over-utilization. You can also monitor metrics to help you determine if \nyour service is under-provisioned or over-provisioned. For more information, see\n View container service metrics. Use Lightsail container services These are the \ngeneral steps to manage your Lightsail container service if you plan to push con\ntainer images from your local machine to your service, and use them in your depl\noyment: Create your container service in your Lightsail account. For more inform\nation, see Create Lightsail container services. Install software on your local m\nachine that you need to create your own container images and push them to your L\nightsail container service. For more information, see For more information, see \nthe following guides: Install software to manage container images for your Light\nsail container services Create container images for your Lightsail container ser\nvices Push and manage container images on your Lightsail container services Crea\nte a deployment in your container service that configures and launches your cont\nainers. For more information, see Create and manage deployments for your Lightsa\nil container services. View previous deployments for your container service. You\n can create a new deployment using a previous deployment version. For more infor\nmation, see View and manage deployment versions of your Lightsail container serv\nices. View the logs of containers on your container service. For more informatio\nn, see View the container logs of your Lightsail container services. Create an S\nSL/TLS certificate for the domains that you want to use with your containers. Fo\nr more information, see Create SSL/TLS certificates for your Lightsail container\n services. Validate the SSL/TLS certificate by adding records to the DNS of your\n domains. For more information, see Validate SSL/TLS certificates for your Light\nsail container services. Enable custom domains by attaching a valid SSL/TLS cert\nificate to your container service. For more information, see Enable and manage c\nustom domains for your Lightsail container services. Monitor the utilization met\nrics of your container service. For more information, see View container service\n metrics. (Optional) Scale the capacity of your container service vertically, by\n increasing its power specification, and horizontally, by increasing its scale s\npecification. For more information, see Change the capacity of your Lightsail co\nntainer services. Delete your container service if you're not using it to avoid \nincurring monthly charges. For more information, see Delete Lightsail container \nservices. These are the general steps to manage your Lightsail container service\n if you plan to use container images from a public registry in your deployment: \nCreate your container service in your Lightsail account. For more information, s\nee Create Lightsail container services. If you plan to use container images from\n a public registry, find container images from a public registry such as the Ama\nzon ECR Public Gallery. For more information about Amazon ECR Public, see What I\ns Amazon Elastic Container Registry Public? in the Amazon ECR Public User Guide.\n Create a deployment in your container service that configures and launches your\n containers. For more information, see Create and manage deployments for your Li\nghtsail container services. View previous deployments for your container service\n. You can create a new deployment using a previous deployment version. For more \ninformation, see View and manage deployment versions of your Lightsail container\n services. View the logs of containers on your container service. For more infor\nmation, see View the container logs of your Lightsail container services. Create\n an SSL/TLS certificate for the domains that you want to use with your container\ns. For more information, see Create SSL/TLS certificates for your Lightsail cont\nainer services. Validate the SSL/TLS certificate by adding records to the DNS of\n your domains. For more information, see Validate SSL/TLS certificates for your \nLightsail container services. Enable custom domains by attaching a valid SSL/TLS\n certificate to your container service. For more information, see Enable and man\nage custom domains for your Lightsail container services. Monitor the utilizatio\nn metrics of your container service. For more information, see View container se\nrvice metrics. (Optional) Scale the capacity of your container service verticall\ny, by increasing its power specification, and horizontally, by increasing its sc\nale specification. For more information, see Change the capacity of your Lightsa\nil container services. Delete your container service if you're not using it to a\nvoid incurring monthly charges. For more information, see Delete Lightsail conta\niner services. Javascript is disabled or is unavailable in your browser. To use \nthe Amazon Web Services Documentation, Javascript must be enabled. Please refer \nto your browser's Help pages for instructions. Document Conventions Upload files\n to bucket Create a container Did this page help you? - Yes Thanks for letting u\ns know we're doing a good job! If you've got a moment, please tell us what we di\nd right so we can do more of it. Did this page help you? - No Thanks for letting\n us know this page needs work. We're sorry we let you down. If you've got a mome\nnt, please tell us how we can make the documentation better.",
  "body": "",
  "code": "Map(code -> GetContainerServices, language -> code)Map(code -> serviceName, lang\nuage -> code)Map(code -> {    \\\"containerServices\\\": [        {            \\\"con\ntainerServiceName\\\": \\\"container-service-1\\\",            \\\"arn\\\": \\\"arn:aws:ligh\ntsail: :111122223333:ContainerService/a1b2c3d4-5678-90ab-cdef-EXAMPLE11111\\\",   \n         \\\"createdAt\\\": \\\"2024-01-01T00:00:00+00:00\\\",            \\\"location\\\": \n{                \\\"availabilityZone\\\": \\\"all\\\",                \\\"regionName\\\": \\\n\"us-west-2\\\"        },        .....}, language -> programlisting)Map(code -> {  \n  \\\"containerServices\\\": [        {            \\\"containerServiceName\\\": \\\"conta\niner-service-1\\\",            \\\"arn\\\": \\\"arn:aws:lightsail: :111122223333:Contain\nerService/a1b2c3d4-5678-90ab-cdef-EXAMPLE11111\\\",            \\\"createdAt\\\": \\\"20\n24-01-01T00:00:00+00:00\\\",            \\\"location\\\": {                \\\"availabil\nityZone\\\": \\\"all\\\",                \\\"regionName\\\": \\\"us-west-2\\\"        },      \n  .....}, language -> nohighlight)Map(code -> https://<ServiceName>.<RandomGUID>\n.<AWSRegion>.cs.amazonlightsail.com, language -> code)Map(code -> <ServiceName>,\n language -> replaceable)Map(code -> <RandomGUID>, language -> replaceable)Map(c\node -> <AWSRegion>, language -> replaceable)Map(code -> <ServiceName>, language \n-> replaceable)Map(code -> <RandomGUID>, language -> replaceable)Map(code -> <AW\nSRegion>, language -> replaceable)Map(code -> <ServiceName>.service.local, langu\nage -> code)Map(code -> <ServiceName>, language -> replaceable)Map(code -> <Serv\niceName>, language -> replaceable)Map(code -> 404 No Such Service, language -> c\node)Map(code -> <ServiceName>.service.local:<PortNumber>, language -> code)Map(c\node -> <ServiceName>, language -> replaceable)Map(code -> <PortNumber>, language\n -> replaceable)Map(code -> <ServiceName>, language -> replaceable)Map(code -> <\nPortNumber>, language -> replaceable)Map(code -> container-service-1, language -\n> code)Map(code -> 6379, language -> code)Map(code -> container-service-1.servic\ne.local:6379, language -> code)Map(code -> container-service-1, language -> repl\naceable)Map(code -> 6379, language -> replaceable)Map(code -> example.com, langu\nage -> code)",
  "table": ""
}
{
  "url": "https://docs.aws.amazon.com/apprunner/latest/dg/what-is-apprunner.html",
  "pageType": "DevGuidePage",
  "title": "What is AWS App Runner? - AWS App Runner AWSDocumentationApp RunnerDeveloper Gui\nde Who is App Runner for?Accessing App RunnerPricing for App RunnerWhat's next W\nhat is AWS App Runner? AWS App Runner is an AWS service that provides a fast, si\nmple, and cost-effective way to deploy from source code or a container image dir\nectly to a scalable and secure web application in the AWS Cloud. You don't need \nto learn new technologies, decide which compute service to use, or know how to p\nrovision and configure AWS resources. App Runner connects directly to your code \nor image repository. It provides an automatic integration and delivery pipeline \nwith fully managed operations, high performance, scalability, and security. Who \nis App Runner for? If you're a developer, you can use App Runner to simplify the\n process of deploying a new version of your code or image repository. For operat\nions teams, App Runner enables automatic deployments each time a commit is pushe\nd to the code repository or a new container image version is pushed to the image\n repository. Accessing App Runner You can define and configure your App Runner s\nervice deployments using any one of the following interfaces: App Runner console\n  Provides a web interface for managing your App Runner services. App Runner API\n  Provides a RESTful API for performing App Runner actions. For more information\n, see AWS App Runner API Reference. AWS Command Line Interface (AWS CLI)  Provid\nes commands for a broad set of AWS services, including Amazon VPC, and is suppor\nted on Windows, macOS, and Linux. For more information, see AWS Command Line Int\nerface. AWS SDKs  Provides language-specific APIs and takes care of many of the \nconnection details, such as calculating signatures, handling request retries, an\nd error handling. For more information, see AWS SDKs. Pricing for App Runner App\n Runner provides a cost-effective way to run your application. You only pay for \nresources that your App Runner service consumes. Your service scales down to few\ner compute instances when request traffic is lower. You have control over scalab\nility settings: the lowest and highest number of provisioned instances, and the \nhighest load an instance handles. For more information about App Runner automati\nc scaling, see Managing App Runner automatic scaling. For pricing information, s\nee AWS App Runner pricing. What's next Learn how to get started with App Runner \nin the following topics: Setting up for App Runner  Complete the prerequisite st\neps for using App Runner. Getting started with App Runner  Deploy your first app\nlication to App Runner. Javascript is disabled or is unavailable in your browser\n. To use the Amazon Web Services Documentation, Javascript must be enabled. Plea\nse refer to your browser's Help pages for instructions. Document Conventions Set\nting up Did this page help you? - Yes Thanks for letting us know we're doing a g\nood job! If you've got a moment, please tell us what we did right so we can do m\nore of it. Did this page help you? - No Thanks for letting us know this page nee\nds work. We're sorry we let you down. If you've got a moment, please tell us how\n we can make the documentation better.",
  "body": "",
  "code": "",
  "table": ""
}
{
  "url": "https://docs.aws.amazon.com/batch/latest/userguide/what-is-batch.html",
  "pageType": "UserGuidePage",
  "title": "What is AWS Batch? - AWS Batch AWSDocumentationAWS BatchUser Guide What is AWS B\natch? AWS Batch helps you to run batch computing workloads on the AWS Cloud. Bat\nch computing is a common way for developers, scientists, and engineers to access\n large amounts of compute resources. AWS Batch removes the undifferentiated heav\ny lifting of configuring and managing the required infrastructure, similar to tr\naditional batch computing software. This service can efficiently provision resou\nrces in response to jobs submitted in order to eliminate capacity constraints, r\neduce compute costs, and deliver results quickly. As a fully managed service, AW\nS Batch helps you to run batch computing workloads of any scale. AWS Batch autom\natically provisions compute resources and optimizes the workload distribution ba\nsed on the quantity and scale of the workloads. With AWS Batch, there's no need \nto install or manage batch computing software, so you can focus your time on ana\nlyzing results and solving problems. Topics Components of AWS Batch The AWS Batc\nh dashboard Javascript is disabled or is unavailable in your browser. To use the\n Amazon Web Services Documentation, Javascript must be enabled. Please refer to \nyour browser's Help pages for instructions. Document Conventions Components of A\nWS Batch Did this page help you? - Yes Thanks for letting us know we're doing a \ngood job! If you've got a moment, please tell us what we did right so we can do \nmore of it. Did this page help you? - No Thanks for letting us know this page ne\neds work. We're sorry we let you down. If you've got a moment, please tell us ho\nw we can make the documentation better.",
  "body": "",
  "code": "",
  "table": ""
}
{
  "url": "https://docs.aws.amazon.com/AmazonECS/latest/userguide/what-is-fargate.html",
  "pageType": "DevGuidePage",
  "title": "AWS Fargate for Amazon ECS - Amazon Elastic Container Service AWSDocumentationAm\nazon ECSDeveloper Guide WalkthroughsCapacity providersTask definitionsPlatform v\nersionsService load balancingUsage metrics AWS Fargate for Amazon ECS AWS Fargat\ne is a technology that you can use with Amazon ECS to run containers without hav\ning to manage servers or clusters of Amazon EC2 instances. With AWS Fargate, you\n no longer have to provision, configure, or scale clusters of virtual machines t\no run containers. This removes the need to choose server types, decide when to s\ncale your clusters, or optimize cluster packing. When you run your tasks and ser\nvices with the Fargate launch type, you package your application in containers, \nspecify the CPU and memory requirements, define networking and IAM policies, and\n launch the application. Each Fargate task has its own isolation boundary and do\nes not share the underlying kernel, CPU resources, memory resources, or elastic \nnetwork interface with another task. You configure your task definitions for Far\ngate by setting the requiresCompatibilities task definition parameter to FARGATE\n. For more information, see Launch types. Fargate offers platform versions for A\nmazon Linux 2 and Microsoft Windows 2019 Server Full and Core editions. Unless o\ntherwise specified, the information on this page applies to all Fargate platform\ns. This topic describes the different components of Fargate tasks and services, \nand calls out special considerations for using Fargate with Amazon ECS. For info\nrmation about the Regions that support Linux containers on Fargate, see Linux co\nntainers on AWS Fargate. For information about the Regions that support Windows \ncontainers on Fargate, see Windows containers on AWS Fargate. Walkthroughs For i\nnformation about how to get started using the console, see: Learn how to create \nan Amazon ECS Linux task for the Fargate launch type Learn how to create an Amaz\non ECS Windows task for the Fargate launch type For information about how to get\n started using the AWS CLI, see: Creating an Amazon ECS Linux task for the Farga\nte launch type with the AWS CLI Creating an Amazon ECS Windows task for the Farg\nate launch type with the AWS CLI Capacity providers The following capacity provi\nders are available: Fargate Fargate Spot - Run interruption tolerant Amazon ECS \ntasks at a discounted rate compared to the AWS Fargate price. Fargate Spot runs \ntasks on spare compute capacity. When AWS needs the capacity back, your tasks wi\nll be interrupted with a two-minute warning. For more information, see Amazon EC\nS clusters for the Fargate launch type . Task definitions Tasks that use the Far\ngate launch type don't support all of the Amazon ECS task definition parameters \nthat are available. Some parameters aren't supported at all, and others behave d\nifferently for Fargate tasks. For more information, see Task CPU and memory. Pla\ntform versions AWS Fargate platform versions are used to refer to a specific run\ntime environment for Fargate task infrastructure. It is a combination of the ker\nnel and container runtime versions. You select a platform version when you run a\n task or when you create a service to maintain a number of identical tasks. New \nrevisions of platform versions are released as the runtime environment evolves, \nfor example, if there are kernel or operating system updates, new features, bug \nfixes, or security updates. A Fargate platform version is updated by making a ne\nw platform version revision. Each task runs on one platform version revision dur\ning its lifecycle. If you want to use the latest platform version revision, then\n you must start a new task. A new task that runs on Fargate always runs on the l\natest revision of a platform version, ensuring that tasks are always started on \nsecure and patched infrastructure. If a security issue is found that affects an \nexisting platform version, AWS creates a new patched revision of the platform ve\nrsion and retires tasks running on the vulnerable revision. In some cases, you m\nay be notified that your tasks on Fargate have been scheduled for retirement. Fo\nr more information, see Task retirement and maintenance for AWS Fargate on Amazo\nn ECS . For more information see Fargate platform versions for Amazon ECS. Servi\nce load balancing Your Amazon ECS service on AWS Fargate can optionally be confi\ngured to use Elastic Load Balancing to distribute traffic evenly across the task\ns in your service. Amazon ECS services on AWS Fargate support the Application Lo\nad Balancer and Network Load Balancer load balancer types. Application Load Bala\nncers are used to route HTTP/HTTPS (or layer 7) traffic. Network Load Balancers \nare used to route TCP or UDP (or layer 4) traffic. For more information, see Use\n load balancing to distribute Amazon ECS service traffic. When you create a targ\net group for these services, you must choose ip as the target type, not instance\n. This is because tasks that use the awsvpc network mode are associated with an \nelastic network interface, not an Amazon EC2 instance. For more information, see\n Use load balancing to distribute Amazon ECS service traffic. Using a Network Lo\nad Balancer to route UDP traffic to your Amazon ECS on AWS Fargate tasks is only\n supported when using platform version 1.4 or later. Usage metrics You can use C\nloudWatch usage metrics to provide visibility into your accounts usage of resour\nces. Use these metrics to visualize your current service usage on CloudWatch gra\nphs and dashboards. AWS Fargate usage metrics correspond to AWS service quotas. \nYou can configure alarms that alert you when your usage approaches a service quo\nta. For more information about AWS Fargate service quotas, see AWS Fargate servi\nce quotas. For more information about AWS Fargate usage metrics, see AWS Fargate\n usage metrics. Javascript is disabled or is unavailable in your browser. To use\n the Amazon Web Services Documentation, Javascript must be enabled. Please refer\n to your browser's Help pages for instructions. Document Conventions Best practi\nces Security considerations for when to use the Fargate launch type Did this pag\ne help you? - Yes Thanks for letting us know we're doing a good job! If you've g\not a moment, please tell us what we did right so we can do more of it. Did this \npage help you? - No Thanks for letting us know this page needs work. We're sorry\n we let you down. If you've got a moment, please tell us how we can make the doc\numentation better.",
  "body": "",
  "code": "Map(code -> requiresCompatibilities, language -> code)Map(code -> FARGATE, langu\nage -> code)Map(code -> ip, language -> code)Map(code -> instance, language -> c\node)Map(code -> awsvpc, language -> code)",
  "table": ""
}
{
  "url": "https://docs.aws.amazon.com/AmazonECS/latest/developerguide/monitoring-fargate-usage.html",
  "pageType": "DevGuidePage",
  "title": "AWS Fargate usage metrics - Amazon Elastic Container Service AWSDocumentationAma\nzon ECSDeveloper Guide AWS Fargate usage metrics You can use CloudWatch usage me\ntrics to provide visibility into your accounts usage of resources. Use these met\nrics to visualize your current service usage on CloudWatch graphs and dashboards\n. AWS Fargate usage metrics correspond to AWS service quotas. You can configure \nalarms that alert you when your usage approaches a service quota. For more infor\nmation about Fargate service quotas, see AWS Fargate service quotas. AWS Fargate\n publishes the following metrics in the AWS/Usage namespace. Metric Description \nResourceCount The total number of the specified resource running on your account\n. The resource is defined by the dimensions associated with the metric. The foll\nowing dimensions are used to refine the usage metrics that are published by AWS \nFargate. Dimension Description Service The name of the AWS service containing th\ne resource. For AWS Fargate usage metrics, the value for this dimension is Farga\nte. Type The type of entity that is being reported. Currently, the only valid va\nlue for AWS Fargate usage metrics is Resource. Resource The type of resource tha\nt is running. The type of resource that is running. Currently, the only valid va\nlue for AWS Fargate usage metrics is vCPU which returns information about the ru\nnning instances. Class The class of resource being tracked. The class of resourc\ne being tracked. For AWS Fargate usage metrics with vCPU as the value of the Res\nource dimension, the valid values are Standard/OnDemand and Standard/Spot. You c\nan use the Service Quotas console to visualize your usage on a graph and configu\nre alarms that alert you when your AWS Fargate usage approaches a service quota.\n For information about how to create a CloudWatch alarm to notify you when you'r\ne close to a quota value threshold, see Service Quotas and Amazon CloudWatch ala\nrms in the Service Quotas User Guide . Javascript is disabled or is unavailable \nin your browser. To use the Amazon Web Services Documentation, Javascript must b\ne enabled. Please refer to your browser's Help pages for instructions. Document \nConventions Amazon ECS CloudWatch metrics Amazon ECS cluster reservation metrics\n Did this page help you? - Yes Thanks for letting us know we're doing a good job\n! If you've got a moment, please tell us what we did right so we can do more of \nit. Did this page help you? - No Thanks for letting us know this page needs work\n. We're sorry we let you down. If you've got a moment, please tell us how we can\n make the documentation better.",
  "body": "List(Map(Metric -> ResourceCount, Description -> The total number of the specifi\ned resource running on your account. The resource is defined by the dimensions a\nssociated with the metric.))List(Map(Dimension -> Service, Description -> The na\nme of the AWS service containing the resource. For AWS Fargate usage metrics, th\ne value for this dimension is Fargate.), Map(Dimension -> Type, Description -> T\nhe type of entity that is being reported. Currently, the only valid value for AW\nS Fargate usage metrics is Resource.), Map(Dimension -> Resource, Description ->\n The type of resource that is running. The type of resource that is running. Cur\nrently, the only valid value for AWS Fargate usage metrics is vCPU which returns\n information about the running instances.), Map(Dimension -> Class, Description \n-> The class of resource being tracked. The class of resource being tracked. For\n AWS Fargate usage metrics with vCPU as the value of the Resource dimension, the\n valid values are Standard/OnDemand and Standard/Spot.))",
  "code": "Map(code -> AWS/Usage, language -> code)Map(code -> ResourceCount, language -> c\node)Map(code -> Service, language -> code)Map(code -> Fargate, language -> code)\nMap(code -> Type, language -> code)Map(code -> Resource, language -> code)Map(co\nde -> Resource, language -> code)Map(code -> vCPU, language -> code)Map(code -> \nClass, language -> code)Map(code -> Standard/OnDemand, language -> code)Map(code\n -> Standard/Spot, language -> code)",
  "table": ""
}
{
  "url": "https://docs.aws.amazon.com/lambda/latest/dg/images-create.html",
  "pageType": "DevGuidePage",
  "title": "Create a Lambda function using a container image - AWS Lambda AWSDocumentationAW\nS LambdaDeveloper Guide RequirementsUsing an AWS base imageUsing an AWS OS-only \nbase imageUsing a non-AWS base imageRuntime interface clientsAmazon ECR permissi\nonsFunction lifecycle Create a Lambda function using a container image Your AWS \nLambda function's code consists of scripts or compiled programs and their depend\nencies. You use a deployment package to deploy your function code to Lambda. Lam\nbda supports two types of deployment packages: container images and .zip file ar\nchives. There are three ways to build a container image for a Lambda function: U\nsing an AWS base image for Lambda The AWS base images are preloaded with a langu\nage runtime, a runtime interface client to manage the interaction between Lambda\n and your function code, and a runtime interface emulator for local testing. Usi\nng an AWS OS-only base image AWS OS-only base images contain an Amazon Linux dis\ntribution and the runtime interface emulator. These images are commonly used to \ncreate container images for compiled languages, such as Go and Rust, and for a l\nanguage or language version that Lambda doesn't provide a base image for, such a\ns Node.js 19. You can also use OS-only base images to implement a custom runtime\n. To make the image compatible with Lambda, you must include a runtime interface\n client for your language in the image. Using a non-AWS base image You can use a\nn alternative base image from another container registry, such as Alpine Linux o\nr Debian. You can also use a custom image created by your organization. To make \nthe image compatible with Lambda, you must include a runtime interface client fo\nr your language in the image. Tip To reduce the time it takes for Lambda contain\ner functions to become active, see Use multi-stage builds in the Docker document\nation. To build efficient container images, follow the Best practices for writin\ng Dockerfiles. To create a Lambda function from a container image, build your im\nage locally and upload it to an Amazon Elastic Container Registry (Amazon ECR) r\nepository. Then, specify the repository URI when you create the function. The Am\nazon ECR repository must be in the same AWS Region as the Lambda function. You c\nan create a function using an image in a different AWS account, as long as the i\nmage is in the same Region as the Lambda function. For more information, see Ama\nzon ECR cross-account permissions. Note Lambda does not support Amazon ECR FIPS \nendpoints for container images. If your repository URI includes ecr-fips, you ar\ne using a FIPS endpoint. Example: 111122223333.dkr.ecr-fips.us-east-1.amazonaws.\ncom. This page explains the base image types and requirements for creating Lambd\na-compatible container images. Note You cannot change the deployment package typ\ne (.zip or container image) for an existing function. For example, you cannot co\nnvert a container image function to use a .zip file archive. You must create a n\new function. Topics Requirements Using an AWS base image for Lambda Using an AWS\n OS-only base image Using a non-AWS base image Runtime interface clients Amazon \nECR permissions Function lifecycle Requirements Install the AWS CLI version 2 an\nd the Docker CLI. Additionally, note the following requirements: The container i\nmage must implement the Using the Lambda runtime API for custom runtimes. The AW\nS open-source runtime interface clients implement the API. You can add a runtime\n interface client to your preferred base image to make it compatible with Lambda\n. The container image must be able to run on a read-only file system. Your funct\nion code can access a writable /tmp directory with between 512 MB and 10,240 MB,\n in 1-MB increments, of storage. The default Lambda user must be able to read al\nl the files required to run your function code. Lambda follows security best pra\nctices by defining a default Linux user with least-privileged permissions. This \nmeans that you don't need to specify a USER in your Dockerfile. Verify that your\n application code does not rely on files that other Linux users are restricted f\nrom running. Lambda supports only Linux-based container images. Lambda provides \nmulti-architecture base images. However, the image you build for your function m\nust target only one of the architectures. Lambda does not support functions that\n use multi-architecture container images. Using an AWS base image for Lambda You\n can use one of the AWS base images for Lambda to build the container image for \nyour function code. The base images are preloaded with a language runtime and ot\nher components required to run a container image on Lambda. You add your functio\nn code and dependencies to the base image and then package it as a container ima\nge. AWS periodically provides updates to the AWS base images for Lambda. If your\n Dockerfile includes the image name in the FROM property, your Docker client pul\nls the latest version of the image from the Amazon ECR repository. To use the up\ndated base image, you must rebuild your container image and update the function \ncode. The Node.js 20, Python 3.12, Java 21, .NET 8, Ruby 3.3, and later base ima\nges are based on the Amazon Linux 2023 minimal container image. Earlier base ima\nges use Amazon Linux 2. AL2023 provides several advantages over Amazon Linux 2, \nincluding a smaller deployment footprint and updated versions of libraries such \nas glibc. AL2023-based images use microdnf (symlinked as dnf) as the package man\nager instead of yum, which is the default package manager in Amazon Linux 2. mic\nrodnf is a standalone implementation of dnf. For a list of packages that are inc\nluded in AL2023-based images, refer to the Minimal Container columns in Comparin\ng packages installed on Amazon Linux 2023 Container Images. For more information\n about the differences between AL2023 and Amazon Linux 2, see Introducing the Am\nazon Linux 2023 runtime for AWS Lambda on the AWS Compute Blog. Note To run AL20\n23-based images locally, including with AWS Serverless Application Model (AWS SA\nM), you must use Docker version 20.10.10 or later. To build a container image us\ning an AWS base image, choose the instructions for your preferred language: Node\n.js TypeScript (uses a Node.js base image) Python Java Go .NET Ruby Using an AWS\n OS-only base image AWS OS-only base images contain an Amazon Linux distribution\n and the runtime interface emulator. These images are commonly used to create co\nntainer images for compiled languages, such as Go and Rust, and for a language o\nr language version that Lambda doesn't provide a base image for, such as Node.js\n 19. You can also use OS-only base images to implement a custom runtime. To make\n the image compatible with Lambda, you must include a runtime interface client f\nor your language in the image. Tags Runtime Operating system Dockerfile Deprecat\nion al2023 OS-only Runtime Amazon Linux 2023 Dockerfile for OS-only Runtime on G\nitHub Not scheduled al2 OS-only Runtime Amazon Linux 2 Dockerfile for OS-only Ru\nntime on GitHub Not scheduled Amazon Elastic Container Registry Public Gallery: \ngallery.ecr.aws/lambda/provided Using a non-AWS base image Lambda supports any i\nmage that conforms to one of the following image manifest formats: Docker image \nmanifest V2, schema 2 (used with Docker version 1.10 and newer) Open Container I\nnitiative (OCI) Specifications (v1.0.0 and up) Lambda supports a maximum uncompr\nessed image size of 10 GB, including all layers. Note To make the image compatib\nle with Lambda, you must include a runtime interface client for your language in\n the image. Runtime interface clients If you use an OS-only base image or an alt\nernative base image, you must include a runtime interface client in your image. \nThe runtime interface client must extend the Using the Lambda runtime API for cu\nstom runtimes, which manages the interaction between Lambda and your function co\nde. AWS provides open-source runtime interface clients for the following languag\nes: Node.js Python Java .NET Go Ruby Rust  The Rust runtime client is an experim\nental package. It is subject to change and intended only for evaluation purposes\n. If you're using a language that doesn't have an AWS-provided runtime interface\n client, you must create your own. Amazon ECR permissions Before you create a La\nmbda function from a container image, you must build the image locally and uploa\nd it to an Amazon ECR repository. When you create the function, specify the Amaz\non ECR repository URI. Make sure that the permissions for the user or role that \ncreates the function includes GetRepositoryPolicy and SetRepositoryPolicy. For e\nxample, use the IAM console to create a role with the following policy: {  \\\"Ver\nsion\\\": \\\"2012-10-17\\\",  \\\"Statement\\\": [    {      \\\"Sid\\\": \\\"VisualEditor0\\\", \n     \\\"Effect\\\": \\\"Allow\\\",      \\\"Action\\\": [        \\\"ecr:SetRepositoryPolicy\\\n\",        \\\"ecr:GetRepositoryPolicy\\\"      ],      \\\"Resource\\\": \\\"arn:aws:ecr:u\ns-east-1:111122223333:repository/hello-world\\\"    }  ]} Amazon ECR repository po\nlicies For a function in the same account as the container image in Amazon ECR, \nyou can add ecr:BatchGetImage and ecr:GetDownloadUrlForLayer permissions to your\n Amazon ECR repository policy. The following example shows the minimum policy: {\n        \\\"Sid\\\": \\\"LambdaECRImageRetrievalPolicy\\\",        \\\"Effect\\\": \\\"Allow\\\"\n,        \\\"Principal\\\": {          \\\"Service\\\": \\\"lambda.amazonaws.com\\\"        \n},        \\\"Action\\\": [          \\\"ecr:BatchGetImage\\\",          \\\"ecr:GetDownlo\nadUrlForLayer\\\"        ]    }   For more information about Amazon ECR repository\n permissions, see Private repository policies in the Amazon Elastic Container Re\ngistry User Guide. If the Amazon ECR repository does not include these permissio\nns, Lambda adds ecr:BatchGetImage and ecr:GetDownloadUrlForLayer to the containe\nr image repository permissions. Lambda can add these permissions only if the pri\nncipal calling Lambda has ecr:getRepositoryPolicy and ecr:setRepositoryPolicy pe\nrmissions. To view or edit your Amazon ECR repository permissions, follow the di\nrections in Setting a private repository policy statement in the Amazon Elastic \nContainer Registry User Guide. Amazon ECR cross-account permissions A different \naccount in the same region can create a function that uses a container image own\ned by your account. In the following example, your Amazon ECR repository permiss\nions policy needs the following statements to grant access to account number 123\n456789012. CrossAccountPermission  Allows account 123456789012 to create and upd\nate Lambda functions that use images from this ECR repository. LambdaECRImageCro\nssAccountRetrievalPolicy  Lambda will eventually set a function's state to inact\nive if it is not invoked for an extended period. This statement is required so t\nhat Lambda can retrieve the container image for optimization and caching on beha\nlf of the function owned by 123456789012. Example  Add cross-account permission \nto your repository {  \\\"Version\\\": \\\"2012-10-17\\\",  \\\"Statement\\\": [    {      \\\n\"Sid\\\": \\\"CrossAccountPermission\\\",      \\\"Effect\\\": \\\"Allow\\\",      \\\"Action\\\":\n [        \\\"ecr:BatchGetImage\\\",        \\\"ecr:GetDownloadUrlForLayer\\\"      ],  \n    \\\"Principal\\\": {        \\\"AWS\\\": \\\"arn:aws:iam::123456789012:root\\\"      }  \n  },    {      \\\"Sid\\\": \\\"LambdaECRImageCrossAccountRetrievalPolicy\\\",      \\\"Ef\nfect\\\": \\\"Allow\\\",      \\\"Action\\\": [        \\\"ecr:BatchGetImage\\\",        \\\"ecr\n:GetDownloadUrlForLayer\\\"      ],      \\\"Principal\\\": {        \\\"Service\\\": \\\"la\nmbda.amazonaws.com\\\"      },      \\\"Condition\\\": {        \\\"StringLike\\\": {     \n     \\\"aws:sourceARN\\\": \\\"arn:aws:lambda:us-east-1:123456789012:function:*\\\"    \n    }      }    }  ]} To give access to multiple accounts, you add the account I\nDs to the Principal list in the CrossAccountPermission policy and to the Conditi\non evaluation list in the LambdaECRImageCrossAccountRetrievalPolicy. If you are \nworking with multiple accounts in an AWS Organization, we recommend that you enu\nmerate each account ID in the ECR permissions policy. This approach aligns with \nthe AWS security best practice of setting narrow permissions in IAM policies. In\n addition to Lambda permissions, the user or role that creates the function must\n also have BatchGetImage and GetDownloadUrlForLayer permissions. Function lifecy\ncle After you upload a new or updated container image, Lambda optimizes the imag\ne before the function can process invocations. The optimization process can take\n a few seconds. The function remains in the Pending state until the process comp\nletes, when the state transitions to Active. You can't invoke the function until\n it reaches the Active state. If a function is not invoked for multiple weeks, L\nambda reclaims its optimized version, and the function transitions to the Inacti\nve state. To reactivate the function, you must invoke it. Lambda rejects the fir\nst invocation and the function enters the Pending state until Lambda re-optimize\ns the image. The function then returns to the Active state. Lambda periodically \nfetches the associated container image from the Amazon ECR repository. If the co\nrresponding container image no longer exists on Amazon ECR or permissions are re\nvoked, the function enters the Failed state, and Lambda returns a failure for an\ny function invocations. You can use the Lambda API to get information about a fu\nnction's state. For more information, see Lambda function states. Javascript is \ndisabled or is unavailable in your browser. To use the Amazon Web Services Docum\nentation, Javascript must be enabled. Please refer to your browser's Help pages \nfor instructions. Document Conventions Encryption Memory Did this page help you?\n - Yes Thanks for letting us know we're doing a good job! If you've got a moment\n, please tell us what we did right so we can do more of it. Did this page help y\nou? - No Thanks for letting us know this page needs work. We're sorry we let you\n down. If you've got a moment, please tell us how we can make the documentation \nbetter.",
  "body": "List(HashMap(Deprecation -> Not scheduled, Operating system -> Amazon Linux 2023\n, Dockerfile -> Dockerfile for OS-only Runtime on GitHub, Runtime -> OS-only Run\ntime, Tags -> al2023), HashMap(Deprecation -> Not scheduled, Operating system ->\n Amazon Linux 2, Dockerfile -> Dockerfile for OS-only Runtime on GitHub, Runtime\n -> OS-only Runtime, Tags -> al2))",
  "code": "Map(code -> ecr-fips, language -> code)Map(code -> 111122223333.dkr.ecr-fips.us-\neast-1.amazonaws.com, language -> code)Map(code -> /tmp, language -> code)Map(co\nde -> glibc, language -> code)Map(code -> microdnf, language -> code)Map(code ->\n dnf, language -> code)Map(code -> yum, language -> code)Map(code -> microdnf, l\nanguage -> code)Map(code -> dnf, language -> code)Map(code -> GetRepositoryPolic\ny, language -> code)Map(code -> SetRepositoryPolicy, language -> code)Map(code -\n> {  \\\"Version\\\": \\\"2012-10-17\\\",  \\\"Statement\\\": [    {      \\\"Sid\\\": \\\"VisualE\nditor0\\\",      \\\"Effect\\\": \\\"Allow\\\",      \\\"Action\\\": [        \\\"ecr:SetReposit\noryPolicy\\\",        \\\"ecr:GetRepositoryPolicy\\\"      ],      \\\"Resource\\\": \\\"arn\n:aws:ecr:us-east-1:111122223333:repository/hello-world\\\"    }  ]}, language -> p\nrogramlisting)Map(code -> {  \\\"Version\\\": \\\"2012-10-17\\\",  \\\"Statement\\\": [    {\n      \\\"Sid\\\": \\\"VisualEditor0\\\",      \\\"Effect\\\": \\\"Allow\\\",      \\\"Action\\\": [\n        \\\"ecr:SetRepositoryPolicy\\\",        \\\"ecr:GetRepositoryPolicy\\\"      ], \n     \\\"Resource\\\": \\\"arn:aws:ecr:us-east-1:111122223333:repository/hello-world\\\"\n    }  ]}, language -> nohighlight)Map(code -> us-east-1, language -> replaceabl\ne)Map(code -> :111122223333, language -> replaceable)Map(code -> hello-world, la\nnguage -> replaceable)Map(code -> ecr:BatchGetImage, language -> code)Map(code -\n> ecr:GetDownloadUrlForLayer, language -> code)Map(code -> {        \\\"Sid\\\": \\\"L\nambdaECRImageRetrievalPolicy\\\",        \\\"Effect\\\": \\\"Allow\\\",        \\\"Principal\n\\\": {          \\\"Service\\\": \\\"lambda.amazonaws.com\\\"        },        \\\"Action\\\"\n: [          \\\"ecr:BatchGetImage\\\",          \\\"ecr:GetDownloadUrlForLayer\\\"     \n   ]    }, language -> programlisting)Map(code -> {        \\\"Sid\\\": \\\"LambdaECRI\nmageRetrievalPolicy\\\",        \\\"Effect\\\": \\\"Allow\\\",        \\\"Principal\\\": {    \n      \\\"Service\\\": \\\"lambda.amazonaws.com\\\"        },        \\\"Action\\\": [      \n    \\\"ecr:BatchGetImage\\\",          \\\"ecr:GetDownloadUrlForLayer\\\"        ]    }\n, language -> )Map(code -> ecr:BatchGetImage, language -> code)Map(code -> ecr:G\netDownloadUrlForLayer, language -> code)Map(code -> ecr:getRepositoryPolicy, lan\nguage -> code)Map(code -> ecr:setRepositoryPolicy, language -> code)Map(code -> \n{  \\\"Version\\\": \\\"2012-10-17\\\",  \\\"Statement\\\": [    {      \\\"Sid\\\": \\\"CrossAcco\nuntPermission\\\",      \\\"Effect\\\": \\\"Allow\\\",      \\\"Action\\\": [        \\\"ecr:Bat\nchGetImage\\\",        \\\"ecr:GetDownloadUrlForLayer\\\"      ],      \\\"Principal\\\": \n{        \\\"AWS\\\": \\\"arn:aws:iam::123456789012:root\\\"      }    },    {      \\\"Si\nd\\\": \\\"LambdaECRImageCrossAccountRetrievalPolicy\\\",      \\\"Effect\\\": \\\"Allow\\\", \n     \\\"Action\\\": [        \\\"ecr:BatchGetImage\\\",        \\\"ecr:GetDownloadUrlForL\nayer\\\"      ],      \\\"Principal\\\": {        \\\"Service\\\": \\\"lambda.amazonaws.com\\\n\"      },      \\\"Condition\\\": {        \\\"StringLike\\\": {          \\\"aws:sourceAR\nN\\\": \\\"arn:aws:lambda:us-east-1:123456789012:function:*\\\"        }      }    }  \n]}, language -> programlisting)Map(code -> {  \\\"Version\\\": \\\"2012-10-17\\\",  \\\"St\natement\\\": [    {      \\\"Sid\\\": \\\"CrossAccountPermission\\\",      \\\"Effect\\\": \\\"A\nllow\\\",      \\\"Action\\\": [        \\\"ecr:BatchGetImage\\\",        \\\"ecr:GetDownloa\ndUrlForLayer\\\"      ],      \\\"Principal\\\": {        \\\"AWS\\\": \\\"arn:aws:iam::1234\n56789012:root\\\"      }    },    {      \\\"Sid\\\": \\\"LambdaECRImageCrossAccountRetr\nievalPolicy\\\",      \\\"Effect\\\": \\\"Allow\\\",      \\\"Action\\\": [        \\\"ecr:Batch\nGetImage\\\",        \\\"ecr:GetDownloadUrlForLayer\\\"      ],      \\\"Principal\\\": { \n       \\\"Service\\\": \\\"lambda.amazonaws.com\\\"      },      \\\"Condition\\\": {      \n  \\\"StringLike\\\": {          \\\"aws:sourceARN\\\": \\\"arn:aws:lambda:us-east-1:12345\n6789012:function:*\\\"        }      }    }  ]}, language -> nohighlight)Map(code \n-> 123456789012, language -> replaceable)Map(code -> us-east-1, language -> repl\naceable)Map(code -> 123456789012, language -> replaceable)Map(code -> CrossAccou\nntPermission, language -> code)Map(code -> LambdaECRImageCrossAccountRetrievalPo\nlicy, language -> code)Map(code -> BatchGetImage, language -> code)Map(code -> G\netDownloadUrlForLayer, language -> code)Map(code -> Pending, language -> code)Ma\np(code -> Active, language -> code)Map(code -> Active, language -> code)Map(code\n -> Inactive, language -> code)Map(code -> Pending, language -> code)Map(code ->\n Active, language -> code)Map(code -> Failed, language -> code)",
  "table": ""
}
{
  "url": "https://docs.aws.amazon.com/linux/al2023/ug/minimal-container.html",
  "pageType": "UserGuidePage",
  "title": "AL2023 Minimal container image - Amazon Linux 2023 AWSDocumentationAmazon LinuxU\nser Guide Minimal Container image sizeUsing the AL2023 Minimal Container image A\nL2023 Minimal container image Note The standard AL2023 container images are suit\nable for most use cases, and adapting to the minimal container image is likely t\no be more work than adapting to the AL2023 base container image. The AL2023 mini\nmal container image, introduced in AL2023.2, differs from the base container ima\nge because it contains only the bare minimum packages needed to install other pa\nckages. The minimal container image is designed to be a minimal set of packages,\n not a convenient set of packages . The AL2023 minimal container image is built \nfrom software components already available in AL2023. The key difference in the \nminimal container image is using microdnf to provide the dnf package manager rat\nher than the fully featured Python based dnf. This enables the minimal container\n image to be smaller with the trade-off of not having the full feature set of th\ne dnf package manager which is included in the AL2023 AMIs and base container im\nage. The AL2023 minimal container image forms the base of the provided.al2023 AW\nS Lambda runtime environment. For a detailed list of packages included in the mi\nnimal container image, see Comparing packages installed on Amazon Linux 2023 Con\ntainer Images. Minimal Container image size Because the AL2023 minimal container\n image contains fewer packages than the AL2023 base container image, it is also \nsignificantly smaller. The following table compares the container image options \nof current and past releases of Amazon Linux. Note Image Size is as-shown on Ama\nzon Linux on Amazon ECR Public Gallery. Image Version Image Size Note Amazon Lin\nux 1 (AL1) 2018.03.0.20230918.0 62.3MB x86-64 only Amazon Linux 2 2.0.20230926.0\n 64.2MB aarch64 is 1.6MB larger than x86-64 Amazon Linux 2023 base container ima\nge 2023.2.20231002.0 52.4MB Amazon Linux 2023 minimal container image 2023.2.202\n31002.0-minimal 35.2MB Using the AL2023 Minimal Container image The AL2023 minim\nal container image is available on ECR and the 2023-minimal tag will always poin\nt to the latest AL2023 based minimal container image, while the minimal tag may \nbe updated to a newer version of Amazon Linux than AL2023. You can pull these ta\ngs using docker with the following example: $ docker pull public.ecr.aws/amazonl\ninux/amazonlinux:minimal $ docker pull public.ecr.aws/amazonlinux/amazonlinux:20\n23-minimal The following example shows a Dockerfile that takes the minimal conta\niner image and installs GCC on top of it : FROM public.ecr.aws/amazonlinux/amazo\nnlinux:2023-minimalRUN dnf install -y gcc && dnf clean all Javascript is disable\nd or is unavailable in your browser. To use the Amazon Web Services Documentatio\nn, Javascript must be enabled. Please refer to your browser's Help pages for ins\ntructions. Document Conventions AL2023 Base Container Image Building bare-bones \nAL2023 container images Did this page help you? - Yes Thanks for letting us know\n we're doing a good job! If you've got a moment, please tell us what we did righ\nt so we can do more of it. Did this page help you? - No Thanks for letting us kn\now this page needs work. We're sorry we let you down. If you've got a moment, pl\nease tell us how we can make the documentation better.",
  "body": "List(Map(Image -> Amazon Linux 1 (AL1), Version -> 2018.03.0.20230918.0, Image S\nize -> 62.3MB, Note -> x86-64 only), Map(Image -> Amazon Linux 2, Version -> 2.0\n.20230926.0, Image Size -> 64.2MB, Note -> aarch64 is 1.6MB larger than x86-64),\n Map(Image -> Amazon Linux 2023 base container image, Version -> 2023.2.20231002\n.0, Image Size -> 52.4MB, Note -> ), Map(Image -> Amazon Linux 2023 minimal cont\nainer image, Version -> 2023.2.20231002.0-minimal, Image Size -> 35.2MB, Note ->\n ))",
  "code": "Map(code -> microdnf, language -> code)Map(code -> dnf, language -> code)Map(cod\ne -> dnf, language -> code)Map(code -> dnf, language -> code)Map(code -> provide\nd.al2023, language -> code)Map(code -> x86-64, language -> code)Map(code -> aarc\nh64, language -> code)Map(code -> x86-64, language -> code)Map(code -> 2023-mini\nmal, language -> code)Map(code -> minimal, language -> code)Map(code -> docker, \nlanguage -> code)Map(code -> $ docker pull public.ecr.aws/amazonlinux/amazonlinu\nx:minimal, language -> programlisting)Map(code -> $ docker pull public.ecr.aws/a\nmazonlinux/amazonlinux:minimal, language -> sh)Map(code -> $, language -> prompt\n)Map(code -> docker pull public.ecr.aws/amazonlinux/amazonlinux:minimal, languag\ne -> userinput)Map(code -> $ docker pull public.ecr.aws/amazonlinux/amazonlinux:\n2023-minimal, language -> programlisting)Map(code -> $ docker pull public.ecr.aw\ns/amazonlinux/amazonlinux:2023-minimal, language -> sh)Map(code -> $, language -\n> prompt)Map(code -> docker pull public.ecr.aws/amazonlinux/amazonlinux:2023-min\nimal, language -> userinput)Map(code -> Dockerfile, language -> code)Map(code ->\n FROM public.ecr.aws/amazonlinux/amazonlinux:2023-minimalRUN dnf install -y gcc \n&& dnf clean all, language -> programlisting)Map(code -> FROM public.ecr.aws/ama\nzonlinux/amazonlinux:2023-minimalRUN dnf install -y gcc && dnf clean all, langua\nge -> dockerfile)",
  "table": ""
}
{
  "url": "https://docs.aws.amazon.com/linux/al2023/ug/al2023-container-image-types.html",
  "pageType": "UserGuidePage",
  "title": "Comparing packages installed on Amazon Linux 2023 Container Images - Amazon Linu\nx 2023 AWSDocumentationAmazon LinuxUser Guide Comparing packages installed on Am\nazon Linux 2023 Container Images A comparison of the RPMs present on the AL2023 \nbase container image compared with the RPMs present on the AL2023 minimal contai\nner image. Package Container Minimal Container alternatives 1.15 1.15 amazon-lin\nux-repo-cdn 2023.6.20241031 2023.6.20241031 audit-libs 3.0.6 3.0.6 basesystem 11\n 11 bash 5.2.15 5.2.15 bzip2-libs 1.0.8 1.0.8 ca-certificates 2023.2.68 2023.2.6\n8 coreutils-single 8.32 8.32 crypto-policies 20220428 20220428 curl-minimal 8.5.\n0 8.5.0 dnf 4.14.0 dnf-data 4.14.0 4.14.0 elfutils-default-yama-scope 0.188 elfu\ntils-libelf 0.188 elfutils-libs 0.188 expat 2.5.0 file-libs 5.39 5.39 filesystem\n 3.14 3.14 gawk 5.1.0 5.1.0 gdbm-libs 1.19 glib2 2.74.7 2.74.7 glibc 2.34 2.34 g\nlibc-common 2.34 2.34 glibc-minimal-langpack 2.34 2.34 gmp 6.2.1 6.2.1 gnupg2-mi\nnimal 2.3.7 2.3.7 gobject-introspection 1.73.0 gpgme 1.15.1 1.15.1 grep 3.8 3.8 \njson-c 0.14 0.14 keyutils-libs 1.6.3 1.6.3 krb5-libs 1.21.3 1.21.3 libacl 2.3.1 \n2.3.1 libarchive 3.7.4 3.7.4 libassuan 2.5.5 2.5.5 libattr 2.5.1 2.5.1 libblkid \n2.37.4 2.37.4 libcap 2.48 2.48 libcap-ng 0.8.2 0.8.2 libcom_err 1.46.5 1.46.5 li\nbcomps 0.1.20 libcurl-minimal 8.5.0 8.5.0 libdnf 0.69.0 0.69.0 libffi 3.4.4 3.4.\n4 libgcc 11.4.1 11.4.1 libgcrypt 1.10.2 1.10.2 libgomp 11.4.1 libgpg-error 1.42 \n1.42 libidn2 2.3.2 2.3.2 libmodulemd 2.13.0 2.13.0 libmount 2.37.4 2.37.4 libngh\nttp2 1.59.0 1.59.0 libpeas 1.32.0 libpsl 0.21.1 0.21.1 librepo 1.14.5 1.14.5 lib\nreport-filesystem 2.15.2 2.15.2 libselinux 3.4 3.4 libsepol 3.4 3.4 libsigsegv 2\n.13 2.13 libsmartcols 2.37.4 2.37.4 libsolv 0.7.22 0.7.22 libstdc++ 11.4.1 11.4.\n1 libtasn1 4.19.0 4.19.0 libunistring 0.9.10 0.9.10 libuuid 2.37.4 2.37.4 libver\nto 0.3.2 0.3.2 libxcrypt 4.4.33 libxml2 2.10.4 2.10.4 libyaml 0.2.5 0.2.5 libzst\nd 1.5.5 1.5.5 lua-libs 5.4.4 5.4.4 lz4-libs 1.9.4 1.9.4 microdnf 3.10.0 microdnf\n-dnf 3.10.0 mpfr 4.1.0 4.1.0 ncurses-base 6.2 6.2 ncurses-libs 6.2 6.2 npth 1.6 \n1.6 openssl-libs 3.0.8 3.0.8 p11-kit 0.24.1 0.24.1 p11-kit-trust 0.24.1 0.24.1 p\ncre2 10.40 10.40 pcre2-syntax 10.40 10.40 popt 1.18 1.18 publicsuffix-list-dafsa\n 20240212 20240212 python3 3.9.16 python3-dnf 4.14.0 python3-gpg 1.15.1 python3-\nhawkey 0.69.0 python3-libcomps 0.1.20 python3-libdnf 0.69.0 python3-libs 3.9.16 \npython3-pip-wheel 21.3.1 python3-rpm 4.16.1.3 python3-setuptools-wheel 59.6.0 re\nadline 8.1 8.1 rpm 4.16.1.3 4.16.1.3 rpm-build-libs 4.16.1.3 rpm-libs 4.16.1.3 4\n.16.1.3 rpm-sign-libs 4.16.1.3 sed 4.8 4.8 setup 2.13.7 2.13.7 sqlite-libs 3.40.\n0 3.40.0 system-release 2023.6.20241031 2023.6.20241031 tzdata 2024a xz-libs 5.2\n.5 5.2.5 yum 4.14.0 zlib 1.2.11 1.2.11 Javascript is disabled or is unavailable \nin your browser. To use the Amazon Web Services Documentation, Javascript must b\ne enabled. Please refer to your browser's Help pages for instructions. Document \nConventions Building bare-bones AL2023 container images AL2023 Minimal AMI compa\nred to container images Did this page help you? - Yes Thanks for letting us know\n we're doing a good job! If you've got a moment, please tell us what we did righ\nt so we can do more of it. Did this page help you? - No Thanks for letting us kn\now this page needs work. We're sorry we let you down. If you've got a moment, pl\nease tell us how we can make the documentation better.",
  "body": "List(Map(Package -> alternatives, Container -> 1.15, Minimal Container -> 1.15),\n Map(Package -> amazon-linux-repo-cdn, Container -> 2023.6.20241031, Minimal Con\ntainer -> 2023.6.20241031), Map(Package -> audit-libs, Container -> 3.0.6, Minim\nal Container -> 3.0.6), Map(Package -> basesystem, Container -> 11, Minimal Cont\nainer -> 11), Map(Package -> bash, Container -> 5.2.15, Minimal Container -> 5.2\n.15), Map(Package -> bzip2-libs, Container -> 1.0.8, Minimal Container -> 1.0.8)\n, Map(Package -> ca-certificates, Container -> 2023.2.68, Minimal Container -> 2\n023.2.68), Map(Package -> coreutils-single, Container -> 8.32, Minimal Container\n -> 8.32), Map(Package -> crypto-policies, Container -> 20220428, Minimal Contai\nner -> 20220428), Map(Package -> curl-minimal, Container -> 8.5.0, Minimal Conta\niner -> 8.5.0), Map(Package -> dnf, Container -> 4.14.0, Minimal Container -> ),\n Map(Package -> dnf-data, Container -> 4.14.0, Minimal Container -> 4.14.0), Map\n(Package -> elfutils-default-yama-scope, Container -> 0.188, Minimal Container -\n> ), Map(Package -> elfutils-libelf, Container -> 0.188, Minimal Container -> ),\n Map(Package -> elfutils-libs, Container -> 0.188, Minimal Container -> ), Map(P\nackage -> expat, Container -> 2.5.0, Minimal Container -> ), Map(Package -> file\n-libs, Container -> 5.39, Minimal Container -> 5.39), Map(Package -> filesystem,\n Container -> 3.14, Minimal Container -> 3.14), Map(Package -> gawk, Container -\n> 5.1.0, Minimal Container -> 5.1.0), Map(Package -> gdbm-libs, Container -> 1.1\n9, Minimal Container -> ), Map(Package -> glib2, Container -> 2.74.7, Minimal Co\nntainer -> 2.74.7), Map(Package -> glibc, Container -> 2.34, Minimal Container -\n> 2.34), Map(Package -> glibc-common, Container -> 2.34, Minimal Container -> 2.\n34), Map(Package -> glibc-minimal-langpack, Container -> 2.34, Minimal Container\n -> 2.34), Map(Package -> gmp, Container -> 6.2.1, Minimal Container -> 6.2.1), \nMap(Package -> gnupg2-minimal, Container -> 2.3.7, Minimal Container -> 2.3.7), \nMap(Package -> gobject-introspection, Container -> , Minimal Container -> 1.73.0\n), Map(Package -> gpgme, Container -> 1.15.1, Minimal Container -> 1.15.1), Map(\nPackage -> grep, Container -> 3.8, Minimal Container -> 3.8), Map(Package -> jso\nn-c, Container -> 0.14, Minimal Container -> 0.14), Map(Package -> keyutils-libs\n, Container -> 1.6.3, Minimal Container -> 1.6.3), Map(Package -> krb5-libs, Con\ntainer -> 1.21.3, Minimal Container -> 1.21.3), Map(Package -> libacl, Container\n -> 2.3.1, Minimal Container -> 2.3.1), Map(Package -> libarchive, Container -> \n3.7.4, Minimal Container -> 3.7.4), Map(Package -> libassuan, Container -> 2.5.5\n, Minimal Container -> 2.5.5), Map(Package -> libattr, Container -> 2.5.1, Minim\nal Container -> 2.5.1), Map(Package -> libblkid, Container -> 2.37.4, Minimal Co\nntainer -> 2.37.4), Map(Package -> libcap, Container -> 2.48, Minimal Container \n-> 2.48), Map(Package -> libcap-ng, Container -> 0.8.2, Minimal Container -> 0.8\n.2), Map(Package -> libcom_err, Container -> 1.46.5, Minimal Container -> 1.46.5\n), Map(Package -> libcomps, Container -> 0.1.20, Minimal Container -> ), Map(Pac\nkage -> libcurl-minimal, Container -> 8.5.0, Minimal Container -> 8.5.0), Map(Pa\nckage -> libdnf, Container -> 0.69.0, Minimal Container -> 0.69.0), Map(Package \n-> libffi, Container -> 3.4.4, Minimal Container -> 3.4.4), Map(Package -> libgc\nc, Container -> 11.4.1, Minimal Container -> 11.4.1), Map(Package -> libgcrypt, \nContainer -> 1.10.2, Minimal Container -> 1.10.2), Map(Package -> libgomp, Conta\niner -> 11.4.1, Minimal Container -> ), Map(Package -> libgpg-error, Container -\n> 1.42, Minimal Container -> 1.42), Map(Package -> libidn2, Container -> 2.3.2, \nMinimal Container -> 2.3.2), Map(Package -> libmodulemd, Container -> 2.13.0, Mi\nnimal Container -> 2.13.0), Map(Package -> libmount, Container -> 2.37.4, Minima\nl Container -> 2.37.4), Map(Package -> libnghttp2, Container -> 1.59.0, Minimal \nContainer -> 1.59.0), Map(Package -> libpeas, Container -> , Minimal Container -\n> 1.32.0), Map(Package -> libpsl, Container -> 0.21.1, Minimal Container -> 0.21\n.1), Map(Package -> librepo, Container -> 1.14.5, Minimal Container -> 1.14.5), \nMap(Package -> libreport-filesystem, Container -> 2.15.2, Minimal Container -> 2\n.15.2), Map(Package -> libselinux, Container -> 3.4, Minimal Container -> 3.4), \nMap(Package -> libsepol, Container -> 3.4, Minimal Container -> 3.4), Map(Packag\ne -> libsigsegv, Container -> 2.13, Minimal Container -> 2.13), Map(Package -> l\nibsmartcols, Container -> 2.37.4, Minimal Container -> 2.37.4), Map(Package -> l\nibsolv, Container -> 0.7.22, Minimal Container -> 0.7.22), Map(Package -> libstd\nc++, Container -> 11.4.1, Minimal Container -> 11.4.1), Map(Package -> libtasn1,\n Container -> 4.19.0, Minimal Container -> 4.19.0), Map(Package -> libunistring,\n Container -> 0.9.10, Minimal Container -> 0.9.10), Map(Package -> libuuid, Cont\nainer -> 2.37.4, Minimal Container -> 2.37.4), Map(Package -> libverto, Containe\nr -> 0.3.2, Minimal Container -> 0.3.2), Map(Package -> libxcrypt, Container -> \n4.4.33, Minimal Container -> ), Map(Package -> libxml2, Container -> 2.10.4, Min\nimal Container -> 2.10.4), Map(Package -> libyaml, Container -> 0.2.5, Minimal C\nontainer -> 0.2.5), Map(Package -> libzstd, Container -> 1.5.5, Minimal Containe\nr -> 1.5.5), Map(Package -> lua-libs, Container -> 5.4.4, Minimal Container -> 5\n.4.4), Map(Package -> lz4-libs, Container -> 1.9.4, Minimal Container -> 1.9.4),\n Map(Package -> microdnf, Container -> , Minimal Container -> 3.10.0), Map(Packa\nge -> microdnf-dnf, Container -> , Minimal Container -> 3.10.0), Map(Package -> \nmpfr, Container -> 4.1.0, Minimal Container -> 4.1.0), Map(Package -> ncurses-ba\nse, Container -> 6.2, Minimal Container -> 6.2), Map(Package -> ncurses-libs, Co\nntainer -> 6.2, Minimal Container -> 6.2), Map(Package -> npth, Container -> 1.6\n, Minimal Container -> 1.6), Map(Package -> openssl-libs, Container -> 3.0.8, Mi\nnimal Container -> 3.0.8), Map(Package -> p11-kit, Container -> 0.24.1, Minimal \nContainer -> 0.24.1), Map(Package -> p11-kit-trust, Container -> 0.24.1, Minimal\n Container -> 0.24.1), Map(Package -> pcre2, Container -> 10.40, Minimal Contain\ner -> 10.40), Map(Package -> pcre2-syntax, Container -> 10.40, Minimal Container\n -> 10.40), Map(Package -> popt, Container -> 1.18, Minimal Container -> 1.18), \nMap(Package -> publicsuffix-list-dafsa, Container -> 20240212, Minimal Container\n -> 20240212), Map(Package -> python3, Container -> 3.9.16, Minimal Container ->\n ), Map(Package -> python3-dnf, Container -> 4.14.0, Minimal Container -> ), Map\n(Package -> python3-gpg, Container -> 1.15.1, Minimal Container -> ), Map(Packag\ne -> python3-hawkey, Container -> 0.69.0, Minimal Container -> ), Map(Package ->\n python3-libcomps, Container -> 0.1.20, Minimal Container -> ), Map(Package -> p\nython3-libdnf, Container -> 0.69.0, Minimal Container -> ), Map(Package -> pytho\nn3-libs, Container -> 3.9.16, Minimal Container -> ), Map(Package -> python3-pip\n-wheel, Container -> 21.3.1, Minimal Container -> ), Map(Package -> python3-rpm,\n Container -> 4.16.1.3, Minimal Container -> ), Map(Package -> python3-setuptool\ns-wheel, Container -> 59.6.0, Minimal Container -> ), Map(Package -> readline, C\nontainer -> 8.1, Minimal Container -> 8.1), Map(Package -> rpm, Container -> 4.1\n6.1.3, Minimal Container -> 4.16.1.3), Map(Package -> rpm-build-libs, Container \n-> 4.16.1.3, Minimal Container -> ), Map(Package -> rpm-libs, Container -> 4.16.\n1.3, Minimal Container -> 4.16.1.3), Map(Package -> rpm-sign-libs, Container -> \n4.16.1.3, Minimal Container -> ), Map(Package -> sed, Container -> 4.8, Minimal \nContainer -> 4.8), Map(Package -> setup, Container -> 2.13.7, Minimal Container \n-> 2.13.7), Map(Package -> sqlite-libs, Container -> 3.40.0, Minimal Container -\n> 3.40.0), Map(Package -> system-release, Container -> 2023.6.20241031, Minimal \nContainer -> 2023.6.20241031), Map(Package -> tzdata, Container -> 2024a, Minima\nl Container -> ), Map(Package -> xz-libs, Container -> 5.2.5, Minimal Container \n-> 5.2.5), Map(Package -> yum, Container -> 4.14.0, Minimal Container -> ), Map(\nPackage -> zlib, Container -> 1.2.11, Minimal Container -> 1.2.11))",
  "code": "Map(code -> alternatives, language -> code)Map(code -> amazon-linux-repo-cdn, la\nnguage -> code)Map(code -> audit-libs, language -> code)Map(code -> basesystem, \nlanguage -> code)Map(code -> bash, language -> code)Map(code -> bzip2-libs, lang\nuage -> code)Map(code -> ca-certificates, language -> code)Map(code -> coreutils\n-single, language -> code)Map(code -> crypto-policies, language -> code)Map(code\n -> curl-minimal, language -> code)Map(code -> dnf, language -> code)Map(code ->\n dnf-data, language -> code)Map(code -> elfutils-default-yama-scope, language ->\n code)Map(code -> elfutils-libelf, language -> code)Map(code -> elfutils-libs, l\nanguage -> code)Map(code -> expat, language -> code)Map(code -> file-libs, langu\nage -> code)Map(code -> filesystem, language -> code)Map(code -> gawk, language \n-> code)Map(code -> gdbm-libs, language -> code)Map(code -> glib2, language -> c\node)Map(code -> glibc, language -> code)Map(code -> glibc-common, language -> co\nde)Map(code -> glibc-minimal-langpack, language -> code)Map(code -> gmp, languag\ne -> code)Map(code -> gnupg2-minimal, language -> code)Map(code -> gobject-intro\nspection, language -> code)Map(code -> gpgme, language -> code)Map(code -> grep,\n language -> code)Map(code -> json-c, language -> code)Map(code -> keyutils-libs\n, language -> code)Map(code -> krb5-libs, language -> code)Map(code -> libacl, l\nanguage -> code)Map(code -> libarchive, language -> code)Map(code -> libassuan, \nlanguage -> code)Map(code -> libattr, language -> code)Map(code -> libblkid, lan\nguage -> code)Map(code -> libcap, language -> code)Map(code -> libcap-ng, langua\nge -> code)Map(code -> libcom_err, language -> code)Map(code -> libcomps, langua\nge -> code)Map(code -> libcurl-minimal, language -> code)Map(code -> libdnf, lan\nguage -> code)Map(code -> libffi, language -> code)Map(code -> libgcc, language \n-> code)Map(code -> libgcrypt, language -> code)Map(code -> libgomp, language ->\n code)Map(code -> libgpg-error, language -> code)Map(code -> libidn2, language -\n> code)Map(code -> libmodulemd, language -> code)Map(code -> libmount, language \n-> code)Map(code -> libnghttp2, language -> code)Map(code -> libpeas, language -\n> code)Map(code -> libpsl, language -> code)Map(code -> librepo, language -> cod\ne)Map(code -> libreport-filesystem, language -> code)Map(code -> libselinux, lan\nguage -> code)Map(code -> libsepol, language -> code)Map(code -> libsigsegv, lan\nguage -> code)Map(code -> libsmartcols, language -> code)Map(code -> libsolv, la\nnguage -> code)Map(code -> libstdc++, language -> code)Map(code -> libtasn1, lan\nguage -> code)Map(code -> libunistring, language -> code)Map(code -> libuuid, la\nnguage -> code)Map(code -> libverto, language -> code)Map(code -> libxcrypt, lan\nguage -> code)Map(code -> libxml2, language -> code)Map(code -> libyaml, languag\ne -> code)Map(code -> libzstd, language -> code)Map(code -> lua-libs, language -\n> code)Map(code -> lz4-libs, language -> code)Map(code -> microdnf, language -> \ncode)Map(code -> microdnf-dnf, language -> code)Map(code -> mpfr, language -> co\nde)Map(code -> ncurses-base, language -> code)Map(code -> ncurses-libs, language\n -> code)Map(code -> npth, language -> code)Map(code -> openssl-libs, language -\n> code)Map(code -> p11-kit, language -> code)Map(code -> p11-kit-trust, language\n -> code)Map(code -> pcre2, language -> code)Map(code -> pcre2-syntax, language \n-> code)Map(code -> popt, language -> code)Map(code -> publicsuffix-list-dafsa, \nlanguage -> code)Map(code -> python3, language -> code)Map(code -> python3-dnf, \nlanguage -> code)Map(code -> python3-gpg, language -> code)Map(code -> python3-h\nawkey, language -> code)Map(code -> python3-libcomps, language -> code)Map(code \n-> python3-libdnf, language -> code)Map(code -> python3-libs, language -> code)M\nap(code -> python3-pip-wheel, language -> code)Map(code -> python3-rpm, language\n -> code)Map(code -> python3-setuptools-wheel, language -> code)Map(code -> read\nline, language -> code)Map(code -> rpm, language -> code)Map(code -> rpm-build-l\nibs, language -> code)Map(code -> rpm-libs, language -> code)Map(code -> rpm-sig\nn-libs, language -> code)Map(code -> sed, language -> code)Map(code -> setup, la\nnguage -> code)Map(code -> sqlite-libs, language -> code)Map(code -> system-rele\nase, language -> code)Map(code -> tzdata, language -> code)Map(code -> xz-libs, \nlanguage -> code)Map(code -> yum, language -> code)Map(code -> zlib, language ->\n code)",
  "table": ""
}
{
  "url": "https://docs.aws.amazon.com/AmazonECR/latest/userguide/repository-policies.html",
  "pageType": "UserGuidePage",
  "title": "Private repository policies in Amazon ECR - Amazon ECR AWSDocumentationAmazon EC\nRUser Guide Repository policies vs IAM policies Private repository policies in A\nmazon ECR Amazon ECR uses resource-based permissions to control access to reposi\ntories. Resource-based permissions let you specify which users or roles have acc\ness to a repository and what actions they can perform on the repository. By defa\nult, only the AWS account that created the repository has access to the reposito\nry. You can apply a repository policy that allows additional access to your repo\nsitory. Topics Repository policies vs IAM policies Private repository policy exa\nmples in Amazon ECR Setting a private repository policy statement in Amazon ECR \nRepository policies vs IAM policies Amazon ECR repository policies are a subset \nof IAM policies that are scoped for, and specifically used for, controlling acce\nss to individual Amazon ECR repositories. IAM policies are generally used to app\nly permissions for the entire Amazon ECR service but can also be used to control\n access to specific resources as well. Both Amazon ECR repository policies and I\nAM policies are used when determining which actions a specific user or role may \nperform on a repository. If a user or role is allowed to perform an action throu\ngh a repository policy but is denied permission through an IAM policy (or vice v\nersa) then the action will be denied. A user or role only needs to be allowed pe\nrmission for an action through either a repository policy or an IAM policy but n\not both for the action to be allowed. Important Amazon ECR requires that users h\nave permission to make calls to the ecr:GetAuthorizationToken API through an IAM\n policy before they can authenticate to a registry and push or pull any images f\nrom any Amazon ECR repository. Amazon ECR provides several managed IAM policies \nto control user access at varying levels; for more information, see Amazon Elast\nic Container Registry Identity-based policy examples. You can use either of thes\ne policy types to control access to your repositories, as shown in the following\n examples. This example shows an Amazon ECR repository policy, which allows for \na specific user to describe the repository and the images within the repository.\n {    \\\"Version\\\": \\\"2012-10-17\\\",    \\\"Statement\\\": [        {            \\\"Sid\n\\\": \\\"ECRRepositoryPolicy\\\",            \\\"Effect\\\": \\\"Allow\\\",            \\\"Prin\ncipal\\\": {\\\"AWS\\\": \\\"arn:aws:iam::account-id:user/username\\\"},            \\\"Acti\non\\\": [                \\\"ecr:DescribeImages\\\",                \\\"ecr:DescribeRepo\nsitories\\\"            ]        }    ]} This example shows an IAM policy that ach\nieves the same goal as above, by scoping the policy to a repository (specified b\ny the full ARN of the repository) using the resource parameter. For more informa\ntion about Amazon Resource Name (ARN) format, see Resources. {    \\\"Version\\\": \\\n\"2012-10-17\\\",    \\\"Statement\\\": [        {            \\\"Sid\\\": \\\"AllowDescribeR\nepoImage\\\",            \\\"Effect\\\": \\\"Allow\\\",            \\\"Action\\\": [          \n      \\\"ecr:DescribeImages\\\",                \\\"ecr:DescribeRepositories\\\"       \n     ],            \\\"Resource\\\": [\\\"arn:aws:ecr:region:account-id:repository/rep\nository-name\\\"]        }    ]} Javascript is disabled or is unavailable in your \nbrowser. To use the Amazon Web Services Documentation, Javascript must be enable\nd. Please refer to your browser's Help pages for instructions. Document Conventi\nons Deleting a repository Repository policy examples Did this page help you? - Y\nes Thanks for letting us know we're doing a good job! If you've got a moment, pl\nease tell us what we did right so we can do more of it. Did this page help you? \n- No Thanks for letting us know this page needs work. We're sorry we let you dow\nn. If you've got a moment, please tell us how we can make the documentation bett\ner.",
  "body": "",
  "code": "Map(code -> ecr:GetAuthorizationToken, language -> code)Map(code -> {    \\\"Versi\non\\\": \\\"2012-10-17\\\",    \\\"Statement\\\": [        {            \\\"Sid\\\": \\\"ECRRepo\nsitoryPolicy\\\",            \\\"Effect\\\": \\\"Allow\\\",            \\\"Principal\\\": {\\\"A\nWS\\\": \\\"arn:aws:iam::account-id:user/username\\\"},            \\\"Action\\\": [      \n          \\\"ecr:DescribeImages\\\",                \\\"ecr:DescribeRepositories\\\"   \n         ]        }    ]}, language -> programlisting)Map(code -> {    \\\"Version\n\\\": \\\"2012-10-17\\\",    \\\"Statement\\\": [        {            \\\"Sid\\\": \\\"ECRReposi\ntoryPolicy\\\",            \\\"Effect\\\": \\\"Allow\\\",            \\\"Principal\\\": {\\\"AWS\n\\\": \\\"arn:aws:iam::account-id:user/username\\\"},            \\\"Action\\\": [        \n        \\\"ecr:DescribeImages\\\",                \\\"ecr:DescribeRepositories\\\"     \n       ]        }    ]}, language -> JSON)Map(code -> account-id, language -> re\nplaceable)Map(code -> username, language -> replaceable)Map(code -> {    \\\"Versi\non\\\": \\\"2012-10-17\\\",    \\\"Statement\\\": [        {            \\\"Sid\\\": \\\"AllowDe\nscribeRepoImage\\\",            \\\"Effect\\\": \\\"Allow\\\",            \\\"Action\\\": [   \n             \\\"ecr:DescribeImages\\\",                \\\"ecr:DescribeRepositories\\\"\n            ],            \\\"Resource\\\": [\\\"arn:aws:ecr:region:account-id:reposit\nory/repository-name\\\"]        }    ]}, language -> programlisting)Map(code -> { \n   \\\"Version\\\": \\\"2012-10-17\\\",    \\\"Statement\\\": [        {            \\\"Sid\\\":\n \\\"AllowDescribeRepoImage\\\",            \\\"Effect\\\": \\\"Allow\\\",            \\\"Acti\non\\\": [                \\\"ecr:DescribeImages\\\",                \\\"ecr:DescribeRepo\nsitories\\\"            ],            \\\"Resource\\\": [\\\"arn:aws:ecr:region:account-\nid:repository/repository-name\\\"]        }    ]}, language -> JSON)Map(code -> re\ngion, language -> replaceable)Map(code -> account-id, language -> replaceable)Ma\np(code -> repository-name, language -> replaceable)",
  "table": ""
}
{
  "url": "https://docs.aws.amazon.com/AmazonECR/latest/userguide/set-repository-policy.html",
  "pageType": "UserGuidePage",
  "title": "Setting a private repository policy statement in Amazon ECR - Amazon ECR AWSDocu\nmentationAmazon ECRUser Guide Setting a private repository policy statement in A\nmazon ECR You can add an access policy statement to a repository in the AWS Mana\ngement Console by following the steps below. You can add multiple policy stateme\nnts per repository. For example policies, see Private repository policy examples\n in Amazon ECR. Important Amazon ECR requires that users have permission to make\n calls to the ecr:GetAuthorizationToken API through an IAM policy before they ca\nn authenticate to a registry and push or pull any images from any Amazon ECR rep\nository. Amazon ECR provides several managed IAM policies to control user access\n at varying levels; for more information, see Amazon Elastic Container Registry \nIdentity-based policy examples. To set a repository policy statement Open the Am\nazon ECR console at https://console.aws.amazon.com/ecr/repositories. From the na\nvigation bar, choose the Region that contains the repository to set a policy sta\ntement on. In the navigation pane, choose Repositories. On the Repositories page\n, choose the repository to set a policy statement on to view the contents of the\n repository. From the repository image list view, in the navigation pane, choose\n Permissions, Edit. Note If you don't see the Permissions option in the navigati\non pane, ensure that you are in the repository image list view. On the Edit perm\nissions page, choose Add statement. For Statement name, enter a name for the sta\ntement. For Effect, choose whether the policy statement will result in an allow \nor an explicit deny. For Principal, choose the scope to apply the policy stateme\nnt to. For more information, see AWS JSON Policy Elements: Principal in the IAM \nUser Guide. You can apply the statement to all authenticated AWS users by select\ning the Everyone (*) check box. For Service principal, specify the service princ\nipal name (for example, ecs.amazonaws.com) to apply the statement to a specific \nservice. For AWS Account IDs, specify an AWS account number (for example, 111122\n223333) to apply the statement to all users under a specific AWS account. Multip\nle accounts can be specified by using a comma delimited list. Important The acco\nunt you are granting permissions to must have the Region you are creating the re\npository policy in enabled, otherwise an error will occur. For IAM Entities, sel\nect the roles or users under your AWS account to apply the statement to. Note Fo\nr more complicated repository policies that are not currently supported in the A\nWS Management Console, you can apply the policy with the set-repository-policy A\nWS CLI command. For Actions, choose the scope of the Amazon ECR API operations t\nhat the policy statement should apply to from the list of individual API operati\nons. When you are finished, choose Save to set the policy. Repeat the previous s\ntep for each repository policy to add. Javascript is disabled or is unavailable \nin your browser. To use the Amazon Web Services Documentation, Javascript must b\ne enabled. Please refer to your browser's Help pages for instructions. Document \nConventions Repository policy examples Tagging a repository Did this page help y\nou? - Yes Thanks for letting us know we're doing a good job! If you've got a mom\nent, please tell us what we did right so we can do more of it. Did this page hel\np you? - No Thanks for letting us know this page needs work. We're sorry we let \nyou down. If you've got a moment, please tell us how we can make the documentati\non better.",
  "body": "",
  "code": "Map(code -> ecr:GetAuthorizationToken, language -> code)Map(code -> ecs.amazonaw\ns.com, language -> code)Map(code -> 111122223333, language -> code)",
  "table": ""
}
{
  "url": "https://docs.aws.amazon.com/ROSA/latest/userguide/getting-started.html",
  "pageType": "UserGuidePage",
  "title": "Get started with ROSA - Red Hat OpenShift Service on AWS AWSDocumentationRed Hat\n OpenShift Service on AWSUser Guide Get started with ROSA Red Hat OpenShift Serv\nice on AWS (ROSA) is a managed service that you can use to build, scale, and dep\nloy containerized applications with the Red Hat OpenShift enterprise Kubernetes \nplatform on AWS. You can use the following guides to create your first ROSA clus\nter, grant user access, deploy your first application, and learn how to revoke u\nser access and delete your cluster. Create a ROSA with HCP cluster using the ROS\nA CLI - Create your first ROSA with HCP cluster using AWS STS and the ROSA CLI. \nCreate a ROSA classic cluster that uses AWS PrivateLink - Create your first ROSA\n classic cluster using AWS PrivateLink. Create a ROSA classic cluster using the \nROSA CLI - Create your first ROSA classic cluster using AWS STS and the ROSA CLI\n. Javascript is disabled or is unavailable in your browser. To use the Amazon We\nb Services Documentation, Javascript must be enabled. Please refer to your brows\ner's Help pages for instructions. Document Conventions Architecture Set up Did t\nhis page help you? - Yes Thanks for letting us know we're doing a good job! If y\nou've got a moment, please tell us what we did right so we can do more of it. Di\nd this page help you? - No Thanks for letting us know this page needs work. We'r\ne sorry we let you down. If you've got a moment, please tell us how we can make \nthe documentation better.",
  "body": "",
  "code": "",
  "table": ""
}
{
  "url": "https://docs.aws.amazon.com/lambda/latest/dg/welcome.html",
  "pageType": "DevGuidePage",
  "title": "What is AWS Lambda? - AWS Lambda AWSDocumentationAWS LambdaDeveloper Guide When \nto use LambdaKey features What is AWS Lambda? You can use AWS Lambda to run code\n without provisioning or managing servers. Lambda runs your code on a high-avail\nability compute infrastructure and performs all of the administration of the com\npute resources, including server and operating system maintenance, capacity prov\nisioning and automatic scaling, and logging. With Lambda, all you need to do is \nsupply your code in one of the language runtimes that Lambda supports. You organ\nize your code into Lambda functions. The Lambda service runs your function only \nwhen needed and scales automatically. You only pay for the compute time that you\n consumethere is no charge when your code is not running. For more information, \nsee AWS Lambda Pricing. Tip To learn how to build serverless solutions, check ou\nt the Serverless Developer Guide. When to use Lambda Lambda is an ideal compute \nservice for application scenarios that need to scale up rapidly, and scale down \nto zero when not in demand. For example, you can use Lambda for: File processing\n: Use Amazon Simple Storage Service (Amazon S3) to trigger Lambda data processin\ng in real time after an upload. Stream processing: Use Lambda and Amazon Kinesis\n to process real-time streaming data for application activity tracking, transact\nion order processing, clickstream analysis, data cleansing, log filtering, index\ning, social media analysis, Internet of Things (IoT) device data telemetry, and \nmetering. Web applications: Combine Lambda with other AWS services to build powe\nrful web applications that automatically scale up and down and run in a highly a\nvailable configuration across multiple data centers. IoT backends: Build serverl\ness backends using Lambda to handle web, mobile, IoT, and third-party API reques\nts. Mobile backends: Build backends using Lambda and Amazon API Gateway to authe\nnticate and process API requests. Use AWS Amplify to easily integrate with your \niOS, Android, Web, and React Native frontends. When using Lambda, you are respon\nsible only for your code. Lambda manages the compute fleet that offers a balance\n of memory, CPU, network, and other resources to run your code. Because Lambda m\nanages these resources, you cannot log in to compute instances or customize the \noperating system on provided runtimes. Lambda performs operational and administr\native activities on your behalf, including managing capacity, monitoring, and lo\ngging your Lambda functions. Key features The following key features help you de\nvelop Lambda applications that are scalable, secure, and easily extensible: Envi\nronment variables Use environment variables to adjust your function's behavior w\nithout updating code. Versions Manage the deployment of your functions with vers\nions, so that, for example, a new function can be used for beta testing without \naffecting users of the stable production version. Container images Create a cont\nainer image for a Lambda function by using an AWS provided base image or an alte\nrnative base image so that you can reuse your existing container tooling or depl\noy larger workloads that rely on sizable dependencies, such as machine learning.\n Layers Package libraries and other dependencies to reduce the size of deploymen\nt archives and makes it faster to deploy your code. Lambda extensions Augment yo\nur Lambda functions with tools for monitoring, observability, security, and gove\nrnance. Function URLs Add a dedicated HTTP(S) endpoint to your Lambda function. \nResponse streaming Configure your Lambda function URLs to stream response payloa\nds back to clients from Node.js functions, to improve time to first byte (TTFB) \nperformance or to return larger payloads. Concurrency and scaling controls Apply\n fine-grained control over the scaling and responsiveness of your production app\nlications. Code signing Verify that only approved developers publish unaltered, \ntrusted code in your Lambda functions Private networking Create a private networ\nk for resources such as databases, cache instances, or internal services. File s\nystem access Configure a function to mount an Amazon Elastic File System (Amazon\n EFS) to a local directory, so that your function code can access and modify sha\nred resources safely and at high concurrency. Lambda SnapStart for Java Improve \nstartup performance for Java runtimes by up to 10x at no extra cost, typically w\nith no changes to your function code. Javascript is disabled or is unavailable i\nn your browser. To use the Amazon Web Services Documentation, Javascript must be\n enabled. Please refer to your browser's Help pages for instructions. Document C\nonventions Create your first function Did this page help you? - Yes Thanks for l\netting us know we're doing a good job! If you've got a moment, please tell us wh\nat we did right so we can do more of it. Did this page help you? - No Thanks for\n letting us know this page needs work. We're sorry we let you down. If you've go\nt a moment, please tell us how we can make the documentation better.",
  "body": "",
  "code": "",
  "table": ""
}
{
  "url": "https://docs.aws.amazon.com/lightsail/latest/userguide/what-is-amazon-lightsail.html",
  "pageType": "UserGuidePage",
  "title": "What is Amazon Lightsail? - Amazon Lightsail AWSDocumentationAmazon LightsailUse\nr Guide FeaturesWho is Lightsail for?Access LightsailGet startedRelated services\nEstimates, billing, and cost optimization What is Amazon Lightsail? Amazon Light\nsail is the easiest way to get started with Amazon Web Services (AWS) for anyone\n who needs to build websites or web applications. It includes everything you nee\nd to launch your project quicklyinstances (virtual private servers), container s\nervices, managed databases, content delivery network (CDN) distributions, load b\nalancers, SSD-based block storage, static IP addresses, DNS management of regist\nered domains, and resource snapshots (backups)for a low, predictable monthly pri\nce. Lightsail also offers Amazon Lightsail for Research. With Lightsail for Rese\narch, academics and researchers can create powerful virtual computers in the AWS\n Cloud. These virtual computers come with pre-installed research applications, s\nuch as RStudio and Scilab. For more information see the Amazon Lightsail for Res\nearch User Guide. Topics Features Who is Lightsail for? Access Lightsail Get sta\nrted Related services Estimates, billing, and cost optimization Features of Ligh\ntsail Lightsail provides the following high-level features: Instances Lightsail \noffers virtual private servers (instances) that are easy to set up and backed by\n the power and reliability of AWS. You can launch your website, web application,\n or project in minutes, and manage your instance from the intuitive Lightsail co\nnsole or API. As youre creating your instance, you'll click-to-launch a simple o\nperating system (OS), a pre-configured application, or development stacksuch as \nWordPress, Windows, Plesk, LAMP, Nginx, and more. Every Lightsail instance comes\n with a built-in firewall that you can use to allow or restrict traffic to your \ninstances based on source IP, port, and protocol. Learn more Containers Run and \nsecurely access containerized applications in the cloud. A container is a standa\nrd unit of software that packages code and its dependencies together so the appl\nication runs quickly and reliably from one computing environment to another. Lea\nrn more Load balancers Route web traffic across your instances so your websites \nand applications can accommodate variations in traffic, protected against outage\ns, and deliver a seamless visitor experience. Learn more Managed databases Light\nsail offers a fully configured MySQL or PostgreSQL databases plan that includes \nmemory, processing, storage, and transfer allowance. With Lightsail managed data\nbases, you can easily scale your databases independently of your virtual servers\n, improve application availability, or run standalone databases in the cloud. Le\narn more Block and object storage Lightsail offers both block and object storage\n. You can scale your storage quickly and easily with highly available SSD-backed\n storage for your Linux or Windows virtual server. Learn more With Lightsail Obj\nect storage buckets, you can store and retrieve objects, at any time, from anywh\nere on the internet. You can also host static content on the cloud. Learn more C\nDN distributions Lightsail enables content delivery network (CDN) distributions,\n which are built on the same infrastructure as Amazon CloudFront. You can easily\n distribute your content to a global audience by setting up proxy servers across\n the world, so that your users can access your website geographically closer to \nthem, thus reducing latency. Learn more Access to AWS services Lightsail uses a \nfocused set of features like instances, managed databases and load balancers to \nmake it easier to get started. But that doesn't mean you're limited to those opt\nions you can integrate your Lightsail project with some of the 90+ other service\ns in AWS through Amazon VPC peering. Learn more For more details about Lightsail\n, see Amazon Lightsail. Who is Lightsail for? Lightsail is for everyone. You can\n choose an image for your Lightsail instance that jump starts your project so yo\nu don't have to spend as much time installing software or frameworks. If you're \nan individual developer or hobbyist working on a personal project, Lightsail can\n help you deploy and manage basic cloud resources. You might also be interested \nin learning or experimenting with cloud services, such as virtual machines, doma\nins or networking. Lightsail provides a quick way to get started. Lightsail has \nimages with base operating systems, development stacks like LAMP, LEMP (Nginx), \nand SQL Server Express, and applications like WordPress, Drupal, and Magento. Fo\nr more detailed information about the software installed on each image, see Choo\nse a Lightsail instance image. As your project grows, you can add block storage \ndisks and attach them to your Lightsail instance. You can take snapshots of thes\ne instances and disks and easily create new instances from those snapshots. You \ncan also peer your VPC so that your Lightsail instances can use other AWS resour\nces outside of Lightsail. You can also create a Lightsail load balancer and atta\nch target instances to create a highly available application. You can also confi\ngure your load balancer to handle encrypted (HTTPS) traffic, session persistence\n, health checking, and more. Access Lightsail You can create and manage your Lig\nhtsail resources with the following interfaces: Amazon Lightsail console A simpl\ne web interface to create and manage Lightsail instances and resources. If you'v\ne signed up for an AWS account, you can access the Lightsail console by signing \ninto the AWS Management Console and selecting Lightsail from the console home pa\nge. AWS Command Line Interface Enables you to interact with AWS services using c\nommands in your command-line shell. It is supported on Windows, Mac, and Linux. \nFor more information about the AWS CLI , see AWS Command Line Interface User Gui\nde. You can find the Lightsail commands in the Amazon Lightsail API Reference. A\nWS Tools for PowerShell A set of PowerShell modules that are built on the functi\nonality exposed by the AWS SDK for .NET. The Tools for PowerShell enable you to \nscript operations on your AWS resources from the PowerShell command line. To get\n started, see the AWS Tools for Windows PowerShell User Guide. You can find the \ncmdlets for Lightsail, in the AWS Tools for PowerShell Cmdlet Reference. Query A\nPI Lightsail provides a Query API. These requests are HTTP or HTTPS requests tha\nt use the HTTP verbs GET or POST and a Query parameter named Action. For more in\nformation about the API actions for Lightsail, see Actions in the Amazon Lightsa\nil API Reference. AWS SDKs If you prefer to build applications using language-sp\necific APIs instead of submitting a request over HTTP or HTTPS, AWS provides lib\nraries, sample code, tutorials, and other resources for software developers. The\nse libraries provide basic functions that automate tasks such as cryptographical\nly signing your requests, retrying requests, and handling error responses, makin\ng it easier for you to get started. For more information, see Tools to Build on \nAWS. Get started with Lightsail After you set up to use Lightsail, you can walk \nthrough Getting started with virtual private servers on Lightsail to launch, con\nnect to, and clean up an instance. Related services You can provision Lightsail \nresources, such as instances and disks, directly using Lightsail. In addition, y\nou can provision resources using other AWS services, such as the following: Amaz\non EC2 Provides resizeable computing capacityliterally, servers in Amazon's data\n centersthat you use to build and host your software systems. To compare Lightsa\nil and Amazon EC2, see Amazon Lightsail or Amazon EC2. Amazon EC2 Auto Scaling H\nelps ensure you have the correct number of Amazon EC2 instances available to han\ndle the load for your application. Elastic Load Balancing Automatically distribu\nte incoming application traffic across multiple instances. Amazon Relational Dat\nabase Service (Amazon RDS) Set up, operate, and scale a managed relational datab\nase in the cloud. Amazon Elastic Container Service (Amazon ECS) Deploy, manage, \nand scale containerized applications on a cluster of Amazon EC2 instances. Estim\nates, billing, and cost optimization To create estimates for your AWS use cases,\n use the AWS Pricing Calculator. To see your bill, go to the Billing and Cost Ma\nnagement Dashboard in the AWS Billing and Cost Management console. Your bill con\ntains links to usage reports that provide details about your bill. To learn more\n about AWS account billing, see AWS Billing and Cost Management User Guide. If y\nou have questions concerning AWS billing, accounts, and events, contact AWS Supp\nort. You can optimize the cost, security, and performance of your AWS environmen\nt using AWS Trusted Advisor. Javascript is disabled or is unavailable in your br\nowser. To use the Amazon Web Services Documentation, Javascript must be enabled.\n Please refer to your browser's Help pages for instructions. Document Convention\ns Set up Did this page help you? - Yes Thanks for letting us know we're doing a \ngood job! If you've got a moment, please tell us what we did right so we can do \nmore of it. Did this page help you? - No Thanks for letting us know this page ne\neds work. We're sorry we let you down. If you've got a moment, please tell us ho\nw we can make the documentation better.",
  "body": "",
  "code": "Map(code -> Action, language -> code)",
  "table": ""
}
{
  "url": "https://docs.aws.amazon.com/lightsail-for-research/latest/ug/what-is-lfr.html",
  "pageType": "UserGuidePage",
  "title": "What is Amazon Lightsail for Research? - Amazon Lightsail for Research AWSDocume\nntationAmazon Lightsail for ResearchUser Guide PricingAvailability What is Amazo\nn Lightsail for Research? With Amazon Lightsail for Research, academics and rese\narchers can create powerful virtual computers in the Amazon Web Services (AWS) C\nloud. These virtual computers come with pre-installed research applications, suc\nh as RStudio and Scilab. With Lightsail for Research, you can upload data direct\nly from a web browser to begin your work. You can create and delete your virtual\n computers at any time, which gives you on-demand access to powerful computing r\nesources. You pay only for as long as you need the virtual computer. Lightsail f\nor Research offers budgeting controls that can automatically stop your computer \nwhen it reaches a preconfigured cost limit, so you don't have to worry about ove\nrage charges. Everything you do in the Lightsail for Research console is backed \nby a publicly available API. Learn how to install and use the AWS CLI and API fo\nr Amazon Lightsail. Pricing With Lightsail for Research, you pay only for the re\nsources you create and use. For more information, see Lightsail for Research pri\ncing. Availability Lightsail for Research is available in the same AWS Regions a\ns Amazon Lightsail, with the exception of the US East (N. Virginia) Region. Ligh\ntsail for Research also uses the same endpoints as Lightsail. To view the curren\ntly supported AWS Regions and endpoints for Lightsail, see Lightsail Endpoints a\nnd Quotas in the AWS General Reference. Javascript is disabled or is unavailable\n in your browser. To use the Amazon Web Services Documentation, Javascript must \nbe enabled. Please refer to your browser's Help pages for instructions. Document\n Conventions Setting up Did this page help you? - Yes Thanks for letting us know\n we're doing a good job! If you've got a moment, please tell us what we did righ\nt so we can do more of it. Did this page help you? - No Thanks for letting us kn\now this page needs work. We're sorry we let you down. If you've got a moment, pl\nease tell us how we can make the documentation better.",
  "body": "",
  "code": "",
  "table": ""
}
{
  "url": "https://docs.aws.amazon.com/cloud-map/latest/dg/what-is-cloud-map.html",
  "pageType": "DevGuidePage",
  "title": "What Is AWS Cloud Map? - AWS Cloud Map AWSDocumentationAWS Cloud MapDeveloper Gu\nide Components of AWS Cloud MapAccessing AWS Cloud MapAWS Identity and Access Ma\nnagementAWS Cloud Map PricingAWS Cloud Map and AWS Cloud Compliance What Is AWS \nCloud Map? AWS Cloud Map is a fully managed solution that you can use to map log\nical names to the backend services and resources that your applications depend o\nn. It also helps your applications discover resources using one of the AWS SDKs,\n RESTful API calls, or DNS queries. AWS Cloud Map serves only healthy resources,\n which can be Amazon DynamoDB (DynamoDB) tables, Amazon Simple Queue Service (Am\nazon SQS) queues, any higher-level application services that are built using Ama\nzon Elastic Compute Cloud (Amazon EC2) instances or Amazon Elastic Container Ser\nvice (Amazon ECS) tasks, and more. Components of AWS Cloud Map Namespace To get \nstarted, you first create a AWS Cloud Map namespace that functions as a way to g\nroup services for an application. A namespace identifies the name that you want \nto use to locate your resources and also specifies how you want to locate resour\nces: using AWS Cloud Map DiscoverInstances API calls, DNS queries in a VPC, or p\nublic DNS queries. In most cases, a namespace contains all the services for an a\npplication, such as a billing application. For more information, see AWS Cloud M\nap namespaces. Service After creating a namespace, you create an AWS Cloud Map s\nervice for each type of resource for which you want to use AWS Cloud Map to loca\nte endpoints. For example, you might create services for web servers and databas\ne servers. A service is a template that AWS Cloud Map uses when your application\n adds another resource, such as another web server. If you chose to locate resou\nrces using DNS when you created the namespace, a service contains information ab\nout the types of records that you want to use to locate the web server. A servic\ne also indicates whether you want to check the health of the resource and whethe\nr you want to use Amazon Route 53 health checks or a third-party health checker.\n For more information, see AWS Cloud Map services. Service instance When your ap\nplication adds a resource, you can call the AWS Cloud Map RegisterInstance API a\nction in the code, which creates a AWS Cloud Map service instance in a service. \nThe service instance contains information about how your application can locate \nthe resource, whether using DNS or using the AWS Cloud Map DiscoverInstances API\n action. When your application needs to connect to a resource, it calls Discover\nInstances or utilizes public or private DNS queries by specifying the namespace \nand service that are associated with the resource. AWS Cloud Map returns informa\ntion about how to locate one or more resources. If you specified health checking\n when you created the service, AWS Cloud Map returns only healthy instances. For\n more information, see AWS Cloud Map service instances. Accessing AWS Cloud Map \nYou can access AWS Cloud Map in the following ways: AWS Management Console  The \nprocedures throughout this guide explain how to use the AWS Management Console t\no perform tasks. AWS SDKs  If you're using a programming language that AWS provi\ndes an SDK for, you can use an SDK to access AWS Cloud Map. SDKs simplify authen\ntication, integrate easily with your development environment, and provide access\n to AWS Cloud Map commands. For more information, see Tools for Amazon Web Servi\nces. AWS Command Line Interface  For more information, see Get started with the \nAWS CLI in the AWS Command Line Interface User Guide. AWS Tools for Windows Powe\nrShell  For more information, see Get started with the AWS Tools for Windows Pow\nerShell in the AWS Tools for Windows PowerShell User Guide. AWS Cloud Map API  I\nf you're using a programming language that an SDK isn't available for, see the A\nWS Cloud Map API Reference for information about API actions and about how to ma\nke API requests. Note IPv6 Client Support  As of June 22nd, 2023 in all new regi\nons, any commands sent to AWS Cloud Map from IPv6 clients are routed to a new du\nalstack endpoint (servicediscovery.<region>.api.aws). AWS Cloud Map IPv6-only ne\ntworks are reachable for both legacy (servicediscovery.<region>.amazonaws.com) a\nnd dualstack endpoints in the following regions that were released prior to June\n 22nd, 2023: US East (Ohio)  us-east-2 US East (N. Virginia)  us-east-1 US West \n(N. California)  us-west-1 US West (Oregon)  us-west-2 Africa (Cape Town)  af-so\nuth-1 Asia Pacific (Hong Kong)  ap-east-1 Asia Pacific (Hyderabad)  ap-south-2 A\nsia Pacific (Jakarta)  ap-southeast-3 Asia Pacific (Melbourne)  ap-southeast-4 A\nsia Pacific (Mumbai)  ap-south-1 Asia Pacific (Osaka)  ap-northeast-3 Asia Pacif\nic (Seoul)  ap-northeast-2 Asia Pacific (Singapore)  ap-southeast-1 Asia Pacific\n (Sydney)  ap-southeast-2 Asia Pacific (Tokyo)  ap-northeast-1 Canada (Central) \n ca-central-1 Europe (Frankfurt)  eu-central-1 Europe (Ireland)  eu-west-1 Europ\ne (London)  eu-west-2 Europe (Milan)  eu-south-1 Europe (Paris)  eu-west-3 Europ\ne (Spain)  eu-south-2 Europe (Stockholm)  eu-north-1 Europe (Zurich)  eu-central\n-2 Middle East (Bahrain)  me-south-1 Middle East (UAE)  me-central-1 South Ameri\nca (So Paulo)  sa-east-1 AWS GovCloud (US-East)  us-gov-east-1 AWS GovCloud (US-\nWest)  us-gov-west-1 AWS Identity and Access Management AWS Cloud Map integrates\n with AWS Identity and Access Management (IAM), a service that your organization\n can use to do the following actions: Create users and groups under your organiz\nation's AWS account Share your AWS account resources among the users in the acco\nunt in an efficient manner Assign unique security credentials to each user Granu\nlarly control user access to services and resources For example, you can use IAM\n with AWS Cloud Map to control which users in your AWS account can create a new \nnamespace or register instances. For general information about IAM, see the foll\nowing resources: Identity and Access Management for AWS Cloud Map AWS Identity a\nnd Access Management IAM User Guide AWS Cloud Map Pricing AWS Cloud Map pricing \nis based on resources that you register in the service registry and API calls th\nat you make to discover them. With AWS Cloud Map there are no upfront payments, \nand you only pay for what you use. Optionally, you can enable DNS-based discover\ny for the resources with IP addresses. You can also enable health checking for y\nour resources using Amazon Route 53 health checks, whether you're discovering in\nstances using API calls or DNS queries. You will incur additional charges relate\nd to Route 53 DNS and health check usage. For more information, see AWS Cloud Ma\np Pricing. AWS Cloud Map and AWS Cloud Compliance For information about AWS Clou\nd Map compliance with various security compliance regulations and audits standar\nds, see the following pages: AWS Cloud Compliance AWS Services in Scope by Compl\niance Program Javascript is disabled or is unavailable in your browser. To use t\nhe Amazon Web Services Documentation, Javascript must be enabled. Please refer t\no your browser's Help pages for instructions. Document Conventions Get started D\nid this page help you? - Yes Thanks for letting us know we're doing a good job! \nIf you've got a moment, please tell us what we did right so we can do more of it\n. Did this page help you? - No Thanks for letting us know this page needs work. \nWe're sorry we let you down. If you've got a moment, please tell us how we can m\nake the documentation better.",
  "body": "",
  "code": "Map(code -> IPv6, language -> code)Map(code -> servicediscovery.<region>.api.aws\n, language -> code)Map(code -> IPv6, language -> code)Map(code -> servicediscove\nry.<region>.amazonaws.com, language -> code)",
  "table": ""
}
{
  "url": "https://docs.aws.amazon.com/cli/latest/userguide/cli-chap-getting-started.html",
  "pageType": "UserGuidePage",
  "title": "Getting started with the AWS CLI - AWS Command Line Interface AWSDocumentationAW\nS Command Line InterfaceUser Guide for Version 2 Getting started with the AWS CL\nI This chapter provides steps to get started with version 2 of the AWS Command L\nine Interface (AWS CLI) and provides links to the relevant instructions. Complet\ne all prerequisites - To access AWS services with the AWS CLI, you need at minim\num an AWS account and IAM credentials. To increase the security of your AWS acco\nunt, we recommend that you do not use your root account credentials. You should \ncreate a user with least privilege to provide access credentials to the tasks yo\nu'll be running in AWS. Install or gain access to the AWS CLI using one of the f\nollowing methods: (Recommended) Installing or updating to the latest version of \nthe AWS CLI. Installing past releases of the AWS CLI version 2. Installing a spe\ncific version is primarily used if your team aligns their tools to a specific ve\nrsion. Building and installing the AWS CLI from source. Building the AWS CLI fro\nm GitHub source is a more in-depth method that is primarily used by customers wh\no work on platforms that we do not directly support with our pre-built installer\ns. Running the official Amazon ECR Public or Docker images for the AWS CLI. Acce\nss the AWS CLI version 2 in the AWS console from your browser using AWS CloudShe\nll. For more information, see the AWS CloudShell User Guide. After you have acce\nss to the AWS CLI, configure your AWS CLI with your IAM credentials for first ti\nme use. Troubleshooting installer or configure errors If you have issues after i\nnstalling, uninstalling, or configuring the AWS CLI, see Troubleshooting errors \nfor the AWS CLI for troubleshooting steps. Topics Prerequisites to use the AWS C\nLI version 2 Installing or updating to the latest version of the AWS CLI Install\ning past releases of the AWS CLI version 2 Building and installing the AWS CLI f\nrom source Running the official Amazon ECR Public or Docker images for the AWS C\nLI Setting up the AWS CLI Javascript is disabled or is unavailable in your brows\ner. To use the Amazon Web Services Documentation, Javascript must be enabled. Pl\nease refer to your browser's Help pages for instructions. Document Conventions A\ndditional documentation and resources Prerequisites Did this page help you? - Ye\ns Thanks for letting us know we're doing a good job! If you've got a moment, ple\nase tell us what we did right so we can do more of it. Did this page help you? -\n No Thanks for letting us know this page needs work. We're sorry we let you down\n. If you've got a moment, please tell us how we can make the documentation bette\nr.",
  "body": "",
  "code": "",
  "table": ""
}
{
  "url": "https://docs.aws.amazon.com/powershell/latest/userguide/pstools-getting-started.html",
  "pageType": "UserGuidePage",
  "title": "Get started with the AWS Tools for Windows PowerShell - AWS Tools for PowerShell\n AWSDocumentationAWS Tools for PowerShellUser Guide Get started with the AWS Too\nls for Windows PowerShell Some of the topics in this section describe the fundam\nentals of using the Tools for Windows PowerShell after you have installed the to\nols. For example, they explain how to specify which credentials and AWS Region t\nhe Tools for Windows PowerShell should use when interacting with AWS. Other topi\ncs in this section provide information about advanced ways that you can configur\ne the tools, your environment, and your projects. Topics Configure tool authenti\ncation Specify AWS Regions Configure federated identity Cmdlet discovery and ali\nases Pipelining, output, and iteration Credential and profile resolution Users a\nnd roles Using legacy credentials Javascript is disabled or is unavailable in yo\nur browser. To use the Amazon Web Services Documentation, Javascript must be ena\nbled. Please refer to your browser's Help pages for instructions. Document Conve\nntions Migrating from AWS Tools for PowerShell Version 3.3 to Version 4 Configur\ne tool authentication Did this page help you? - Yes Thanks for letting us know w\ne're doing a good job! If you've got a moment, please tell us what we did right \nso we can do more of it. Did this page help you? - No Thanks for letting us know\n this page needs work. We're sorry we let you down. If you've got a moment, plea\nse tell us how we can make the documentation better.",
  "body": "",
  "code": "",
  "table": ""
}
{
  "url": "https://docs.aws.amazon.com/AmazonECS/latest/developerguide/ecs-anywhere.html",
  "pageType": "DevGuidePage",
  "title": "Amazon ECS clusters for the external launch type - Amazon Elastic Container Serv\nice AWSDocumentationAmazon ECSDeveloper Guide Supported operating systems and sy\nstem architecturesConsiderations Amazon ECS clusters for the external launch typ\ne Amazon ECS Anywhere provides support for registering an external instance such\n as an on-premises server or virtual machine (VM), to your Amazon ECS cluster. E\nxternal instances are optimized for running applications that generate outbound \ntraffic or process data. If your application requires inbound traffic, the lack \nof Elastic Load Balancing support makes running these workloads less efficient. \nAmazon ECS added a new EXTERNAL launch type that you can use to create services \nor run tasks on your external instances. Supported operating systems and system \narchitectures The following is the list of supported operating systems and syste\nm architectures. Amazon Linux 2 Amazon Linux 2023 CentOS 7 CentOS Stream 9 RHEL \n7, RHEL 8  Neither Docker or RHEL's open package repositories support installing\n Docker natively on RHEL. You must ensure that Docker is installed before you ru\nn the install script that's described in this document. Fedora 32, Fedora 33, Fe\ndora 40 openSUSE Tumbleweed Ubuntu 18, Ubuntu 20, Ubuntu 22, Ubuntu 24 Debian 10\n Important Debian 9 Long Term Support (LTS support) ended on June 30, 2022 and i\ns no longer supported by Amazon ECS Anywhere. Debian 11 Debian 12 SUSE Enterpris\ne Server 15 The x86_64 and ARM64 CPU architectures are supported. The following \nWindows operating system versions are supported: Windows Server 2022 Windows Ser\nver 2019 Windows Server 2016 Windows Server 20H2 Considerations Before you start\n using external instances, be aware of the following considerations. You can reg\nister an external instance to one cluster at a time. For instructions on how to \nregister an external instance with a different cluster, see Deregistering an Ama\nzon ECS external instance. Your external instances require an IAM role that allo\nws them to communicate with AWS APIs. For more information, see Amazon ECS Anywh\nere IAM role. Your external instances should not have a preconfigured instance c\nredential chain defined locally as this will interfere with the registration scr\nipt. To send container logs to CloudWatch Logs, make sure that you create and sp\necify a task execution IAM role in your task definition. When an external instan\nce is registered to a cluster, the ecs.capability.external attribute is associat\ned with the instance. This attribute identifies the instance as an external inst\nance. You can add custom attributes to your external instances to use as a task \nplacement constraint. For more information, see Custom attributes. You can add r\nesource tags to your external instance. For more information, see External conta\niner instances. ECS Exec is supported on external instances. For more informatio\nn, see Monitor Amazon ECS containers with ECS Exec. The following are additional\n considerations that are specific to networking with your external instances. Fo\nr more information, see Networking . Service load balancing isn't supported. Ser\nvice discovery isn't supported. Tasks that run on external instances must use th\ne bridge, host, or none network modes. The awsvpc network mode isn't supported. \nThere are Amazon ECS service domains in each AWS Region. These service domains m\nust be allowed to send traffic to your external instances. The SSM Agent install\ned on your external instance maintains IAM credentials that are rotated every 30\n minutes using a hardware fingerprint. If your external instance loses connectio\nn to AWS, the SSM Agent automatically refreshes the credentials after the connec\ntion is re-established. For more information, see Validating on-premises servers\n and virtual machines using a hardware fingerprint in the AWS Systems Manager Us\ner Guide. The UpdateContainerAgent API isn't supported. For instructions on how \nto update the SSM Agent or the Amazon ECS agent on your external instances, see \nUpdating the AWS Systems Manager agent and Amazon ECS container agent on an exte\nrnal instance. Amazon ECS capacity providers aren't supported. To create a servi\nce or run a standalone task on your external instances, use the EXTERNAL launch \ntype. SELinux isn't supported. Using Amazon EFS volumes or specifying an EFSVolu\nmeConfiguration isn't supported. Integration with App Mesh isn't supported. If y\nou use the console to create an external instance task definition, you must crea\nte the task definition with the console JSON editor. When you run ECS Anywhere o\nn Windows, you must use your own Windows license on the on-premises infrastructu\nre. When you use a non Amazon ECS-optimized AMI, run the following commands on t\nhe external container instance to configure rules to use IAM roles for tasks. Fo\nr more information, see External instance additional configuration. $ sysctl -w \nnet.ipv4.conf.all.route_localnet=1$ iptables -t nat -A PREROUTING -p tcp -d 169.\n254.170.2 --dport 80 -j DNAT --to-destination 127.0.0.1:51679$ iptables -t nat -\nA OUTPUT -d 169.254.170.2 -p tcp -m tcp --dport 80 -j REDIRECT --to-ports 51679 \nNetworking Amazon ECS external instances are optimized for running applications \nthat generate outbound traffic or process data. If your application requires inb\nound traffic, such as a web service, the lack of Elastic Load Balancing support \nmakes running these workloads less efficient because there isn't support for pla\ncing these workloads behind a load balancer. The following are additional consid\nerations that are specific to networking with your external instances. Service l\noad balancing isn't supported. Service discovery isn't supported. Linux tasks th\nat run on external instances must use the bridge, host, or none network modes. T\nhe awsvpc network mode isn't supported. For more information about each network \nmode, see Amazon ECS task networking options for the EC2 launch type. Windows ta\nsks that run on external instances must use the default network mode. There are \nAmazon ECS service domains in each Region and must be allowed to send traffic to\n your external instances. The SSM Agent installed on your external instance main\ntains IAM credentials that are rotated every 30 minutes using a hardware fingerp\nrint. If your external instance loses connection to AWS, the SSM Agent automatic\nally refreshes the credentials after the connection is re-established. For more \ninformation, see Validating on-premises servers and virtual machines using a har\ndware fingerprint in the AWS Systems Manager User Guide. The following domains a\nre used for communication between the Amazon ECS service and the Amazon ECS agen\nt that's installed on your external instance. Make sure that traffic is allowed \nand that DNS resolution works. For each endpoint, region represents the Region i\ndentifier for an AWS Region that's supported by Amazon ECS, such as us-east-2 fo\nr the US East (Ohio) Region. The endpoints for all Regions that you use should b\ne allowed. For the ecs-a and ecs-t endpoints, you should include an asterisk (fo\nr example, ecs-a-*). ecs-a-*.region.amazonaws.com  This endpoint is used when ma\nnaging tasks. ecs-t-*.region.amazonaws.com  This endpoint is used to manage task\n and container metrics. ecs.region.amazonaws.com  This is the service endpoint f\nor Amazon ECS. ssm.region.amazonaws.com  This is the service endpoint for AWS Sy\nstems Manager. ec2messages.region.amazonaws.com  This is the service endpoint th\nat AWS Systems Manager uses to communicate between the Systems Manager agent and\n the Systems Manager service in the cloud. ssmmessages.region.amazonaws.com  Thi\ns is the service endpoint that is required to create and delete session channels\n with the Session Manager service in the cloud. If your tasks require communicat\nion with any other AWS services, make sure that those service endpoints are allo\nwed. Example applications include using Amazon ECR to pull container images or u\nsing CloudWatch for CloudWatch Logs. For more information, see Service endpoints\n in the AWS General Reference. Amazon FSx for Windows File Server with ECS Anywh\nere In order to use the Amazon FSx for Windows File Server with Amazon ECS exter\nnal instances you must establish a connection between your on-premises data cent\ner and the AWS Cloud. For information about the options for connecting your netw\nork to your VPC, see Amazon Virtual Private Cloud Connectivity Options. gMSA wit\nh ECS Anywhere The following use cases are supported for ECS Anywhere. The Activ\ne Directory is in the AWS Cloud - For this configuration, you create a connectio\nn between your on-premises network and the AWS Cloud using an AWS Direct Connect\n connection. For information about how to create the connection, see Amazon Virt\nual Private Cloud Connectivity Options.You create an Active Directory in the AWS\n Cloud. For information about how to get started with AWS Directory Service, see\n Setting up AWS Directory Service in the AWS Directory Service Administration Gu\nide. You can then join your external instances to the domain using the AWS Direc\nt Connect connection. For information about working with gMSA with Amazon ECS, s\nee Learn how to use gMSAs for EC2 Windows containers for Amazon ECS. The Active \nDirectory is in the on-premises data center. - For this configuration, you join \nyour external instances to the on-premises Active Directory. You then use the lo\ncally available credentials when you run the Amazon ECS tasks. Javascript is dis\nabled or is unavailable in your browser. To use the Amazon Web Services Document\nation, Javascript must be enabled. Please refer to your browser's Help pages for\n instructions. Document Conventions Configuring container instances to receive S\npot Instance notices Creating a cluster for the External launch type Did this pa\nge help you? - Yes Thanks for letting us know we're doing a good job! If you've \ngot a moment, please tell us what we did right so we can do more of it. Did this\n page help you? - No Thanks for letting us know this page needs work. We're sorr\ny we let you down. If you've got a moment, please tell us how we can make the do\ncumentation better.",
  "body": "",
  "code": "Map(code -> EXTERNAL, language -> code)Map(code -> x86_64, language -> code)Map(\ncode -> ARM64, language -> code)Map(code -> ecs.capability.external, language ->\n code)Map(code -> bridge, language -> code)Map(code -> host, language -> code)Ma\np(code -> none, language -> code)Map(code -> awsvpc, language -> code)Map(code -\n> UpdateContainerAgent, language -> code)Map(code -> EXTERNAL, language -> code)\nMap(code -> EFSVolumeConfiguration, language -> code)Map(code -> $ sysctl -w net\n.ipv4.conf.all.route_localnet=1$ iptables -t nat -A PREROUTING -p tcp -d 169.254\n.170.2 --dport 80 -j DNAT --to-destination 127.0.0.1:51679$ iptables -t nat -A O\nUTPUT -d 169.254.170.2 -p tcp -m tcp --dport 80 -j REDIRECT --to-ports 51679, la\nnguage -> programlisting)Map(code -> $ sysctl -w net.ipv4.conf.all.route_localne\nt=1$ iptables -t nat -A PREROUTING -p tcp -d 169.254.170.2 --dport 80 -j DNAT --\nto-destination 127.0.0.1:51679$ iptables -t nat -A OUTPUT -d 169.254.170.2 -p tc\np -m tcp --dport 80 -j REDIRECT --to-ports 51679, language -> )Map(code -> bridg\ne, language -> code)Map(code -> host, language -> code)Map(code -> none, languag\ne -> code)Map(code -> awsvpc, language -> code)Map(code -> default, language -> \ncode)Map(code -> region, language -> replaceable)Map(code -> us-east-2, language\n -> code)Map(code -> ecs-a, language -> code)Map(code -> ecs-t, language -> code\n)Map(code -> ecs-a-*, language -> code)Map(code -> ecs-a-*.region.amazonaws.com,\n language -> code)Map(code -> region, language -> replaceable)Map(code -> ecs-t-\n*.region.amazonaws.com, language -> code)Map(code -> region, language -> replace\nable)Map(code -> ecs.region.amazonaws.com, language -> code)Map(code -> region, \nlanguage -> replaceable)Map(code -> ssm.region.amazonaws.com, language -> code)M\nap(code -> region, language -> replaceable)Map(code -> ec2messages.region.amazon\naws.com, language -> code)Map(code -> region, language -> replaceable)Map(code -\n> ssmmessages.region.amazonaws.com, language -> code)Map(code -> region, languag\ne -> replaceable)",
  "table": ""
}
{
  "url": "https://docs.aws.amazon.com/AmazonECR/latest/userguide/what-is-ecr.html",
  "pageType": "UserGuidePage",
  "title": "What is Amazon Elastic Container Registry? - Amazon ECR AWSDocumentationAmazon E\nCRUser Guide Features of Amazon ECRHow to get started with Amazon ECRPricing for\n Amazon ECR What is Amazon Elastic Container Registry? Amazon Elastic Container \nRegistry (Amazon ECR) is an AWS managed container image registry service that is\n secure, scalable, and reliable. Amazon ECR supports private repositories with r\nesource-based permissions using AWS IAM. This is so that specified users or Amaz\non EC2 instances can access your container repositories and images. You can use \nyour preferred CLI to push, pull, and manage Docker images, Open Container Initi\native (OCI) images, and OCI compatible artifacts. Note Amazon ECR supports publi\nc container image repositories as well. For more information, see What is Amazon\n ECR Public in the Amazon ECR Public User Guide. The AWS container services team\n maintains a public roadmap on GitHub. It contains information about what the te\nams are working on and allows all AWS customers the ability to give direct feedb\nack. For more information, see AWS Containers Roadmap. Features of Amazon ECR Am\nazon ECR provides the following features: Lifecycle policies help with managing \nthe lifecycle of the images in your repositories. You define rules that result i\nn the cleaning up of unused images. You can test rules before applying them to y\nour repository. For more information, see Automate the cleanup of images by usin\ng lifecycle policies in Amazon ECR. Image scanning helps in identifying software\n vulnerabilities in your container images. Each repository can be configured to \nscan on push. This ensures that each new image pushed to the repository is scann\ned. You can then retrieve the results of the image scan. For more information, s\nee Scan images for software vulnerabilities in Amazon ECR. Cross-Region and cros\ns-account replication makes it easier for you to have your images where you need\n them. This is configured as a registry setting and is on a per-Region basis. Fo\nr more information, see Private registry settings in Amazon ECR. Pull through ca\nche rules provide a way to cache repositories in an upstream registry in your pr\nivate Amazon ECR registry. Using a pull through cache rule, Amazon ECR will peri\nodically reach out to the upstream registry to ensure the cached image in your A\nmazon ECR private registry is up to date. For more information, see Sync an upst\nream registry with an Amazon ECR private registry. How to get started with Amazo\nn ECR If you are using Amazon Elastic Container Service (Amazon ECS) or Amazon E\nlastic Kubernetes Service (Amazon EKS), note that the setup for those two servic\nes is similar to the setup for Amazon ECR because Amazon ECR is an extension of \nboth services. When using the AWS Command Line Interface with Amazon ECR, use a \nversion of the AWS CLI that supports the latest Amazon ECR features. If you don'\nt see support for an Amazon ECR feature in the AWS CLI, upgrade to the latest ve\nrsion of the AWS CLI. For information about installing the latest version of the\n AWS CLI, see Install or update to the latest version of the AWS CLI in the AWS \nCommand Line Interface User Guide. To learn how to push a container image to a p\nrivate Amazon ECR repository using the AWS CLI and Docker, see Moving an image t\nhrough its lifecycle in Amazon ECR. Pricing for Amazon ECR With Amazon ECR, you \nonly pay for the amount of data you store in your repositories and for the data \ntransfer from your image pushes and pulls. For more information, see Amazon ECR \npricing. Javascript is disabled or is unavailable in your browser. To use the Am\nazon Web Services Documentation, Javascript must be enabled. Please refer to you\nr browser's Help pages for instructions. Document Conventions Concepts and compo\nnents Did this page help you? - Yes Thanks for letting us know we're doing a goo\nd job! If you've got a moment, please tell us what we did right so we can do mor\ne of it. Did this page help you? - No Thanks for letting us know this page needs\n work. We're sorry we let you down. If you've got a moment, please tell us how w\ne can make the documentation better.",
  "body": "",
  "code": "",
  "table": ""
}
{
  "url": "https://docs.aws.amazon.com/AmazonECR/latest/public/what-is-ecr.html",
  "pageType": "UserGuidePage",
  "title": "What Is Amazon Elastic Container Registry Public? - Amazon ECR Public AWSDocumen\ntationAmazon ECRUser Guide Components of Amazon ECR PublicHow to get started wit\nh Amazon ECR Public What Is Amazon Elastic Container Registry Public? Amazon Ela\nstic Container Registry Public is a managed AWS container image registry service\n that is secure, scalable, and reliable. Amazon ECR supports public image reposi\ntories with resource-based permissions using AWS IAM so that specific users can \naccess your public repositories to push images. Developers can use their preferr\ned CLI to push and manage Docker images, Open Container Initiative (OCI) images,\n and OCI compatible artifacts. Your images are publicly available to pull, eithe\nr anonymously or using an Amazon ECR Public authentication token. Note Amazon EC\nR supports private container image repositories as well. For more information, s\nee What is Amazon ECR in the Amazon Elastic Container Registry User Guide. The A\nWS container services team maintains a public roadmap on GitHub. It contains inf\normation about what the teams are working on and allows all AWS customers the ab\nility to give direct feedback. For more information, see AWS Containers Roadmap.\n Components of Amazon ECR Public Amazon ECR Public contains the following compon\nents: Amazon ECR Public Gallery The Amazon ECR Public Gallery is the public port\nal that lists all public repositories hosted on Amazon ECR Public. Visit the Ama\nzon ECR Public Gallery at https://gallery.ecr.aws. For more information, see Ama\nzon ECR Public Gallery. Registry A public registry is provided to each AWS accou\nnt; you can create public image repositories in your public registry and store i\nmages in them. For more information, see Amazon ECR public registries. Authoriza\ntion token Your client must authenticate to a public registry as an AWS user bef\nore it can push images to a public repository. For image pulls, Amazon ECR Publi\nc accepts both anonymous pulls and pulls using an authentication token. For more\n information, see Registry authentication in Amazon ECR public. Repository An Am\nazon ECR image repository contains your Docker images, Open Container Initiative\n (OCI) images, and OCI compatible artifacts. For more information, see Amazon EC\nR public repositories. Repository policy You can control access to your reposito\nries and the images within them with repository policies. For more information, \nsee Public repository policies in Amazon ECR Public. Image You can push and pull\n container images to your repositories. You can use these images locally on your\n development system, or you can use them in Amazon ECS task definitions and Amaz\non EKS pod specifications. How to get started with Amazon ECR Public If you've s\nigned up for AWS and have been using Amazon Elastic Container Service (Amazon EC\nS) or Amazon Elastic Kubernetes Service (Amazon EKS), you are close to being abl\ne to use Amazon ECR. The setup process for those two services is similar, as Ama\nzon ECR is an extension of both services. When using the AWS CLI with Amazon ECR\n, we recommend that you use a version of the AWS CLI that supports the latest Am\nazon ECR features. If you do not see support for an Amazon ECR feature in the AW\nS CLI, you should upgrade to the latest version. For more information, see http:\n//aws.amazon.com/cli/. For a quickstart guide on pushing a container image to Am\nazon ECR Public repository, see Moving an image through its lifecycle in Amazon \nECR Public. Javascript is disabled or is unavailable in your browser. To use the\n Amazon Web Services Documentation, Javascript must be enabled. Please refer to \nyour browser's Help pages for instructions. Document Conventions Amazon ECR Publ\nic Gallery Did this page help you? - Yes Thanks for letting us know we're doing \na good job! If you've got a moment, please tell us what we did right so we can d\no more of it. Did this page help you? - No Thanks for letting us know this page \nneeds work. We're sorry we let you down. If you've got a moment, please tell us \nhow we can make the documentation better.",
  "body": "",
  "code": "",
  "table": ""
}
{
  "url": "https://docs.aws.amazon.com/AmazonECS/latest/developerguide/Welcome.html",
  "pageType": "DevGuidePage",
  "title": "What is Amazon Elastic Container Service? - Amazon Elastic Container Service AWS\nDocumentationAmazon ECSDeveloper Guide Amazon ECS terminology and componentsAppl\nication lifecycle What is Amazon Elastic Container Service? Amazon Elastic Conta\niner Service (Amazon ECS) is a fully managed container orchestration service tha\nt helps you easily deploy, manage, and scale containerized applications. As a fu\nlly managed service, Amazon ECS comes with AWS configuration and operational bes\nt practices built-in. It's integrated with both AWS and third-party tools, such \nas Amazon Elastic Container Registry and Docker. This integration makes it easie\nr for teams to focus on building the applications, not the environment. You can \nrun and scale your container workloads across AWS Regions in the cloud, and on-p\nremises, without the complexity of managing a control plane. Amazon ECS terminol\nogy and components There are three layers in Amazon ECS: Capacity - The infrastr\nucture where your containers run Controller - Deploy and manage your application\ns that run on the containers Provisioning - The tools that you can use to interf\nace with the scheduler to deploy and manage your applications and containers The\n following diagram shows the Amazon ECS layers. Amazon ECS capacity Amazon ECS c\napacity is the infrastructure where your containers run. The following is an ove\nrview of the capacity options: Amazon EC2 instances in the AWS cloud You choose \nthe instance type, the number of instances, and manage the capacity. Serverless \n(AWS Fargate) in the AWS cloud Fargate is a serverless, pay-as-you-go compute en\ngine. With Fargate you don't need to manage servers, handle capacity planning, o\nr isolate container workloads for security. On-premises virtual machines (VM) or\n servers Amazon ECS Anywhere provides support for registering an external instan\nce such as an on-premises server or virtual machine (VM), to your Amazon ECS clu\nster. The capacity can be located in any of the following AWS resources: Availab\nility Zones Local Zones Wavelength Zones AWS Regions AWS Outposts Amazon ECS con\ntroller The Amazon ECS scheduler is the software that manages your applications.\n Amazon ECS provisioning There are multiple options for provisioning Amazon ECS:\n AWS Management Console  Provides a web interface that you can use to access you\nr Amazon ECS resources. AWS Command Line Interface (AWS CLI)  Provides commands \nfor a broad set of AWS services, including Amazon ECS. It's supported on Windows\n, Mac, and Linux. For more information, see AWS Command Line Interface. AWS SDKs\n  Provides language-specific APIs and takes care of many of the connection detai\nls. These include calculating signatures, handling request retries, and error ha\nndling. For more information, see AWS SDKs. Copilot  Provides an open-source too\nl for developers to build, release, and operate production ready containerized a\npplications on Amazon ECS. For more information, see Copilot on the GitHub websi\nte. AWS CDK  Provides an open-source software development framework that you can\n use to model and provision your cloud application resources using familiar prog\nramming languages. The AWS CDK provisions your resources in a safe, repeatable m\nanner through AWS CloudFormation. Application lifecycle The following diagram sh\nows the application lifecycle and how it works with the Amazon ECS components. Y\nou must architect your applications so that they can run on containers. A contai\nner is a standardized unit of software development that holds everything that yo\nur software application requires to run. This includes relevant code, runtime, s\nystem tools, and system libraries. Containers are created from a read-only templ\nate that's called an image. Images are typically built from a Dockerfile. A Dock\nerfile is a plaintext file that contains the instructions for building a contain\ner. After they're built, these images are stored in a registry such as Amazon EC\nR where they can be downloaded from. After you create and store your image, you \ncreate an Amazon ECS task definition. A task definition is a blueprint for your \napplication. It is a text file in JSON format that describes the parameters and \none or more containers that form your application. For example, you can use it t\no specify the image and parameters for the operating system, which containers to\n use, which ports to open for your application, and what data volumes to use wit\nh the containers in the task. The specific parameters available for your task de\nfinition depend on the needs of your specific application. After you define your\n task definition, you deploy it as either a service or a task on your cluster. A\n cluster is a logical grouping of tasks or services that runs on the capacity in\nfrastructure that is registered to a cluster. A task is the instantiation of a t\nask definition within a cluster. You can run a standalone task, or you can run a\n task as part of a service. You can use an Amazon ECS service to run and maintai\nn your desired number of tasks simultaneously in an Amazon ECS cluster. How it w\norks is that, if any of your tasks fail or stop for any reason, the Amazon ECS s\nervice scheduler launches another instance based on your task definition. It doe\ns this to replace it and thereby maintain your desired number of tasks in the se\nrvice. The container agent runs on each container instance within an Amazon ECS \ncluster. The agent sends information about the current running tasks and resourc\ne utilization of your containers to Amazon ECS. It starts and stops tasks whenev\ner it receives a request from Amazon ECS. After you deploy the task or service, \nyou can use any of the following tools to monitor your deployment and applicatio\nn: CloudWatch Runtime Monitoring Javascript is disabled or is unavailable in you\nr browser. To use the Amazon Web Services Documentation, Javascript must be enab\nled. Please refer to your browser's Help pages for instructions. Document Conven\ntions Related information Did this page help you? - Yes Thanks for letting us kn\now we're doing a good job! If you've got a moment, please tell us what we did ri\nght so we can do more of it. Did this page help you? - No Thanks for letting us \nknow this page needs work. We're sorry we let you down. If you've got a moment, \nplease tell us how we can make the documentation better.",
  "body": "",
  "code": "",
  "table": ""
}
{
  "url": "https://docs.aws.amazon.com/eks/latest/userguide/what-is-eks.html",
  "pageType": "UserGuidePage",
  "title": "What is Amazon EKS? - Amazon EKS AWSDocumentationAmazon EKSUser Guide Features o\nf Amazon EKSAmazon EKS Pricing Help improve this page Want to contribute to this\n user guide? Scroll to the bottom of this page and select Edit this page on GitH\nub. Your contributions will help make our user guide better for everyone. What i\ns Amazon EKS? Amazon Elastic Kubernetes Service (Amazon EKS) is a managed Kubern\netes service that eliminates the need to operate and maintain the availability a\nnd scalability of Kubernetes clusters in Amazon Web Services (AWS) and in your o\nwn data centers. Kubernetes is an open source system that automates the manageme\nnt, scaling, and deployment of containerized applications. To get started, see t\nhe Quickstart: Deploy a web app and store data page in the Amazon EKS User Guide\n. Features of Amazon EKS Fully Managed Kubernetes Amazon EKS provides a scalable\n and highly-available Kubernetes control plane running across multiple AWS Avail\nability Zones (AZs). Amazon EKS automatically manages availability and scalabili\nty of Kubernetes API servers and etcd persistence layer. Amazon EKS runs the Kub\nernetes control plane across multiple AZs to ensure high availability, and autom\natically detects and replaces unhealthy control plane nodes. Amazon EKS Auto Mod\ne fully automates Kubernetes cluster infrastructure management for compute, stor\nage, and networking on AWS. It simplifies Kubernetes management by automatically\n provisioning infrastructure, selecting optimal compute instances, dynamically s\ncaling resources, continuously optimizing costs, patching operating systems, and\n integrating with AWS security services. Kubernetes Compatibility and Support Am\nazon EKS runs upstream Kubernetes and is certified Kubernetes-conformant, so you\n can use all the existing plug-ins and tooling from the Kubernetes community. Ap\nplications running on Amazon EKS are fully compatible with applications running \non any standard Kubernetes environment, whether running in on-premises data cent\ners or public clouds. This means that you can easily migrate any standard Kubern\netes application to Amazon EKS without refactoring your code. Amazon EKS support\ns Kubernetes versions longer than they are supported upstream, with standard sup\nport for Kubernetes minor versions for 14 months from the time they are released\n in Amazon EKS, and extended support for Kubernetes minor versions for an additi\nonal 12 months of support (26 total months per version). See Understand the Kube\nrnetes version lifecycle on EKS for more information. Machine Learning Amazon EK\nS has become a cornerstone for deploying and managing AI/ML workloads in the clo\nud. With its ability to handle complex, resource-intensive tasks, Amazon EKS pro\nvides a scalable and flexible foundation for running AI/ML models, making it an \nideal choice for organizations aiming to harness the full potential of machine l\nearning. Whether youre training large language models that require vast amounts \nof compute power or deploying inference pipelines that need to handle unpredicta\nble traffic patterns, Amazon EKS scales up and down efficiently, optimizing reso\nurce use and cost. Amazon EKS supports a wide range of compute options including\n GPU-powered instances and AWS Neuron, allowing for high-performance training an\nd low-latency inference, ensuring that models run efficiently in production envi\nronments. See the Machine Learning on Amazon EKS Overview for more information. \nHybrid Deployments You can use the same Amazon EKS clusters to run nodes on AWS-\nhosted infrastructure in AWS Regions, AWS Local Zones, AWS Wavelength Zones, or \nin your own on-premises environments with AWS Outposts and Amazon EKS Hybrid Nod\nes. AWS Outposts is AWS-managed infrastructure that you run in your data centers\n or co-location facilities, whereas Amazon EKS Hybrid Nodes runs on virtual mach\nines or bare metal infrastructure that you manage in your on-premises or edge en\nvironments. If you need to run in isolated or air-gapped environments, you can u\nse Amazon EKS Anywhere, which is AWS-supported Kubernetes management software th\nat runs on infrastructure you manage. With Amazon EKS Anywhere, you are responsi\nble for cluster lifecycle operations and maintenance of your Amazon EKS Anywhere\n clusters. The Amazon EKS Connector can be used to view any Kubernetes cluster a\nnd their resources in the Amazon EKS console. Amazon EKS Distro is the AWS distr\nibution of the underlying Kubernetes components that power all Amazon EKS offeri\nngs. Compute You can use the full range of Amazon EC2 instance types and AWS inn\novations such as Nitro and Graviton with Amazon EKS for you to optimize the comp\nute for your workloads. You can use on-demand or Spot instances and your savings\n plans with compute you use with your Amazon EKS clusters. See Manage compute re\nsources by using nodes for more information. Networking Amazon EKS integrates wi\nth Amazon VPC allowing you to use your own Amazon VPC security groups and networ\nk access control lists (ACLs) with Amazon EKS clusters. Amazon EKS provides the \nAmazon VPC container network interface (CNI), allowing Kubernetes pods to receiv\ne IP addresses directly from the VPC. Amazon EKS supports IPv4 and IPv6 for work\nloads and dual-stack endpoints for the Amazon EKS APIs and Kubernetes API. You c\nan use Application Load Balancers (ALB) and Network Load Balancers (NLB) managed\n by the AWS Load Balancer Controller for application ingress and load balancing.\n You can also use Amazon VPC Lattice, a managed application networking service b\nuilt directly into the AWS networking infrastructure, for cross-cluster connecti\nvity with standard Kubernetes semantics in a simple and consistent manner. See C\nonfigure networking for Amazon EKS clusters for more information. Security Amazo\nn EKS integrates with AWS Identity and Access Management (IAM) for you to secure\n your clusters and applications. Amazon EKS makes it easy to map AWS IAM permiss\nions to Kubernetes Role Based Access Control (RBAC). You can use AWS IAM for clu\nster authentication and authorization with Amazon EKS Cluster Access Management,\n for access and permissions of operational software running on your clusters, an\nd for granular application access to other AWS services with Amazon EKS Pod Iden\ntity. Amazon EKS is certified by multiple compliance programs for regulated and \nsensitive applications. Amazon EKS is compliant with SOC, PCI, ISO, FedRAMP-Mode\nrate, IRAP, C5, K-ISMS, ENS High, OSPAR, HITRUST CSF, and is a HIPAA eligible se\nrvice. See Learn how access control works in Amazon EKS for more information. Ob\nservability Amazon EKS integrates with AWS Managed Service for Prometheus (AMP),\n Amazon CloudWatch, Amazon CloudTrail, and Amazon GuardDuty for monitoring, logg\ning, and auditing capabilities. You can also view performance insights for your \nAmazon EKS clusters directly in the Amazon EKS console. You can use AMP agent-le\nss scrapers or the AWS Distro for OpenTelemetry add-on to monitor and collect lo\ngs for your clusters, infrastructure, and applications. You can use Amazon Cloud\nWatch Container Insights, the CloudWatch Observability Agent add-on, and Amazon \nEKS control plane logging to monitor, collect logs, and analyze issues with your\n clusters, infrastructure, and applications. Amazon EKS also integrates with Ama\nzon CloudTrail for auditing cluster API activity, and Amazon GuardDuty for audit\n log threat analysis and runtime threat detection. See Monitor your cluster perf\normance and view logs for more information. Storage You can use a range of AWS s\ntorage services with Amazon EKS for the storage needs of your applications. Thro\nugh an AWS-supported breadth of Container Storage Interface (CSI) drivers, you c\nan easily use Amazon EBS, Amazon S3, Amazon EFS, Amazon FSX, and Amazon File Cac\nhe for the storage needs of your applications running on Amazon EKS. See Store a\npplication data for your cluster for more information. Add-ons Amazon EKS offers\n a curated set of AWS-vended Kubernetes software, also known as Amazon EKS add-o\nns, that provide key operational capabilities for Kubernetes clusters and integr\nation with various AWS services for cluster and pod networking, load balancing, \nstorage, observability, and security. Amazon EKS provides a unified management e\nxperience for finding, selecting, installing, managing, and configuring third-pa\nrty Kubernetes operational software (add-ons) from independent software vendors \non Amazon EKS clusters. See Amazon EKS add-ons for more information. Management \ninterfaces Amazon EKS supports a range of interfaces to provision, manage, and m\naintain clusters including the Amazon EKS console, Amazon EKS API/SDKs, CDK, AWS\n CLI, eksctl CLI, AWS CloudFormation, and Terraform. You can also use AWS Contro\nllers for Kubernetes (ACK) to provision and manage AWS services from within your\n Kubernetes environment using Kubernetes interfaces. ACK makes it simple to buil\nd scalable and highly available Kubernetes applications utilizing AWS services. \nSee Get started with Amazon EKS for more information. Operating systems Amazon E\nKS supports a range of operating systems and you can use pre-built, Amazon EKS-o\nptimized Amazon Machine Images (AMIs) for the base images of your compute nodes.\n Amazon EKS maintains optimized images for Amazon Linux 2, Amazon Linux 2023, Bo\nttlerocket, Windows, and there are Ubuntu images maintained by Canonical. You ca\nn also use your own custom AMIs for other operating system variants. The Amazon \nEKS AMIs for Amazon Linux have built-in support for NVIDIA and AWS Neuron accele\nrated instance types. See Create nodes with pre-built optimized images for more \ninformation. Amazon EKS Pricing Amazon EKS has per cluster pricing based on Kube\nrnetes cluster version support, pricing for Amazon EKS Auto Mode, and per vCPU p\nricing for Amazon EKS Hybrid Nodes. When using Amazon EKS, you pay separately fo\nr the AWS resources you use to run your applications on Kubernetes worker nodes.\n For example, if you are running Kubernetes worker nodes as Amazon EC2 instances\n with Amazon EBS volumes and public IPv4 addresses, you are charged for the inst\nance capacity through Amazon EC2, the volume capacity through Amazon EBS, and th\ne IPv4 address through Amazon VPC. Visit the respective pricing pages of the AWS\n services you are using with your Kubernetes applications for detailed pricing i\nnformation. For Amazon EKS cluster, Amazon EKS Auto Mode, and Amazon EKS Hybrid \nNodes pricing, see Amazon EKS Pricing. For Amazon EC2 pricing, see Amazon EC2 On\n-Demand Pricing and Amazon EC2 Spot Pricing. For AWS Fargate pricing, see AWS Fa\nrgate Pricing. You can use your savings plans for compute used in Amazon EKS clu\nsters. For more information, see Pricing with Savings Plans.  Edit this page on \nGitHub Javascript is disabled or is unavailable in your browser. To use the Amaz\non Web Services Documentation, Javascript must be enabled. Please refer to your \nbrowser's Help pages for instructions. Document Conventions Common use cases Did\n this page help you? - Yes Thanks for letting us know we're doing a good job! If\n you've got a moment, please tell us what we did right so we can do more of it. \nDid this page help you? - No Thanks for letting us know this page needs work. We\n're sorry we let you down. If you've got a moment, please tell us how we can mak\ne the documentation better.",
  "body": "",
  "code": "",
  "table": ""
}
{
  "url": "https://docs.aws.amazon.com/eks/latest/userguide/machine-learning-on-eks.html",
  "pageType": "UserGuidePage",
  "title": "Machine Learning on Amazon EKS Overview - Amazon EKS AWSDocumentationAmazon EKSU\nser Guide Advantages of Machine Learning on EKS and the AWS cloudWhy Choose Amaz\non EKS for AI/ML?Start using Machine Learning on EKS Help improve this page Want\n to contribute to this user guide? Scroll to the bottom of this page and select \nEdit this page on GitHub. Your contributions will help make our user guide bette\nr for everyone. Machine Learning on Amazon EKS Overview Machine Learning (ML) is\n an area of Artificial Intelligence (AI) where machines process large amounts of\n data to look for patterns and make connections between the data. This can expos\ne new relationships and help predict outcomes that might not have been apparent \notherwise. For large-scale ML projects, data centers must be able to store large\n amounts of data, process data quickly, and integrate data from many sources. Th\ne platforms running ML applications must be reliable and secure, but also offer \nresiliency to recover from data center outages and application failures. AWS Ela\nstic Kubernetes Service (EKS), running in the AWS cloud, is particularly suited \nfor ML workloads. The primary goal of this section of the EKS User Guide is to h\nelp you put together the hardware and software component to build platforms to r\nun Machine Learning workloads in an EKS cluster. We start by explaining the feat\nures and services available to you in EKS and the AWS cloud, then provide you wi\nth tutorials to help you work with ML platforms, frameworks, and models. Advanta\nges of Machine Learning on EKS and the AWS cloud Amazon Elastic Kubernetes Servi\nce (EKS) is a powerful, managed Kubernetes platform that has become a cornerston\ne for deploying and managing AI/ML workloads in the cloud. With its ability to h\nandle complex, resource-intensive tasks, Amazon EKS provides a scalable and flex\nible foundation for running AI/ML models, making it an ideal choice for organiza\ntions aiming to harness the full potential of machine learning. Key Advantages o\nf AI/ML Platforms on Amazon EKS include: Scalability and Flexibility Amazon EKS \nenables organizations to scale AI/ML workloads seamlessly. Whether youre trainin\ng large language models that require vast amounts of compute power or deploying \ninference pipelines that need to handle unpredictable traffic patterns, EKS scal\nes up and down efficiently, optimizing resource use and cost. High Performance w\nith GPUs and Neuron Instances Amazon EKS supports a wide range of compute option\ns, including GPUs and AWS} Neuron instances, which are essential for acceleratin\ng AI/ML workloads. This support allows for high-performance training and low-lat\nency inference, ensuring that models run efficiently in production environments.\n Integration with AI/ML Tools Amazon EKS integrates seamlessly with popular AI/M\nL tools and frameworks like TensorFlow, PyTorch, and Ray, providing a familiar a\nnd robust ecosystem for data scientists and engineers. These integrations enable\n users to leverage existing tools while benefiting from the scalability and mana\ngement capabilities of Kubernetes. Automation and Management Kubernetes on Amazo\nn EKS automates many of the operational tasks associated with managing AI/ML wor\nkloads. Features like automatic scaling, rolling updates, and self-healing ensur\ne that your applications remain highly available and resilient, reducing the ove\nrhead of manual intervention. Security and Compliance Running AI/ML workloads on\n Amazon EKS provides robust security features, including fine-grained IAM roles,\n encryption, and network policies, ensuring that sensitive data and models are p\nrotected. EKS also adheres to various compliance standards, making it suitable f\nor enterprises with strict regulatory requirements. Why Choose Amazon EKS for AI\n/ML? Amazon EKS offers a comprehensive, managed environment that simplifies the \ndeployment of AI/ML models while providing the performance, scalability, and sec\nurity needed for production workloads. With its ability to integrate with a vari\nety of AI/ML tools and its support for advanced compute resources, EKS empowers \norganizations to accelerate their AI/ML initiatives and deliver innovative solut\nions at scale. By choosing Amazon EKS, you gain access to a robust infrastructur\ne that can handle the complexities of modern AI/ML workloads, allowing you to fo\ncus on innovation and value creation rather than managing underlying systems. Wh\nether you are deploying simple models or complex AI systems, Amazon EKS provides\n the tools and capabilities needed to succeed in a competitive and rapidly evolv\ning field. Start using Machine Learning on EKS To begin planning for and using M\nachine Learning platforms and workloads on EKS on the AWS cloud, proceed to the \nGet started deploying Machine Learning tools on EKS section.  Edit this page on \nGitHub Javascript is disabled or is unavailable in your browser. To use the Amaz\non Web Services Documentation, Javascript must be enabled. Please refer to your \nbrowser's Help pages for instructions. Document Conventions Nodes Get started wi\nth ML Did this page help you? - Yes Thanks for letting us know we're doing a goo\nd job! If you've got a moment, please tell us what we did right so we can do mor\ne of it. Did this page help you? - No Thanks for letting us know this page needs\n work. We're sorry we let you down. If you've got a moment, please tell us how w\ne can make the documentation better.",
  "body": "",
  "code": "",
  "table": ""
}
{
  "url": "https://docs.aws.amazon.com/eks/latest/userguide/hybrid-nodes-overview.html",
  "pageType": "UserGuidePage",
  "title": "Amazon EKS Hybrid Nodes overview - Amazon EKS AWSDocumentationAmazon EKSUser Gui\nde General concepts of Amazon EKS Hybrid Nodes Help improve this page Want to co\nntribute to this user guide? Scroll to the bottom of this page and select Edit t\nhis page on GitHub. Your contributions will help make our user guide better for \neveryone. Amazon EKS Hybrid Nodes overview With Amazon EKS Hybrid Nodes, you can\n use your on-premises and edge infrastructure as nodes in Amazon EKS clusters. A\nWS manages the AWS-hosted Kubernetes control plane of the Amazon EKS cluster, an\nd you manage the hybrid nodes that run in your on-premises or edge environments.\n This unifies Kubernetes management across your environments and offloads Kubern\netes control plane management to AWS for your on-premises and edge applications.\n Amazon EKS Hybrid Nodes works with any on-premises hardware or virtual machines\n, bringing the efficiency, scalability, and availability of Amazon EKS to wherev\ner your applications need to run. You can use a wide range of Amazon EKS feature\ns with Amazon EKS Hybrid Nodes including Amazon EKS add-ons, Amazon EKS Pod Iden\ntity, cluster access entries, cluster insights, and extended Kubernetes version \nsupport. Amazon EKS Hybrid Nodes natively integrates with AWS services including\n AWS Systems Manager, AWS IAM Roles Anywhere, Amazon Managed Service for Prometh\neus, Amazon CloudWatch, and Amazon GuardDuty for centralized monitoring, logging\n, and identity management. With Amazon EKS Hybrid Nodes, there are no upfront co\nmmitments or minimum fees, and you are charged per hour for the vCPU resources o\nf your hybrid nodes when they are attached to your Amazon EKS clusters. For more\n pricing information, see Amazon EKS Pricing. For an overview of the other Amazo\nn EKS options for on-premises and edge deployments, see Deploy Amazon EKS cluste\nrs across cloud and on-premises environments. General concepts of Amazon EKS Hyb\nrid Nodes Amazon EKS Hybrid Nodes must have a reliable connection between your o\nn-premises environment and AWS. Amazon EKS Hybrid Nodes arent a fit for disconne\ncted, disrupted, intermittent or limited (DDIL) environments. If you are running\n in a DDIL environment, consider Amazon EKS Anywhere. Running Amazon EKS Hybrid \nNodes on cloud infrastructure, including AWS Regions, AWS Local Zones, AWS Outpo\nsts, or in other clouds, is not supported. Use Amazon EKS Auto Mode, Karpenter, \nAmazon EC2 managed node groups, self-managed nodes, or AWS Fargate when running \nin AWS Regions. Use Amazon EC2 managed node groups or Amazon EC2 self-managed no\ndes when running on AWS Local Zones. Only Amazon EC2 self-managed nodes can be u\nsed on AWS Outposts or AWS Wavelength Zones. A single Amazon EKS cluster can be \nused to run hybrid nodes and nodes in AWS Regions, AWS Local Zones, or AWS Outpo\nsts. Amazon EKS Hybrid Nodes is available in all AWS Regions, except the AWS Gov\nCloud (US) Regions and the AWS China Regions. You will be charged the hybrid nod\nes fee if you run hybrid nodes on Amazon EC2 instances. Billing for hybrid nodes\n starts when the nodes join the Amazon EKS cluster and stops when the nodes are \nremoved from the cluster. Be sure to remove your hybrid nodes from your Amazon E\nKS cluster if you are not using them. Infrastructure Management Amazon EKS Hybri\nd Nodes follows a bring your own infrastructure approach where it is your respon\nsibility to provision and manage the physical or virtual machines and the operat\ning system you use for hybrid nodes. Amazon EKS Hybrid Nodes are agnostic to the\n infrastructure they run on. You can run hybrid nodes on physical or virtual mac\nhines, and x86 and ARM architectures. Operating Systems for hybrid nodes Amazon \nLinux 2023 (AL2023): You can use Amazon Linux 2023 (AL2023) as the node operatin\ng system for hybrid nodes, but only in virtualized environments such as VMWare, \nKVM, and Hyper-V. AWS supports the integration of hybrid nodes with AL2023, but \nAL2023 isnt covered by the AWS Support Plans when you run it outside of Amazon E\nC2. Ubuntu: You can use Ubuntu 20.04, Ubuntu 22.04, and Ubuntu 24.04 as the node\n operating system for hybrid nodes. Red Hat Enterprise Linux (RHEL): You can use\n RHEL 8 and RHEL 9 as the node operating system for hybrid nodes. Kubernetes and\n platform versions Amazon EKS Hybrid Nodes supports the same Kubernetes versions\n and deprecation schedule as Amazon EKS, including standard and extended Kuberne\ntes version support. For more information on Kubernetes versions in Amazon EKS, \nsee Understand the Kubernetes version lifecycle on EKS. For more information abo\nut Amazon EKS platform versions, see View Amazon EKS platform versions for each \nKubernetes version. You must create new Amazon EKS clusters to use Amazon EKS Hy\nbrid Nodes. Hybrid nodes cant be used with existing Amazon EKS clusters. Network\ning The communication between the Amazon EKS control plane and hybrid nodes is r\nouted through the VPC and subnets you pass during cluster creation, which builds\n on the existing mechanism in Amazon EKS for control plane to node networking. A\nmazon EKS Hybrid Nodes is flexible to your preferred method of connecting your o\nn-premises networks to a VPC in AWS. There are several documented options availa\nble including AWS Site-to-Site VPN and AWS Direct Connect, and you can choose th\ne method that best fits your use case. IP address family: Hybrid nodes can be us\ned with Amazon EKS clusters configured with the IPv4 IP address family only. You\n cant use Amazon EKS clusters configured with the IPv6 IP address family. Simila\nrly, your on-premises node and Pod CIDRs must be IPv4 RFC1918 CIDR blocks. You m\nust enable the required domains, protocols, and ports for Amazon EKS Hybrid Node\ns in your on-premises environments and firewalls. For more information, includin\ng minimum networking requirements, see Prepare networking for hybrid nodes. Clus\nter endpoint access: You can use Public or Private cluster endpoint access. You \nshould not use Public and Private cluster endpoint access, as the endpoint DNS r\nesolution will always resolve to the public addresses for queries originating fr\nom your on-premises environment. For information and best practices during scena\nrios where there are network disconnections between hybrid nodes and the AWS Reg\nion, see the hybrid nodes section of the Amazon EKS Best Practices Guide. Applic\nation load balancing: Kubernetes has a Service object to define the names and do\nmain names for your applications and resolve and load balance to them. By defaul\nt, the type:LoadBalancer type of Service additionally creates an AWS Classic Loa\nd Balancer for traffic from outside the cluster. You can change this behavior wi\nth add-ons. Specifically, we recommend the AWS Application Load Balancer and AWS\n Network Load Balancer which are created by the AWS Load Balancer Controller, in\nstead of the AWS Classic Load Balancer. For steps to install the AWS Load Balanc\ner Controller in a hybrid environment, see AWS Load Balancer Controller. Securit\ny for hybrid nodes Amazon EKS Hybrid Nodes use temporary IAM credentials to auth\nenticate with your Amazon EKS cluster. You can use either AWS IAM Roles Anywhere\n or AWS Systems Manager (SSM) hybrid activations for provisioning the on-premise\ns IAM credentials for hybrid nodes. It is recommended to use AWS SSM hybrid acti\nvations if you do not have existing Public Key Infrastructure (PKI) with a Certi\nficate Authority (CA) and certificates for your on-premises environments. If you\n do have existing PKI and certificates on-premises, use AWS IAM Roles Anywhere. \nYou can use API or API_AND_CONFIG_MAP cluster authentication modes for your hybr\nid nodes-enabled Amazon EKS clusters. Use the cluster access entry type called H\nYBRID_LINUX with your hybrid nodes IAM role to enable hybrid nodes to join the A\nmazon EKS cluster. OIDC authentication is supported for hybrid nodes-enabled Ama\nzon EKS clusters. You can use Amazon EKS Pod Identities and IAM Roles for Servic\ne Accounts (IRSA) with applications running on hybrid nodes to enable granular a\nccess for your Pods running on hybrid nodes with other AWS services. You can use\n Amazon GuardDuty EKS Protection with hybrid nodes-enabled Amazon EKS clusters t\no analyze activities of users and applications accessing your cluster. Add-ons f\nor hybrid nodes For detailed information, see Configure common add-ons for hybri\nd nodes. Container Networking Interface (CNI): The AWS VPC CNI cant be used with\n hybrid nodes. The core capabilities of Cilium and Calico are supported for use \nwith hybrid nodes. You can manage your CNI with your choice of tooling such as H\nelm. For more information, see Configure a CNI for hybrid nodes. kube-proxy and \nCoreDNS: kube-proxy and CoreDNS are installed automatically when hybrid nodes jo\nin the Amazon EKS cluster. These add-ons can be managed as Amazon EKS add-ons af\nter cluster creation. Ingress and Load Balancing: You can use the AWS Load Balan\ncer Controller and Application Load Balancer (ALB) or Network Load Balancer (NLB\n) with the target type ip for workloads on hybrid nodes connected with AWS Direc\nt Connect or AWS Site-to-Site VPN. You can alternatively use your choice of Ingr\ness controller or load balancer for application traffic that stays local to your\n on-premises environment. Metrics: You can use Amazon Managed Prometheus (AMP) a\ngent-less scrapers, AWS Distro for Open Telemetry (ADOT), and the Amazon CloudWa\ntch Observability Agent with hybrid nodes. To use AMP agent-less scrapers for Po\nd metrics on hybrid nodes, your Pods must be accessible from the VPC that you us\ne for the Amazon EKS cluster. Logs: You can enable Amazon EKS control plane logg\ning for hybrid nodes-enabled clusters. You can use the ADOT EKS add-on and the A\nmazon CloudWatch Observability Agent EKS add-on for hybrid node and Pod logging.\n User interfaces Node management: The Amazon EKS Hybrid Nodes CLI is called node\nadm and is run on each on-premises host to simplify the installation, configurat\nion, registration, and uninstall of the hybrid nodes components. The hybrid node\ns nodeadm version is different than the nodeadm version used in the AL2023 Amazo\nn EKS-optimized AMIs. You should not use the hybrid nodes nodeadm version for no\ndes running in Amazon EC2. Cluster management: The Amazon EKS user interfaces fo\nr cluster management are the same with hybrid nodes-enabled Amazon EKS clusters.\n This includes the AWS Management Console, AWS API, AWS SDKs, AWS CLI, eksctl CL\nI, AWS CloudFormation, and Terraform.  Edit this page on GitHub Javascript is di\nsabled or is unavailable in your browser. To use the Amazon Web Services Documen\ntation, Javascript must be enabled. Please refer to your browser's Help pages fo\nr instructions. Document Conventions Get node logs Prerequisites Did this page h\nelp you? - Yes Thanks for letting us know we're doing a good job! If you've got \na moment, please tell us what we did right so we can do more of it. Did this pag\ne help you? - No Thanks for letting us know this page needs work. We're sorry we\n let you down. If you've got a moment, please tell us how we can make the docume\nntation better.",
  "body": "",
  "code": "Map(code -> IPv4, language -> code)Map(code -> IPv6, language -> code)Map(code -\n> IPv4, language -> code)Map(code -> type:LoadBalancer, language -> code)Map(cod\ne -> API, language -> code)Map(code -> API_AND_CONFIG_MAP, language -> code)Map(\ncode -> HYBRID_LINUX, language -> code)Map(code -> kube-proxy, language -> code)\nMap(code -> kube-proxy, language -> code)Map(code -> ip, language -> code)Map(co\nde -> nodeadm, language -> code)Map(code -> nodeadm, language -> code)Map(code -\n> nodeadm, language -> code)Map(code -> nodeadm, language -> code)",
  "table": ""
}
{
  "url": "https://docs.aws.amazon.com/vpc/latest/userguide/vpc-network-acls",
  "pageType": "UserGuidePage",
  "title": "Control subnet traffic with network access control lists - Amazon Virtual Privat\ne Cloud AWSDocumentationAmazon VPCUser Guide Control subnet traffic with network\n access control lists A network access control list (ACL) allows or denies speci\nfic inbound or outbound traffic at the subnet level. You can use the default net\nwork ACL for your VPC, or you can create a custom network ACL for your VPC with \nrules that are similar to the rules for your security groups in order to add an \nadditional layer of security to your VPC. There is no additional charge for usin\ng network ACLs. The following diagram shows a VPC with two subnets. Each subnet \nhas a network ACL. When traffic enters the VPC (for example, from a peered VPC, \nVPN connection, or the internet), the router sends the traffic to its destinatio\nn. Network ACL A determines which traffic destined for subnet 1 is allowed to en\nter subnet 1, and which traffic destined for a location outside subnet 1 is allo\nwed to leave subnet 1. Similarly, network ACL B determines which traffic is allo\nwed to enter and leave subnet 2. For information about the differences between s\necurity groups and network ACLs, see Compare security groups and network ACLs. C\nontents Network ACL basics Network ACL rules Default network ACL Custom network \nACLs Ephemeral ports Path MTU Discovery Work with network ACLs Example: Control \naccess to instances in a subnet Troubleshoot reachability issues Javascript is d\nisabled or is unavailable in your browser. To use the Amazon Web Services Docume\nntation, Javascript must be enabled. Please refer to your browser's Help pages f\nor instructions. Document Conventions Share security groups with AWS Organizatio\nns Network ACL basics Did this page help you? - Yes Thanks for letting us know w\ne're doing a good job! If you've got a moment, please tell us what we did right \nso we can do more of it. Did this page help you? - No Thanks for letting us know\n this page needs work. We're sorry we let you down. If you've got a moment, plea\nse tell us how we can make the documentation better.",
  "body": "",
  "code": "",
  "table": ""
}
{
  "url": "https://docs.aws.amazon.com/lightsail/latest/userguide/amazon-lightsail-container-services.html",
  "pageType": "UserGuidePage",
  "title": "Deploy and manage containers on Amazon Lightsail - Amazon Lightsail AWSDocumenta\ntionAmazon LightsailUser Guide ContainersLightsail container service elementsUse\n Lightsail container services Deploy and manage containers on Amazon Lightsail A\nn Amazon Lightsail container service is a highly scalable compute and networking\n resource on which you can deploy, run, and manage containers. A container is a \nstandard unit of software that packages code and its dependencies together so th\ne application runs quickly and reliably from one computing environment to anothe\nr. You can think of your Lightsail container service as a computing environment \nthat lets you run containers on AWS infrastructure by using images that you crea\nte on your local machine and push to your service, or images from an online repo\nsitory, like Amazon ECR Public Gallery. You can also run containers locally, on \nyour local machine, by installing software such as Docker. Amazon Elastic Contai\nner Service (Amazon ECS) and Amazon Elastic Compute Cloud (Amazon EC2) are other\n resources within the AWS infrastructure on which you can run containers. For mo\nre information, see the Amazon ECS Developer Guide. Contents Containers Lightsai\nl container service elements Lightsail container services Container service capa\ncity (scale and power) Pricing Deployments Deployment versions Container image s\nources Container service ARN Public endpoints and default domains Custom domains\n and SSL/TLS certificates Container logs Metrics Use Lightsail container service\ns Containers A container is a standard unit of software that packages code and i\nts dependencies together so the application runs quickly and reliably from one c\nomputing environment to another. You could run a container on your development e\nnvironment, deploy it to your pre-production environment, and then deploy it to \nyour production environment. Your containers will run reliably regardless of whe\nther your development environment is your local machine, your pre-production env\nironment is a physical server in a data center, or your production environment i\ns a virtual private server in the cloud. A container image is a lightweight, sta\nndalone, executable package of software that includes everything needed to run a\nn application: code, runtime, system tools, system libraries and settings. Conta\niner images become containers at runtime. By containerizing the application and \nits dependencies, you no longer have to worry about whether your software runs c\norrectly on the operating system and infrastructure that you deploy it on  you c\nan spend more time focusing on the code. For more information about containers, \nand container images, see What is a Container? in the Docker documentation. Ligh\ntsail container service elements The following are the key elements of Lightsail\n container services that you should understand before getting started. Lightsail\n container services A container service is the Lightsail compute resource that y\nou can create in any AWS Region in which Lightsail is available. You can create \nand delete container services at any time. For more information, see Create Ligh\ntsail container services and Delete Lightsail container services. Container serv\nice capacity (scale and power) You must choose the following capacity parameters\n when you first create your container service: Scale  The number of compute node\ns that you want your container workload to run in. Your container workload is co\npied across the compute nodes of your service. You can specify up to 20 compute \nnodes for a container service. You pick the scale based on the number of nodes y\nou want powering your service for better availability and higher capacity. Traff\nic to your containers will be load-balanced across all nodes. Power  The memory \nand vCPUs of each node in your container service. The powers that you can choose\n are Nano (Na), Micro (Mi), Small (Sm), Medium (Md), Large (Lg), and Xlarge (Xl)\n, each with a progressively greater amount of memory and vCPUs. If you specify t\nhe scale of your container service as more than 1, then your container workload \nis copied across the multiple compute nodes of your service. For example, if the\n scale of your service is 3 and the power is Nano, then there are three copies o\nf your container workload running on three compute resources each with 512 MB of\n RAM and 0.25 vCPUs. The incoming traffic is load-balanced between the three res\nources. The greater the capacity you specify for your container service, the mor\ne traffic it is able to handle. You can dynamically increase the power and scale\n of your container service at any time without any down-time if you find that it\n's under-provisioned, or decrease it if you find that it's over-provisioned. Lig\nhtsail automatically manages the capacity change along with your current deploym\nent. For more information, see Change the capacity of your container service. Pr\nicing The monthly price of your container service is calculated by multiplying t\nhe price of its power with the number of its compute nodes (the scale of your se\nrvice). For example, a service with a medium power, which has a price of $40 USD\n, and a scale of 3 compute nodes, will cost $120 USD per month. You are charged \nfor your container service whether it's enabled or disabled, and whether it has \na deployment or not. You must delete your container service to stop being charge\nd for it. Each container service, regardless of its configured capacity, include\ns a monthly data transfer quota of 500 GB. The data transfer quota does not chan\nge regardless of the power and scale that you choose for your service. Data tran\nsfer out to the internet in excess of the quota will result in an overage charge\n that varies by AWS Region and starts at $0.09 USD per GB. Data transfer in from\n the internet in excess of the quota does not incur an overage charge. For more \ninformation, see the Lightsail pricing page. Deployments You can create a deploy\nment in your Lightsail container service. A deployment is a set of specification\ns for the container workload that you wish to launch on your service. You can sp\necify the following parameters for each container entry in a deployment: The nam\ne of your container that will be launched The source container image to use for \nyour container The command to run when launching your container The environment \nvariables to apply to your container The network ports to open on your container\n The container in the deployment to make publicly accessible through the default\n domain of the container service Note Only one container in a deployment can be \nmade publicly accessible for each container service. The following health check \nparameters will apply to the public endpoint of a deployment after it's launched\n: The directory path on which to perform a health check. Advanced health check s\nettings, such as interval seconds, timeout seconds, success codes, healthy thres\nhold, and unhealthy threshold. Your container service can have one active deploy\nment at a time, and a deployment can have up to 10 container entries. You can cr\neate a deployment at the same time as you create your container service, or you \ncan create it after your service is up and running. For more information, see Cr\neate and manage container service deployments. Deployment versions Every deploym\nent that you create in your container service is saved as a deployment version. \nIf you modify the parameters of an existing deployment, the containers are re-de\nployed to your service and the modified deployment results in a new deployment v\nersion. The latest 50 deployment versions for each container service are saved. \nYou can use any of the 50 deployment versions to create a new deployment in the \nsame container service. For more information, see Create and manage container se\nrvice deployments. Container image sources When you create a deployment, you mus\nt specify a source container image for each container entry in your deployment. \nImmediately after you create your deployment, your container service pulls the i\nmages from the sources you specify and uses them to create your containers. The \nimages that you specify can originate from the following sources: A public regis\ntry, such as Amazon ECR Public Gallery, or some other public container image reg\nistry. For more information about Amazon ECR Public, see What Is Amazon Elastic \nContainer Registry Public? in the Amazon ECR Public User Guide. Images pushed fr\nom your local machine to your container service. If you create container images \non your local machine, you can push them to your container service to use them w\nhen creating a deployment. For more information, see Create container service im\nages and Push and manage container images. Lightsail container services support \nLinux-based container images. Windows-based container images are currently not s\nupported, but you can run Docker, the AWS Command Line Interface (AWS CLI), and \nthe Lightsail Control (lightsailctl) plugin on Windows to build and push your Li\nnux based images to your Lightsail container service. Container service ARN Amaz\non Resource Names (ARNs) uniquely identify AWS resources. We require an ARN when\n you need to specify a resource unambiguously across all of AWS, such as in IAM \npolicies, and API calls. To get the ARN for your container service, use the GetC\nontainerServices Lightsail API action, and specify the name of the container ser\nvice using the serviceName parameter. Your container service ARN will be listed \nin the results of that action as shown in the following example. For more inform\nation, see GetContainerServices in the Amazon Lightsail API Reference. You'll se\ne output similar to the following: {    \\\"containerServices\\\": [        {       \n     \\\"containerServiceName\\\": \\\"container-service-1\\\",            \\\"arn\\\": \\\"ar\nn:aws:lightsail: :111122223333:ContainerService/a1b2c3d4-5678-90ab-cdef-EXAMPLE1\n1111\\\",            \\\"createdAt\\\": \\\"2024-01-01T00:00:00+00:00\\\",            \\\"lo\ncation\\\": {                \\\"availabilityZone\\\": \\\"all\\\",                \\\"regio\nnName\\\": \\\"us-west-2\\\"        },        .....} Public endpoints and default doma\nins When you create a deployment, you can specify the container entry in the dep\nloyment that will serve as the public endpoint of your container service. The ap\nplication on the public endpoint container is publicly accessible on the interne\nt through a randomly generated default domain of your container service. The def\nault domain is formatted as https://<ServiceName>.<RandomGUID>.<AWSRegion>.cs.am\nazonlightsail.com, in which <ServiceName> is the name of your container service,\n <RandomGUID> is a randomly generated globally unique identifier of your contain\ner service in the AWS Region for your Lightsail account, and <AWSRegion> is the \nAWS Region in which the container service was created. The public endpoint of Li\nghtsail container services supports HTTPS only, and it does not support TCP or U\nDP traffic. Only one container can be the public endpoint for a service. So make\n sure that choose the container that is hosting the front-end of your applicatio\nn as the public endpoint while rest of the containers are internally accessible.\n You can use the default domain of your container service, or you can use your o\nwn custom domain (your registered domain name). For more information about using\n custom domains with your container services, see Enable and manage custom domai\nns for your container services. Private domain All container services also have \na private domain that is formatted as <ServiceName>.service.local, in which <Ser\nviceName> is the name of your container service. Use the private domain to acces\ns your container service from another one of your Lightsail resources in the sam\ne AWS Region as your service. The private domain is the only way to access your \ncontainer service if you don't specify a public endpoint in the deployment of yo\nur service. A default domain is generated for your container service even if you\n don't specify a public endpoint, but it will show a 404 No Such Service error m\nessage when you try to browse to it. To access a specific container using the pr\nivate domain of your container service, you must specify the open port of the co\nntainer that will accept your connection request. You do this by formatting the \ndomain of your request as <ServiceName>.service.local:<PortNumber>, in which <Se\nrviceName> is the name of your container service and <PortNumber> is the open po\nrt of the container that you wish to connect to. For example, if you create a de\nployment on your container service named container-service-1, and you specify a \nRedis container with port 6379 open, then you should format the domain of your r\nequest as container-service-1.service.local:6379. Custom domains and SSL/TLS cer\ntificates You can use up to 4 of your custom domains with your container service\n instead of using the default domain. For example, you can direct traffic for yo\nur custom domain, such as example.com, to the container in your deployment that \nis labeled as the public endpoint. To use your custom domains with your service,\n you must first request an SSL/TLS certificate for the domains that you want to \nuse. You must then validate the SSL/TLS certificate by adding a set of CNAME rec\nords to the DNS of your domains. After the SSL/TLS certificate is validated, you\n enable custom domains on your container service by attaching the valid SSL/TLS \ncertificate to your service. For more information see Create SSL/TLS certificate\ns for your Lightsail container services, Validate SSL/TLS certificates for your \nLightsail container services, and Enable and manage custom domains for your Ligh\ntsail container services. Container logs Every container in your container servi\nce generates a log that you can access to diagnose the operation of your contain\ners. The logs provide the stdout and stderr streams of processes that run inside\n the container. For more information, see View container service logs. Metrics M\nonitor the metrics of your container service to diagnose issues that may be a re\nsult of over-utilization. You can also monitor metrics to help you determine if \nyour service is under-provisioned or over-provisioned. For more information, see\n View container service metrics. Use Lightsail container services These are the \ngeneral steps to manage your Lightsail container service if you plan to push con\ntainer images from your local machine to your service, and use them in your depl\noyment: Create your container service in your Lightsail account. For more inform\nation, see Create Lightsail container services. Install software on your local m\nachine that you need to create your own container images and push them to your L\nightsail container service. For more information, see For more information, see \nthe following guides: Install software to manage container images for your Light\nsail container services Create container images for your Lightsail container ser\nvices Push and manage container images on your Lightsail container services Crea\nte a deployment in your container service that configures and launches your cont\nainers. For more information, see Create and manage deployments for your Lightsa\nil container services. View previous deployments for your container service. You\n can create a new deployment using a previous deployment version. For more infor\nmation, see View and manage deployment versions of your Lightsail container serv\nices. View the logs of containers on your container service. For more informatio\nn, see View the container logs of your Lightsail container services. Create an S\nSL/TLS certificate for the domains that you want to use with your containers. Fo\nr more information, see Create SSL/TLS certificates for your Lightsail container\n services. Validate the SSL/TLS certificate by adding records to the DNS of your\n domains. For more information, see Validate SSL/TLS certificates for your Light\nsail container services. Enable custom domains by attaching a valid SSL/TLS cert\nificate to your container service. For more information, see Enable and manage c\nustom domains for your Lightsail container services. Monitor the utilization met\nrics of your container service. For more information, see View container service\n metrics. (Optional) Scale the capacity of your container service vertically, by\n increasing its power specification, and horizontally, by increasing its scale s\npecification. For more information, see Change the capacity of your Lightsail co\nntainer services. Delete your container service if you're not using it to avoid \nincurring monthly charges. For more information, see Delete Lightsail container \nservices. These are the general steps to manage your Lightsail container service\n if you plan to use container images from a public registry in your deployment: \nCreate your container service in your Lightsail account. For more information, s\nee Create Lightsail container services. If you plan to use container images from\n a public registry, find container images from a public registry such as the Ama\nzon ECR Public Gallery. For more information about Amazon ECR Public, see What I\ns Amazon Elastic Container Registry Public? in the Amazon ECR Public User Guide.\n Create a deployment in your container service that configures and launches your\n containers. For more information, see Create and manage deployments for your Li\nghtsail container services. View previous deployments for your container service\n. You can create a new deployment using a previous deployment version. For more \ninformation, see View and manage deployment versions of your Lightsail container\n services. View the logs of containers on your container service. For more infor\nmation, see View the container logs of your Lightsail container services. Create\n an SSL/TLS certificate for the domains that you want to use with your container\ns. For more information, see Create SSL/TLS certificates for your Lightsail cont\nainer services. Validate the SSL/TLS certificate by adding records to the DNS of\n your domains. For more information, see Validate SSL/TLS certificates for your \nLightsail container services. Enable custom domains by attaching a valid SSL/TLS\n certificate to your container service. For more information, see Enable and man\nage custom domains for your Lightsail container services. Monitor the utilizatio\nn metrics of your container service. For more information, see View container se\nrvice metrics. (Optional) Scale the capacity of your container service verticall\ny, by increasing its power specification, and horizontally, by increasing its sc\nale specification. For more information, see Change the capacity of your Lightsa\nil container services. Delete your container service if you're not using it to a\nvoid incurring monthly charges. For more information, see Delete Lightsail conta\niner services. Javascript is disabled or is unavailable in your browser. To use \nthe Amazon Web Services Documentation, Javascript must be enabled. Please refer \nto your browser's Help pages for instructions. Document Conventions Upload files\n to bucket Create a container Did this page help you? - Yes Thanks for letting u\ns know we're doing a good job! If you've got a moment, please tell us what we di\nd right so we can do more of it. Did this page help you? - No Thanks for letting\n us know this page needs work. We're sorry we let you down. If you've got a mome\nnt, please tell us how we can make the documentation better.",
  "body": "",
  "code": "Map(code -> GetContainerServices, language -> code)Map(code -> serviceName, lang\nuage -> code)Map(code -> {    \\\"containerServices\\\": [        {            \\\"con\ntainerServiceName\\\": \\\"container-service-1\\\",            \\\"arn\\\": \\\"arn:aws:ligh\ntsail: :111122223333:ContainerService/a1b2c3d4-5678-90ab-cdef-EXAMPLE11111\\\",   \n         \\\"createdAt\\\": \\\"2024-01-01T00:00:00+00:00\\\",            \\\"location\\\": \n{                \\\"availabilityZone\\\": \\\"all\\\",                \\\"regionName\\\": \\\n\"us-west-2\\\"        },        .....}, language -> programlisting)Map(code -> {  \n  \\\"containerServices\\\": [        {            \\\"containerServiceName\\\": \\\"conta\niner-service-1\\\",            \\\"arn\\\": \\\"arn:aws:lightsail: :111122223333:Contain\nerService/a1b2c3d4-5678-90ab-cdef-EXAMPLE11111\\\",            \\\"createdAt\\\": \\\"20\n24-01-01T00:00:00+00:00\\\",            \\\"location\\\": {                \\\"availabil\nityZone\\\": \\\"all\\\",                \\\"regionName\\\": \\\"us-west-2\\\"        },      \n  .....}, language -> nohighlight)Map(code -> https://<ServiceName>.<RandomGUID>\n.<AWSRegion>.cs.amazonlightsail.com, language -> code)Map(code -> <ServiceName>,\n language -> replaceable)Map(code -> <RandomGUID>, language -> replaceable)Map(c\node -> <AWSRegion>, language -> replaceable)Map(code -> <ServiceName>, language \n-> replaceable)Map(code -> <RandomGUID>, language -> replaceable)Map(code -> <AW\nSRegion>, language -> replaceable)Map(code -> <ServiceName>.service.local, langu\nage -> code)Map(code -> <ServiceName>, language -> replaceable)Map(code -> <Serv\niceName>, language -> replaceable)Map(code -> 404 No Such Service, language -> c\node)Map(code -> <ServiceName>.service.local:<PortNumber>, language -> code)Map(c\node -> <ServiceName>, language -> replaceable)Map(code -> <PortNumber>, language\n -> replaceable)Map(code -> <ServiceName>, language -> replaceable)Map(code -> <\nPortNumber>, language -> replaceable)Map(code -> container-service-1, language -\n> code)Map(code -> 6379, language -> code)Map(code -> container-service-1.servic\ne.local:6379, language -> code)Map(code -> container-service-1, language -> repl\naceable)Map(code -> 6379, language -> replaceable)Map(code -> example.com, langu\nage -> code)",
  "table": ""
}
{
  "url": "https://docs.aws.amazon.com/apprunner/latest/dg/what-is-apprunner.html",
  "pageType": "DevGuidePage",
  "title": "What is AWS App Runner? - AWS App Runner AWSDocumentationApp RunnerDeveloper Gui\nde Who is App Runner for?Accessing App RunnerPricing for App RunnerWhat's next W\nhat is AWS App Runner? AWS App Runner is an AWS service that provides a fast, si\nmple, and cost-effective way to deploy from source code or a container image dir\nectly to a scalable and secure web application in the AWS Cloud. You don't need \nto learn new technologies, decide which compute service to use, or know how to p\nrovision and configure AWS resources. App Runner connects directly to your code \nor image repository. It provides an automatic integration and delivery pipeline \nwith fully managed operations, high performance, scalability, and security. Who \nis App Runner for? If you're a developer, you can use App Runner to simplify the\n process of deploying a new version of your code or image repository. For operat\nions teams, App Runner enables automatic deployments each time a commit is pushe\nd to the code repository or a new container image version is pushed to the image\n repository. Accessing App Runner You can define and configure your App Runner s\nervice deployments using any one of the following interfaces: App Runner console\n  Provides a web interface for managing your App Runner services. App Runner API\n  Provides a RESTful API for performing App Runner actions. For more information\n, see AWS App Runner API Reference. AWS Command Line Interface (AWS CLI)  Provid\nes commands for a broad set of AWS services, including Amazon VPC, and is suppor\nted on Windows, macOS, and Linux. For more information, see AWS Command Line Int\nerface. AWS SDKs  Provides language-specific APIs and takes care of many of the \nconnection details, such as calculating signatures, handling request retries, an\nd error handling. For more information, see AWS SDKs. Pricing for App Runner App\n Runner provides a cost-effective way to run your application. You only pay for \nresources that your App Runner service consumes. Your service scales down to few\ner compute instances when request traffic is lower. You have control over scalab\nility settings: the lowest and highest number of provisioned instances, and the \nhighest load an instance handles. For more information about App Runner automati\nc scaling, see Managing App Runner automatic scaling. For pricing information, s\nee AWS App Runner pricing. What's next Learn how to get started with App Runner \nin the following topics: Setting up for App Runner  Complete the prerequisite st\neps for using App Runner. Getting started with App Runner  Deploy your first app\nlication to App Runner. Javascript is disabled or is unavailable in your browser\n. To use the Amazon Web Services Documentation, Javascript must be enabled. Plea\nse refer to your browser's Help pages for instructions. Document Conventions Set\nting up Did this page help you? - Yes Thanks for letting us know we're doing a g\nood job! If you've got a moment, please tell us what we did right so we can do m\nore of it. Did this page help you? - No Thanks for letting us know this page nee\nds work. We're sorry we let you down. If you've got a moment, please tell us how\n we can make the documentation better.",
  "body": "",
  "code": "",
  "table": ""
}
{
  "url": "https://docs.aws.amazon.com/batch/latest/userguide/what-is-batch.html",
  "pageType": "UserGuidePage",
  "title": "What is AWS Batch? - AWS Batch AWSDocumentationAWS BatchUser Guide What is AWS B\natch? AWS Batch helps you to run batch computing workloads on the AWS Cloud. Bat\nch computing is a common way for developers, scientists, and engineers to access\n large amounts of compute resources. AWS Batch removes the undifferentiated heav\ny lifting of configuring and managing the required infrastructure, similar to tr\naditional batch computing software. This service can efficiently provision resou\nrces in response to jobs submitted in order to eliminate capacity constraints, r\neduce compute costs, and deliver results quickly. As a fully managed service, AW\nS Batch helps you to run batch computing workloads of any scale. AWS Batch autom\natically provisions compute resources and optimizes the workload distribution ba\nsed on the quantity and scale of the workloads. With AWS Batch, there's no need \nto install or manage batch computing software, so you can focus your time on ana\nlyzing results and solving problems. Topics Components of AWS Batch The AWS Batc\nh dashboard Javascript is disabled or is unavailable in your browser. To use the\n Amazon Web Services Documentation, Javascript must be enabled. Please refer to \nyour browser's Help pages for instructions. Document Conventions Components of A\nWS Batch Did this page help you? - Yes Thanks for letting us know we're doing a \ngood job! If you've got a moment, please tell us what we did right so we can do \nmore of it. Did this page help you? - No Thanks for letting us know this page ne\neds work. We're sorry we let you down. If you've got a moment, please tell us ho\nw we can make the documentation better.",
  "body": "",
  "code": "",
  "table": ""
}
{
  "url": "https://docs.aws.amazon.com/AmazonECS/latest/userguide/what-is-fargate.html",
  "pageType": "DevGuidePage",
  "title": "AWS Fargate for Amazon ECS - Amazon Elastic Container Service AWSDocumentationAm\nazon ECSDeveloper Guide WalkthroughsCapacity providersTask definitionsPlatform v\nersionsService load balancingUsage metrics AWS Fargate for Amazon ECS AWS Fargat\ne is a technology that you can use with Amazon ECS to run containers without hav\ning to manage servers or clusters of Amazon EC2 instances. With AWS Fargate, you\n no longer have to provision, configure, or scale clusters of virtual machines t\no run containers. This removes the need to choose server types, decide when to s\ncale your clusters, or optimize cluster packing. When you run your tasks and ser\nvices with the Fargate launch type, you package your application in containers, \nspecify the CPU and memory requirements, define networking and IAM policies, and\n launch the application. Each Fargate task has its own isolation boundary and do\nes not share the underlying kernel, CPU resources, memory resources, or elastic \nnetwork interface with another task. You configure your task definitions for Far\ngate by setting the requiresCompatibilities task definition parameter to FARGATE\n. For more information, see Launch types. Fargate offers platform versions for A\nmazon Linux 2 and Microsoft Windows 2019 Server Full and Core editions. Unless o\ntherwise specified, the information on this page applies to all Fargate platform\ns. This topic describes the different components of Fargate tasks and services, \nand calls out special considerations for using Fargate with Amazon ECS. For info\nrmation about the Regions that support Linux containers on Fargate, see Linux co\nntainers on AWS Fargate. For information about the Regions that support Windows \ncontainers on Fargate, see Windows containers on AWS Fargate. Walkthroughs For i\nnformation about how to get started using the console, see: Learn how to create \nan Amazon ECS Linux task for the Fargate launch type Learn how to create an Amaz\non ECS Windows task for the Fargate launch type For information about how to get\n started using the AWS CLI, see: Creating an Amazon ECS Linux task for the Farga\nte launch type with the AWS CLI Creating an Amazon ECS Windows task for the Farg\nate launch type with the AWS CLI Capacity providers The following capacity provi\nders are available: Fargate Fargate Spot - Run interruption tolerant Amazon ECS \ntasks at a discounted rate compared to the AWS Fargate price. Fargate Spot runs \ntasks on spare compute capacity. When AWS needs the capacity back, your tasks wi\nll be interrupted with a two-minute warning. For more information, see Amazon EC\nS clusters for the Fargate launch type . Task definitions Tasks that use the Far\ngate launch type don't support all of the Amazon ECS task definition parameters \nthat are available. Some parameters aren't supported at all, and others behave d\nifferently for Fargate tasks. For more information, see Task CPU and memory. Pla\ntform versions AWS Fargate platform versions are used to refer to a specific run\ntime environment for Fargate task infrastructure. It is a combination of the ker\nnel and container runtime versions. You select a platform version when you run a\n task or when you create a service to maintain a number of identical tasks. New \nrevisions of platform versions are released as the runtime environment evolves, \nfor example, if there are kernel or operating system updates, new features, bug \nfixes, or security updates. A Fargate platform version is updated by making a ne\nw platform version revision. Each task runs on one platform version revision dur\ning its lifecycle. If you want to use the latest platform version revision, then\n you must start a new task. A new task that runs on Fargate always runs on the l\natest revision of a platform version, ensuring that tasks are always started on \nsecure and patched infrastructure. If a security issue is found that affects an \nexisting platform version, AWS creates a new patched revision of the platform ve\nrsion and retires tasks running on the vulnerable revision. In some cases, you m\nay be notified that your tasks on Fargate have been scheduled for retirement. Fo\nr more information, see Task retirement and maintenance for AWS Fargate on Amazo\nn ECS . For more information see Fargate platform versions for Amazon ECS. Servi\nce load balancing Your Amazon ECS service on AWS Fargate can optionally be confi\ngured to use Elastic Load Balancing to distribute traffic evenly across the task\ns in your service. Amazon ECS services on AWS Fargate support the Application Lo\nad Balancer and Network Load Balancer load balancer types. Application Load Bala\nncers are used to route HTTP/HTTPS (or layer 7) traffic. Network Load Balancers \nare used to route TCP or UDP (or layer 4) traffic. For more information, see Use\n load balancing to distribute Amazon ECS service traffic. When you create a targ\net group for these services, you must choose ip as the target type, not instance\n. This is because tasks that use the awsvpc network mode are associated with an \nelastic network interface, not an Amazon EC2 instance. For more information, see\n Use load balancing to distribute Amazon ECS service traffic. Using a Network Lo\nad Balancer to route UDP traffic to your Amazon ECS on AWS Fargate tasks is only\n supported when using platform version 1.4 or later. Usage metrics You can use C\nloudWatch usage metrics to provide visibility into your accounts usage of resour\nces. Use these metrics to visualize your current service usage on CloudWatch gra\nphs and dashboards. AWS Fargate usage metrics correspond to AWS service quotas. \nYou can configure alarms that alert you when your usage approaches a service quo\nta. For more information about AWS Fargate service quotas, see AWS Fargate servi\nce quotas. For more information about AWS Fargate usage metrics, see AWS Fargate\n usage metrics. Javascript is disabled or is unavailable in your browser. To use\n the Amazon Web Services Documentation, Javascript must be enabled. Please refer\n to your browser's Help pages for instructions. Document Conventions Best practi\nces Security considerations for when to use the Fargate launch type Did this pag\ne help you? - Yes Thanks for letting us know we're doing a good job! If you've g\not a moment, please tell us what we did right so we can do more of it. Did this \npage help you? - No Thanks for letting us know this page needs work. We're sorry\n we let you down. If you've got a moment, please tell us how we can make the doc\numentation better.",
  "body": "",
  "code": "Map(code -> requiresCompatibilities, language -> code)Map(code -> FARGATE, langu\nage -> code)Map(code -> ip, language -> code)Map(code -> instance, language -> c\node)Map(code -> awsvpc, language -> code)",
  "table": ""
}
{
  "url": "https://docs.aws.amazon.com/AmazonECS/latest/developerguide/monitoring-fargate-usage.html",
  "pageType": "DevGuidePage",
  "title": "AWS Fargate usage metrics - Amazon Elastic Container Service AWSDocumentationAma\nzon ECSDeveloper Guide AWS Fargate usage metrics You can use CloudWatch usage me\ntrics to provide visibility into your accounts usage of resources. Use these met\nrics to visualize your current service usage on CloudWatch graphs and dashboards\n. AWS Fargate usage metrics correspond to AWS service quotas. You can configure \nalarms that alert you when your usage approaches a service quota. For more infor\nmation about Fargate service quotas, see AWS Fargate service quotas. AWS Fargate\n publishes the following metrics in the AWS/Usage namespace. Metric Description \nResourceCount The total number of the specified resource running on your account\n. The resource is defined by the dimensions associated with the metric. The foll\nowing dimensions are used to refine the usage metrics that are published by AWS \nFargate. Dimension Description Service The name of the AWS service containing th\ne resource. For AWS Fargate usage metrics, the value for this dimension is Farga\nte. Type The type of entity that is being reported. Currently, the only valid va\nlue for AWS Fargate usage metrics is Resource. Resource The type of resource tha\nt is running. The type of resource that is running. Currently, the only valid va\nlue for AWS Fargate usage metrics is vCPU which returns information about the ru\nnning instances. Class The class of resource being tracked. The class of resourc\ne being tracked. For AWS Fargate usage metrics with vCPU as the value of the Res\nource dimension, the valid values are Standard/OnDemand and Standard/Spot. You c\nan use the Service Quotas console to visualize your usage on a graph and configu\nre alarms that alert you when your AWS Fargate usage approaches a service quota.\n For information about how to create a CloudWatch alarm to notify you when you'r\ne close to a quota value threshold, see Service Quotas and Amazon CloudWatch ala\nrms in the Service Quotas User Guide . Javascript is disabled or is unavailable \nin your browser. To use the Amazon Web Services Documentation, Javascript must b\ne enabled. Please refer to your browser's Help pages for instructions. Document \nConventions Amazon ECS CloudWatch metrics Amazon ECS cluster reservation metrics\n Did this page help you? - Yes Thanks for letting us know we're doing a good job\n! If you've got a moment, please tell us what we did right so we can do more of \nit. Did this page help you? - No Thanks for letting us know this page needs work\n. We're sorry we let you down. If you've got a moment, please tell us how we can\n make the documentation better.",
  "body": "List(Map(Metric -> ResourceCount, Description -> The total number of the specifi\ned resource running on your account. The resource is defined by the dimensions a\nssociated with the metric.))List(Map(Dimension -> Service, Description -> The na\nme of the AWS service containing the resource. For AWS Fargate usage metrics, th\ne value for this dimension is Fargate.), Map(Dimension -> Type, Description -> T\nhe type of entity that is being reported. Currently, the only valid value for AW\nS Fargate usage metrics is Resource.), Map(Dimension -> Resource, Description ->\n The type of resource that is running. The type of resource that is running. Cur\nrently, the only valid value for AWS Fargate usage metrics is vCPU which returns\n information about the running instances.), Map(Dimension -> Class, Description \n-> The class of resource being tracked. The class of resource being tracked. For\n AWS Fargate usage metrics with vCPU as the value of the Resource dimension, the\n valid values are Standard/OnDemand and Standard/Spot.))",
  "code": "Map(code -> AWS/Usage, language -> code)Map(code -> ResourceCount, language -> c\node)Map(code -> Service, language -> code)Map(code -> Fargate, language -> code)\nMap(code -> Type, language -> code)Map(code -> Resource, language -> code)Map(co\nde -> Resource, language -> code)Map(code -> vCPU, language -> code)Map(code -> \nClass, language -> code)Map(code -> Standard/OnDemand, language -> code)Map(code\n -> Standard/Spot, language -> code)",
  "table": ""
}
{
  "url": "https://docs.aws.amazon.com/lambda/latest/dg/images-create.html",
  "pageType": "DevGuidePage",
  "title": "Create a Lambda function using a container image - AWS Lambda AWSDocumentationAW\nS LambdaDeveloper Guide RequirementsUsing an AWS base imageUsing an AWS OS-only \nbase imageUsing a non-AWS base imageRuntime interface clientsAmazon ECR permissi\nonsFunction lifecycle Create a Lambda function using a container image Your AWS \nLambda function's code consists of scripts or compiled programs and their depend\nencies. You use a deployment package to deploy your function code to Lambda. Lam\nbda supports two types of deployment packages: container images and .zip file ar\nchives. There are three ways to build a container image for a Lambda function: U\nsing an AWS base image for Lambda The AWS base images are preloaded with a langu\nage runtime, a runtime interface client to manage the interaction between Lambda\n and your function code, and a runtime interface emulator for local testing. Usi\nng an AWS OS-only base image AWS OS-only base images contain an Amazon Linux dis\ntribution and the runtime interface emulator. These images are commonly used to \ncreate container images for compiled languages, such as Go and Rust, and for a l\nanguage or language version that Lambda doesn't provide a base image for, such a\ns Node.js 19. You can also use OS-only base images to implement a custom runtime\n. To make the image compatible with Lambda, you must include a runtime interface\n client for your language in the image. Using a non-AWS base image You can use a\nn alternative base image from another container registry, such as Alpine Linux o\nr Debian. You can also use a custom image created by your organization. To make \nthe image compatible with Lambda, you must include a runtime interface client fo\nr your language in the image. Tip To reduce the time it takes for Lambda contain\ner functions to become active, see Use multi-stage builds in the Docker document\nation. To build efficient container images, follow the Best practices for writin\ng Dockerfiles. To create a Lambda function from a container image, build your im\nage locally and upload it to an Amazon Elastic Container Registry (Amazon ECR) r\nepository. Then, specify the repository URI when you create the function. The Am\nazon ECR repository must be in the same AWS Region as the Lambda function. You c\nan create a function using an image in a different AWS account, as long as the i\nmage is in the same Region as the Lambda function. For more information, see Ama\nzon ECR cross-account permissions. Note Lambda does not support Amazon ECR FIPS \nendpoints for container images. If your repository URI includes ecr-fips, you ar\ne using a FIPS endpoint. Example: 111122223333.dkr.ecr-fips.us-east-1.amazonaws.\ncom. This page explains the base image types and requirements for creating Lambd\na-compatible container images. Note You cannot change the deployment package typ\ne (.zip or container image) for an existing function. For example, you cannot co\nnvert a container image function to use a .zip file archive. You must create a n\new function. Topics Requirements Using an AWS base image for Lambda Using an AWS\n OS-only base image Using a non-AWS base image Runtime interface clients Amazon \nECR permissions Function lifecycle Requirements Install the AWS CLI version 2 an\nd the Docker CLI. Additionally, note the following requirements: The container i\nmage must implement the Using the Lambda runtime API for custom runtimes. The AW\nS open-source runtime interface clients implement the API. You can add a runtime\n interface client to your preferred base image to make it compatible with Lambda\n. The container image must be able to run on a read-only file system. Your funct\nion code can access a writable /tmp directory with between 512 MB and 10,240 MB,\n in 1-MB increments, of storage. The default Lambda user must be able to read al\nl the files required to run your function code. Lambda follows security best pra\nctices by defining a default Linux user with least-privileged permissions. This \nmeans that you don't need to specify a USER in your Dockerfile. Verify that your\n application code does not rely on files that other Linux users are restricted f\nrom running. Lambda supports only Linux-based container images. Lambda provides \nmulti-architecture base images. However, the image you build for your function m\nust target only one of the architectures. Lambda does not support functions that\n use multi-architecture container images. Using an AWS base image for Lambda You\n can use one of the AWS base images for Lambda to build the container image for \nyour function code. The base images are preloaded with a language runtime and ot\nher components required to run a container image on Lambda. You add your functio\nn code and dependencies to the base image and then package it as a container ima\nge. AWS periodically provides updates to the AWS base images for Lambda. If your\n Dockerfile includes the image name in the FROM property, your Docker client pul\nls the latest version of the image from the Amazon ECR repository. To use the up\ndated base image, you must rebuild your container image and update the function \ncode. The Node.js 20, Python 3.12, Java 21, .NET 8, Ruby 3.3, and later base ima\nges are based on the Amazon Linux 2023 minimal container image. Earlier base ima\nges use Amazon Linux 2. AL2023 provides several advantages over Amazon Linux 2, \nincluding a smaller deployment footprint and updated versions of libraries such \nas glibc. AL2023-based images use microdnf (symlinked as dnf) as the package man\nager instead of yum, which is the default package manager in Amazon Linux 2. mic\nrodnf is a standalone implementation of dnf. For a list of packages that are inc\nluded in AL2023-based images, refer to the Minimal Container columns in Comparin\ng packages installed on Amazon Linux 2023 Container Images. For more information\n about the differences between AL2023 and Amazon Linux 2, see Introducing the Am\nazon Linux 2023 runtime for AWS Lambda on the AWS Compute Blog. Note To run AL20\n23-based images locally, including with AWS Serverless Application Model (AWS SA\nM), you must use Docker version 20.10.10 or later. To build a container image us\ning an AWS base image, choose the instructions for your preferred language: Node\n.js TypeScript (uses a Node.js base image) Python Java Go .NET Ruby Using an AWS\n OS-only base image AWS OS-only base images contain an Amazon Linux distribution\n and the runtime interface emulator. These images are commonly used to create co\nntainer images for compiled languages, such as Go and Rust, and for a language o\nr language version that Lambda doesn't provide a base image for, such as Node.js\n 19. You can also use OS-only base images to implement a custom runtime. To make\n the image compatible with Lambda, you must include a runtime interface client f\nor your language in the image. Tags Runtime Operating system Dockerfile Deprecat\nion al2023 OS-only Runtime Amazon Linux 2023 Dockerfile for OS-only Runtime on G\nitHub Not scheduled al2 OS-only Runtime Amazon Linux 2 Dockerfile for OS-only Ru\nntime on GitHub Not scheduled Amazon Elastic Container Registry Public Gallery: \ngallery.ecr.aws/lambda/provided Using a non-AWS base image Lambda supports any i\nmage that conforms to one of the following image manifest formats: Docker image \nmanifest V2, schema 2 (used with Docker version 1.10 and newer) Open Container I\nnitiative (OCI) Specifications (v1.0.0 and up) Lambda supports a maximum uncompr\nessed image size of 10 GB, including all layers. Note To make the image compatib\nle with Lambda, you must include a runtime interface client for your language in\n the image. Runtime interface clients If you use an OS-only base image or an alt\nernative base image, you must include a runtime interface client in your image. \nThe runtime interface client must extend the Using the Lambda runtime API for cu\nstom runtimes, which manages the interaction between Lambda and your function co\nde. AWS provides open-source runtime interface clients for the following languag\nes: Node.js Python Java .NET Go Ruby Rust  The Rust runtime client is an experim\nental package. It is subject to change and intended only for evaluation purposes\n. If you're using a language that doesn't have an AWS-provided runtime interface\n client, you must create your own. Amazon ECR permissions Before you create a La\nmbda function from a container image, you must build the image locally and uploa\nd it to an Amazon ECR repository. When you create the function, specify the Amaz\non ECR repository URI. Make sure that the permissions for the user or role that \ncreates the function includes GetRepositoryPolicy and SetRepositoryPolicy. For e\nxample, use the IAM console to create a role with the following policy: {  \\\"Ver\nsion\\\": \\\"2012-10-17\\\",  \\\"Statement\\\": [    {      \\\"Sid\\\": \\\"VisualEditor0\\\", \n     \\\"Effect\\\": \\\"Allow\\\",      \\\"Action\\\": [        \\\"ecr:SetRepositoryPolicy\\\n\",        \\\"ecr:GetRepositoryPolicy\\\"      ],      \\\"Resource\\\": \\\"arn:aws:ecr:u\ns-east-1:111122223333:repository/hello-world\\\"    }  ]} Amazon ECR repository po\nlicies For a function in the same account as the container image in Amazon ECR, \nyou can add ecr:BatchGetImage and ecr:GetDownloadUrlForLayer permissions to your\n Amazon ECR repository policy. The following example shows the minimum policy: {\n        \\\"Sid\\\": \\\"LambdaECRImageRetrievalPolicy\\\",        \\\"Effect\\\": \\\"Allow\\\"\n,        \\\"Principal\\\": {          \\\"Service\\\": \\\"lambda.amazonaws.com\\\"        \n},        \\\"Action\\\": [          \\\"ecr:BatchGetImage\\\",          \\\"ecr:GetDownlo\nadUrlForLayer\\\"        ]    }   For more information about Amazon ECR repository\n permissions, see Private repository policies in the Amazon Elastic Container Re\ngistry User Guide. If the Amazon ECR repository does not include these permissio\nns, Lambda adds ecr:BatchGetImage and ecr:GetDownloadUrlForLayer to the containe\nr image repository permissions. Lambda can add these permissions only if the pri\nncipal calling Lambda has ecr:getRepositoryPolicy and ecr:setRepositoryPolicy pe\nrmissions. To view or edit your Amazon ECR repository permissions, follow the di\nrections in Setting a private repository policy statement in the Amazon Elastic \nContainer Registry User Guide. Amazon ECR cross-account permissions A different \naccount in the same region can create a function that uses a container image own\ned by your account. In the following example, your Amazon ECR repository permiss\nions policy needs the following statements to grant access to account number 123\n456789012. CrossAccountPermission  Allows account 123456789012 to create and upd\nate Lambda functions that use images from this ECR repository. LambdaECRImageCro\nssAccountRetrievalPolicy  Lambda will eventually set a function's state to inact\nive if it is not invoked for an extended period. This statement is required so t\nhat Lambda can retrieve the container image for optimization and caching on beha\nlf of the function owned by 123456789012. Example  Add cross-account permission \nto your repository {  \\\"Version\\\": \\\"2012-10-17\\\",  \\\"Statement\\\": [    {      \\\n\"Sid\\\": \\\"CrossAccountPermission\\\",      \\\"Effect\\\": \\\"Allow\\\",      \\\"Action\\\":\n [        \\\"ecr:BatchGetImage\\\",        \\\"ecr:GetDownloadUrlForLayer\\\"      ],  \n    \\\"Principal\\\": {        \\\"AWS\\\": \\\"arn:aws:iam::123456789012:root\\\"      }  \n  },    {      \\\"Sid\\\": \\\"LambdaECRImageCrossAccountRetrievalPolicy\\\",      \\\"Ef\nfect\\\": \\\"Allow\\\",      \\\"Action\\\": [        \\\"ecr:BatchGetImage\\\",        \\\"ecr\n:GetDownloadUrlForLayer\\\"      ],      \\\"Principal\\\": {        \\\"Service\\\": \\\"la\nmbda.amazonaws.com\\\"      },      \\\"Condition\\\": {        \\\"StringLike\\\": {     \n     \\\"aws:sourceARN\\\": \\\"arn:aws:lambda:us-east-1:123456789012:function:*\\\"    \n    }      }    }  ]} To give access to multiple accounts, you add the account I\nDs to the Principal list in the CrossAccountPermission policy and to the Conditi\non evaluation list in the LambdaECRImageCrossAccountRetrievalPolicy. If you are \nworking with multiple accounts in an AWS Organization, we recommend that you enu\nmerate each account ID in the ECR permissions policy. This approach aligns with \nthe AWS security best practice of setting narrow permissions in IAM policies. In\n addition to Lambda permissions, the user or role that creates the function must\n also have BatchGetImage and GetDownloadUrlForLayer permissions. Function lifecy\ncle After you upload a new or updated container image, Lambda optimizes the imag\ne before the function can process invocations. The optimization process can take\n a few seconds. The function remains in the Pending state until the process comp\nletes, when the state transitions to Active. You can't invoke the function until\n it reaches the Active state. If a function is not invoked for multiple weeks, L\nambda reclaims its optimized version, and the function transitions to the Inacti\nve state. To reactivate the function, you must invoke it. Lambda rejects the fir\nst invocation and the function enters the Pending state until Lambda re-optimize\ns the image. The function then returns to the Active state. Lambda periodically \nfetches the associated container image from the Amazon ECR repository. If the co\nrresponding container image no longer exists on Amazon ECR or permissions are re\nvoked, the function enters the Failed state, and Lambda returns a failure for an\ny function invocations. You can use the Lambda API to get information about a fu\nnction's state. For more information, see Lambda function states. Javascript is \ndisabled or is unavailable in your browser. To use the Amazon Web Services Docum\nentation, Javascript must be enabled. Please refer to your browser's Help pages \nfor instructions. Document Conventions Encryption Memory Did this page help you?\n - Yes Thanks for letting us know we're doing a good job! If you've got a moment\n, please tell us what we did right so we can do more of it. Did this page help y\nou? - No Thanks for letting us know this page needs work. We're sorry we let you\n down. If you've got a moment, please tell us how we can make the documentation \nbetter.",
  "body": "List(HashMap(Deprecation -> Not scheduled, Operating system -> Amazon Linux 2023\n, Dockerfile -> Dockerfile for OS-only Runtime on GitHub, Runtime -> OS-only Run\ntime, Tags -> al2023), HashMap(Deprecation -> Not scheduled, Operating system ->\n Amazon Linux 2, Dockerfile -> Dockerfile for OS-only Runtime on GitHub, Runtime\n -> OS-only Runtime, Tags -> al2))",
  "code": "Map(code -> ecr-fips, language -> code)Map(code -> 111122223333.dkr.ecr-fips.us-\neast-1.amazonaws.com, language -> code)Map(code -> /tmp, language -> code)Map(co\nde -> glibc, language -> code)Map(code -> microdnf, language -> code)Map(code ->\n dnf, language -> code)Map(code -> yum, language -> code)Map(code -> microdnf, l\nanguage -> code)Map(code -> dnf, language -> code)Map(code -> GetRepositoryPolic\ny, language -> code)Map(code -> SetRepositoryPolicy, language -> code)Map(code -\n> {  \\\"Version\\\": \\\"2012-10-17\\\",  \\\"Statement\\\": [    {      \\\"Sid\\\": \\\"VisualE\nditor0\\\",      \\\"Effect\\\": \\\"Allow\\\",      \\\"Action\\\": [        \\\"ecr:SetReposit\noryPolicy\\\",        \\\"ecr:GetRepositoryPolicy\\\"      ],      \\\"Resource\\\": \\\"arn\n:aws:ecr:us-east-1:111122223333:repository/hello-world\\\"    }  ]}, language -> p\nrogramlisting)Map(code -> {  \\\"Version\\\": \\\"2012-10-17\\\",  \\\"Statement\\\": [    {\n      \\\"Sid\\\": \\\"VisualEditor0\\\",      \\\"Effect\\\": \\\"Allow\\\",      \\\"Action\\\": [\n        \\\"ecr:SetRepositoryPolicy\\\",        \\\"ecr:GetRepositoryPolicy\\\"      ], \n     \\\"Resource\\\": \\\"arn:aws:ecr:us-east-1:111122223333:repository/hello-world\\\"\n    }  ]}, language -> nohighlight)Map(code -> us-east-1, language -> replaceabl\ne)Map(code -> :111122223333, language -> replaceable)Map(code -> hello-world, la\nnguage -> replaceable)Map(code -> ecr:BatchGetImage, language -> code)Map(code -\n> ecr:GetDownloadUrlForLayer, language -> code)Map(code -> {        \\\"Sid\\\": \\\"L\nambdaECRImageRetrievalPolicy\\\",        \\\"Effect\\\": \\\"Allow\\\",        \\\"Principal\n\\\": {          \\\"Service\\\": \\\"lambda.amazonaws.com\\\"        },        \\\"Action\\\"\n: [          \\\"ecr:BatchGetImage\\\",          \\\"ecr:GetDownloadUrlForLayer\\\"     \n   ]    }, language -> programlisting)Map(code -> {        \\\"Sid\\\": \\\"LambdaECRI\nmageRetrievalPolicy\\\",        \\\"Effect\\\": \\\"Allow\\\",        \\\"Principal\\\": {    \n      \\\"Service\\\": \\\"lambda.amazonaws.com\\\"        },        \\\"Action\\\": [      \n    \\\"ecr:BatchGetImage\\\",          \\\"ecr:GetDownloadUrlForLayer\\\"        ]    }\n, language -> )Map(code -> ecr:BatchGetImage, language -> code)Map(code -> ecr:G\netDownloadUrlForLayer, language -> code)Map(code -> ecr:getRepositoryPolicy, lan\nguage -> code)Map(code -> ecr:setRepositoryPolicy, language -> code)Map(code -> \n{  \\\"Version\\\": \\\"2012-10-17\\\",  \\\"Statement\\\": [    {      \\\"Sid\\\": \\\"CrossAcco\nuntPermission\\\",      \\\"Effect\\\": \\\"Allow\\\",      \\\"Action\\\": [        \\\"ecr:Bat\nchGetImage\\\",        \\\"ecr:GetDownloadUrlForLayer\\\"      ],      \\\"Principal\\\": \n{        \\\"AWS\\\": \\\"arn:aws:iam::123456789012:root\\\"      }    },    {      \\\"Si\nd\\\": \\\"LambdaECRImageCrossAccountRetrievalPolicy\\\",      \\\"Effect\\\": \\\"Allow\\\", \n     \\\"Action\\\": [        \\\"ecr:BatchGetImage\\\",        \\\"ecr:GetDownloadUrlForL\nayer\\\"      ],      \\\"Principal\\\": {        \\\"Service\\\": \\\"lambda.amazonaws.com\\\n\"      },      \\\"Condition\\\": {        \\\"StringLike\\\": {          \\\"aws:sourceAR\nN\\\": \\\"arn:aws:lambda:us-east-1:123456789012:function:*\\\"        }      }    }  \n]}, language -> programlisting)Map(code -> {  \\\"Version\\\": \\\"2012-10-17\\\",  \\\"St\natement\\\": [    {      \\\"Sid\\\": \\\"CrossAccountPermission\\\",      \\\"Effect\\\": \\\"A\nllow\\\",      \\\"Action\\\": [        \\\"ecr:BatchGetImage\\\",        \\\"ecr:GetDownloa\ndUrlForLayer\\\"      ],      \\\"Principal\\\": {        \\\"AWS\\\": \\\"arn:aws:iam::1234\n56789012:root\\\"      }    },    {      \\\"Sid\\\": \\\"LambdaECRImageCrossAccountRetr\nievalPolicy\\\",      \\\"Effect\\\": \\\"Allow\\\",      \\\"Action\\\": [        \\\"ecr:Batch\nGetImage\\\",        \\\"ecr:GetDownloadUrlForLayer\\\"      ],      \\\"Principal\\\": { \n       \\\"Service\\\": \\\"lambda.amazonaws.com\\\"      },      \\\"Condition\\\": {      \n  \\\"StringLike\\\": {          \\\"aws:sourceARN\\\": \\\"arn:aws:lambda:us-east-1:12345\n6789012:function:*\\\"        }      }    }  ]}, language -> nohighlight)Map(code \n-> 123456789012, language -> replaceable)Map(code -> us-east-1, language -> repl\naceable)Map(code -> 123456789012, language -> replaceable)Map(code -> CrossAccou\nntPermission, language -> code)Map(code -> LambdaECRImageCrossAccountRetrievalPo\nlicy, language -> code)Map(code -> BatchGetImage, language -> code)Map(code -> G\netDownloadUrlForLayer, language -> code)Map(code -> Pending, language -> code)Ma\np(code -> Active, language -> code)Map(code -> Active, language -> code)Map(code\n -> Inactive, language -> code)Map(code -> Pending, language -> code)Map(code ->\n Active, language -> code)Map(code -> Failed, language -> code)",
  "table": ""
}
{
  "url": "https://docs.aws.amazon.com/linux/al2023/ug/minimal-container.html",
  "pageType": "UserGuidePage",
  "title": "AL2023 Minimal container image - Amazon Linux 2023 AWSDocumentationAmazon LinuxU\nser Guide Minimal Container image sizeUsing the AL2023 Minimal Container image A\nL2023 Minimal container image Note The standard AL2023 container images are suit\nable for most use cases, and adapting to the minimal container image is likely t\no be more work than adapting to the AL2023 base container image. The AL2023 mini\nmal container image, introduced in AL2023.2, differs from the base container ima\nge because it contains only the bare minimum packages needed to install other pa\nckages. The minimal container image is designed to be a minimal set of packages,\n not a convenient set of packages . The AL2023 minimal container image is built \nfrom software components already available in AL2023. The key difference in the \nminimal container image is using microdnf to provide the dnf package manager rat\nher than the fully featured Python based dnf. This enables the minimal container\n image to be smaller with the trade-off of not having the full feature set of th\ne dnf package manager which is included in the AL2023 AMIs and base container im\nage. The AL2023 minimal container image forms the base of the provided.al2023 AW\nS Lambda runtime environment. For a detailed list of packages included in the mi\nnimal container image, see Comparing packages installed on Amazon Linux 2023 Con\ntainer Images. Minimal Container image size Because the AL2023 minimal container\n image contains fewer packages than the AL2023 base container image, it is also \nsignificantly smaller. The following table compares the container image options \nof current and past releases of Amazon Linux. Note Image Size is as-shown on Ama\nzon Linux on Amazon ECR Public Gallery. Image Version Image Size Note Amazon Lin\nux 1 (AL1) 2018.03.0.20230918.0 62.3MB x86-64 only Amazon Linux 2 2.0.20230926.0\n 64.2MB aarch64 is 1.6MB larger than x86-64 Amazon Linux 2023 base container ima\nge 2023.2.20231002.0 52.4MB Amazon Linux 2023 minimal container image 2023.2.202\n31002.0-minimal 35.2MB Using the AL2023 Minimal Container image The AL2023 minim\nal container image is available on ECR and the 2023-minimal tag will always poin\nt to the latest AL2023 based minimal container image, while the minimal tag may \nbe updated to a newer version of Amazon Linux than AL2023. You can pull these ta\ngs using docker with the following example: $ docker pull public.ecr.aws/amazonl\ninux/amazonlinux:minimal $ docker pull public.ecr.aws/amazonlinux/amazonlinux:20\n23-minimal The following example shows a Dockerfile that takes the minimal conta\niner image and installs GCC on top of it : FROM public.ecr.aws/amazonlinux/amazo\nnlinux:2023-minimalRUN dnf install -y gcc && dnf clean all Javascript is disable\nd or is unavailable in your browser. To use the Amazon Web Services Documentatio\nn, Javascript must be enabled. Please refer to your browser's Help pages for ins\ntructions. Document Conventions AL2023 Base Container Image Building bare-bones \nAL2023 container images Did this page help you? - Yes Thanks for letting us know\n we're doing a good job! If you've got a moment, please tell us what we did righ\nt so we can do more of it. Did this page help you? - No Thanks for letting us kn\now this page needs work. We're sorry we let you down. If you've got a moment, pl\nease tell us how we can make the documentation better.",
  "body": "List(Map(Image -> Amazon Linux 1 (AL1), Version -> 2018.03.0.20230918.0, Image S\nize -> 62.3MB, Note -> x86-64 only), Map(Image -> Amazon Linux 2, Version -> 2.0\n.20230926.0, Image Size -> 64.2MB, Note -> aarch64 is 1.6MB larger than x86-64),\n Map(Image -> Amazon Linux 2023 base container image, Version -> 2023.2.20231002\n.0, Image Size -> 52.4MB, Note -> ), Map(Image -> Amazon Linux 2023 minimal cont\nainer image, Version -> 2023.2.20231002.0-minimal, Image Size -> 35.2MB, Note ->\n ))",
  "code": "Map(code -> microdnf, language -> code)Map(code -> dnf, language -> code)Map(cod\ne -> dnf, language -> code)Map(code -> dnf, language -> code)Map(code -> provide\nd.al2023, language -> code)Map(code -> x86-64, language -> code)Map(code -> aarc\nh64, language -> code)Map(code -> x86-64, language -> code)Map(code -> 2023-mini\nmal, language -> code)Map(code -> minimal, language -> code)Map(code -> docker, \nlanguage -> code)Map(code -> $ docker pull public.ecr.aws/amazonlinux/amazonlinu\nx:minimal, language -> programlisting)Map(code -> $ docker pull public.ecr.aws/a\nmazonlinux/amazonlinux:minimal, language -> sh)Map(code -> $, language -> prompt\n)Map(code -> docker pull public.ecr.aws/amazonlinux/amazonlinux:minimal, languag\ne -> userinput)Map(code -> $ docker pull public.ecr.aws/amazonlinux/amazonlinux:\n2023-minimal, language -> programlisting)Map(code -> $ docker pull public.ecr.aw\ns/amazonlinux/amazonlinux:2023-minimal, language -> sh)Map(code -> $, language -\n> prompt)Map(code -> docker pull public.ecr.aws/amazonlinux/amazonlinux:2023-min\nimal, language -> userinput)Map(code -> Dockerfile, language -> code)Map(code ->\n FROM public.ecr.aws/amazonlinux/amazonlinux:2023-minimalRUN dnf install -y gcc \n&& dnf clean all, language -> programlisting)Map(code -> FROM public.ecr.aws/ama\nzonlinux/amazonlinux:2023-minimalRUN dnf install -y gcc && dnf clean all, langua\nge -> dockerfile)",
  "table": ""
}
{
  "url": "https://docs.aws.amazon.com/linux/al2023/ug/al2023-container-image-types.html",
  "pageType": "UserGuidePage",
  "title": "Comparing packages installed on Amazon Linux 2023 Container Images - Amazon Linu\nx 2023 AWSDocumentationAmazon LinuxUser Guide Comparing packages installed on Am\nazon Linux 2023 Container Images A comparison of the RPMs present on the AL2023 \nbase container image compared with the RPMs present on the AL2023 minimal contai\nner image. Package Container Minimal Container alternatives 1.15 1.15 amazon-lin\nux-repo-cdn 2023.6.20241031 2023.6.20241031 audit-libs 3.0.6 3.0.6 basesystem 11\n 11 bash 5.2.15 5.2.15 bzip2-libs 1.0.8 1.0.8 ca-certificates 2023.2.68 2023.2.6\n8 coreutils-single 8.32 8.32 crypto-policies 20220428 20220428 curl-minimal 8.5.\n0 8.5.0 dnf 4.14.0 dnf-data 4.14.0 4.14.0 elfutils-default-yama-scope 0.188 elfu\ntils-libelf 0.188 elfutils-libs 0.188 expat 2.5.0 file-libs 5.39 5.39 filesystem\n 3.14 3.14 gawk 5.1.0 5.1.0 gdbm-libs 1.19 glib2 2.74.7 2.74.7 glibc 2.34 2.34 g\nlibc-common 2.34 2.34 glibc-minimal-langpack 2.34 2.34 gmp 6.2.1 6.2.1 gnupg2-mi\nnimal 2.3.7 2.3.7 gobject-introspection 1.73.0 gpgme 1.15.1 1.15.1 grep 3.8 3.8 \njson-c 0.14 0.14 keyutils-libs 1.6.3 1.6.3 krb5-libs 1.21.3 1.21.3 libacl 2.3.1 \n2.3.1 libarchive 3.7.4 3.7.4 libassuan 2.5.5 2.5.5 libattr 2.5.1 2.5.1 libblkid \n2.37.4 2.37.4 libcap 2.48 2.48 libcap-ng 0.8.2 0.8.2 libcom_err 1.46.5 1.46.5 li\nbcomps 0.1.20 libcurl-minimal 8.5.0 8.5.0 libdnf 0.69.0 0.69.0 libffi 3.4.4 3.4.\n4 libgcc 11.4.1 11.4.1 libgcrypt 1.10.2 1.10.2 libgomp 11.4.1 libgpg-error 1.42 \n1.42 libidn2 2.3.2 2.3.2 libmodulemd 2.13.0 2.13.0 libmount 2.37.4 2.37.4 libngh\nttp2 1.59.0 1.59.0 libpeas 1.32.0 libpsl 0.21.1 0.21.1 librepo 1.14.5 1.14.5 lib\nreport-filesystem 2.15.2 2.15.2 libselinux 3.4 3.4 libsepol 3.4 3.4 libsigsegv 2\n.13 2.13 libsmartcols 2.37.4 2.37.4 libsolv 0.7.22 0.7.22 libstdc++ 11.4.1 11.4.\n1 libtasn1 4.19.0 4.19.0 libunistring 0.9.10 0.9.10 libuuid 2.37.4 2.37.4 libver\nto 0.3.2 0.3.2 libxcrypt 4.4.33 libxml2 2.10.4 2.10.4 libyaml 0.2.5 0.2.5 libzst\nd 1.5.5 1.5.5 lua-libs 5.4.4 5.4.4 lz4-libs 1.9.4 1.9.4 microdnf 3.10.0 microdnf\n-dnf 3.10.0 mpfr 4.1.0 4.1.0 ncurses-base 6.2 6.2 ncurses-libs 6.2 6.2 npth 1.6 \n1.6 openssl-libs 3.0.8 3.0.8 p11-kit 0.24.1 0.24.1 p11-kit-trust 0.24.1 0.24.1 p\ncre2 10.40 10.40 pcre2-syntax 10.40 10.40 popt 1.18 1.18 publicsuffix-list-dafsa\n 20240212 20240212 python3 3.9.16 python3-dnf 4.14.0 python3-gpg 1.15.1 python3-\nhawkey 0.69.0 python3-libcomps 0.1.20 python3-libdnf 0.69.0 python3-libs 3.9.16 \npython3-pip-wheel 21.3.1 python3-rpm 4.16.1.3 python3-setuptools-wheel 59.6.0 re\nadline 8.1 8.1 rpm 4.16.1.3 4.16.1.3 rpm-build-libs 4.16.1.3 rpm-libs 4.16.1.3 4\n.16.1.3 rpm-sign-libs 4.16.1.3 sed 4.8 4.8 setup 2.13.7 2.13.7 sqlite-libs 3.40.\n0 3.40.0 system-release 2023.6.20241031 2023.6.20241031 tzdata 2024a xz-libs 5.2\n.5 5.2.5 yum 4.14.0 zlib 1.2.11 1.2.11 Javascript is disabled or is unavailable \nin your browser. To use the Amazon Web Services Documentation, Javascript must b\ne enabled. Please refer to your browser's Help pages for instructions. Document \nConventions Building bare-bones AL2023 container images AL2023 Minimal AMI compa\nred to container images Did this page help you? - Yes Thanks for letting us know\n we're doing a good job! If you've got a moment, please tell us what we did righ\nt so we can do more of it. Did this page help you? - No Thanks for letting us kn\now this page needs work. We're sorry we let you down. If you've got a moment, pl\nease tell us how we can make the documentation better.",
  "body": "List(Map(Package -> alternatives, Container -> 1.15, Minimal Container -> 1.15),\n Map(Package -> amazon-linux-repo-cdn, Container -> 2023.6.20241031, Minimal Con\ntainer -> 2023.6.20241031), Map(Package -> audit-libs, Container -> 3.0.6, Minim\nal Container -> 3.0.6), Map(Package -> basesystem, Container -> 11, Minimal Cont\nainer -> 11), Map(Package -> bash, Container -> 5.2.15, Minimal Container -> 5.2\n.15), Map(Package -> bzip2-libs, Container -> 1.0.8, Minimal Container -> 1.0.8)\n, Map(Package -> ca-certificates, Container -> 2023.2.68, Minimal Container -> 2\n023.2.68), Map(Package -> coreutils-single, Container -> 8.32, Minimal Container\n -> 8.32), Map(Package -> crypto-policies, Container -> 20220428, Minimal Contai\nner -> 20220428), Map(Package -> curl-minimal, Container -> 8.5.0, Minimal Conta\niner -> 8.5.0), Map(Package -> dnf, Container -> 4.14.0, Minimal Container -> ),\n Map(Package -> dnf-data, Container -> 4.14.0, Minimal Container -> 4.14.0), Map\n(Package -> elfutils-default-yama-scope, Container -> 0.188, Minimal Container -\n> ), Map(Package -> elfutils-libelf, Container -> 0.188, Minimal Container -> ),\n Map(Package -> elfutils-libs, Container -> 0.188, Minimal Container -> ), Map(P\nackage -> expat, Container -> 2.5.0, Minimal Container -> ), Map(Package -> file\n-libs, Container -> 5.39, Minimal Container -> 5.39), Map(Package -> filesystem,\n Container -> 3.14, Minimal Container -> 3.14), Map(Package -> gawk, Container -\n> 5.1.0, Minimal Container -> 5.1.0), Map(Package -> gdbm-libs, Container -> 1.1\n9, Minimal Container -> ), Map(Package -> glib2, Container -> 2.74.7, Minimal Co\nntainer -> 2.74.7), Map(Package -> glibc, Container -> 2.34, Minimal Container -\n> 2.34), Map(Package -> glibc-common, Container -> 2.34, Minimal Container -> 2.\n34), Map(Package -> glibc-minimal-langpack, Container -> 2.34, Minimal Container\n -> 2.34), Map(Package -> gmp, Container -> 6.2.1, Minimal Container -> 6.2.1), \nMap(Package -> gnupg2-minimal, Container -> 2.3.7, Minimal Container -> 2.3.7), \nMap(Package -> gobject-introspection, Container -> , Minimal Container -> 1.73.0\n), Map(Package -> gpgme, Container -> 1.15.1, Minimal Container -> 1.15.1), Map(\nPackage -> grep, Container -> 3.8, Minimal Container -> 3.8), Map(Package -> jso\nn-c, Container -> 0.14, Minimal Container -> 0.14), Map(Package -> keyutils-libs\n, Container -> 1.6.3, Minimal Container -> 1.6.3), Map(Package -> krb5-libs, Con\ntainer -> 1.21.3, Minimal Container -> 1.21.3), Map(Package -> libacl, Container\n -> 2.3.1, Minimal Container -> 2.3.1), Map(Package -> libarchive, Container -> \n3.7.4, Minimal Container -> 3.7.4), Map(Package -> libassuan, Container -> 2.5.5\n, Minimal Container -> 2.5.5), Map(Package -> libattr, Container -> 2.5.1, Minim\nal Container -> 2.5.1), Map(Package -> libblkid, Container -> 2.37.4, Minimal Co\nntainer -> 2.37.4), Map(Package -> libcap, Container -> 2.48, Minimal Container \n-> 2.48), Map(Package -> libcap-ng, Container -> 0.8.2, Minimal Container -> 0.8\n.2), Map(Package -> libcom_err, Container -> 1.46.5, Minimal Container -> 1.46.5\n), Map(Package -> libcomps, Container -> 0.1.20, Minimal Container -> ), Map(Pac\nkage -> libcurl-minimal, Container -> 8.5.0, Minimal Container -> 8.5.0), Map(Pa\nckage -> libdnf, Container -> 0.69.0, Minimal Container -> 0.69.0), Map(Package \n-> libffi, Container -> 3.4.4, Minimal Container -> 3.4.4), Map(Package -> libgc\nc, Container -> 11.4.1, Minimal Container -> 11.4.1), Map(Package -> libgcrypt, \nContainer -> 1.10.2, Minimal Container -> 1.10.2), Map(Package -> libgomp, Conta\niner -> 11.4.1, Minimal Container -> ), Map(Package -> libgpg-error, Container -\n> 1.42, Minimal Container -> 1.42), Map(Package -> libidn2, Container -> 2.3.2, \nMinimal Container -> 2.3.2), Map(Package -> libmodulemd, Container -> 2.13.0, Mi\nnimal Container -> 2.13.0), Map(Package -> libmount, Container -> 2.37.4, Minima\nl Container -> 2.37.4), Map(Package -> libnghttp2, Container -> 1.59.0, Minimal \nContainer -> 1.59.0), Map(Package -> libpeas, Container -> , Minimal Container -\n> 1.32.0), Map(Package -> libpsl, Container -> 0.21.1, Minimal Container -> 0.21\n.1), Map(Package -> librepo, Container -> 1.14.5, Minimal Container -> 1.14.5), \nMap(Package -> libreport-filesystem, Container -> 2.15.2, Minimal Container -> 2\n.15.2), Map(Package -> libselinux, Container -> 3.4, Minimal Container -> 3.4), \nMap(Package -> libsepol, Container -> 3.4, Minimal Container -> 3.4), Map(Packag\ne -> libsigsegv, Container -> 2.13, Minimal Container -> 2.13), Map(Package -> l\nibsmartcols, Container -> 2.37.4, Minimal Container -> 2.37.4), Map(Package -> l\nibsolv, Container -> 0.7.22, Minimal Container -> 0.7.22), Map(Package -> libstd\nc++, Container -> 11.4.1, Minimal Container -> 11.4.1), Map(Package -> libtasn1,\n Container -> 4.19.0, Minimal Container -> 4.19.0), Map(Package -> libunistring,\n Container -> 0.9.10, Minimal Container -> 0.9.10), Map(Package -> libuuid, Cont\nainer -> 2.37.4, Minimal Container -> 2.37.4), Map(Package -> libverto, Containe\nr -> 0.3.2, Minimal Container -> 0.3.2), Map(Package -> libxcrypt, Container -> \n4.4.33, Minimal Container -> ), Map(Package -> libxml2, Container -> 2.10.4, Min\nimal Container -> 2.10.4), Map(Package -> libyaml, Container -> 0.2.5, Minimal C\nontainer -> 0.2.5), Map(Package -> libzstd, Container -> 1.5.5, Minimal Containe\nr -> 1.5.5), Map(Package -> lua-libs, Container -> 5.4.4, Minimal Container -> 5\n.4.4), Map(Package -> lz4-libs, Container -> 1.9.4, Minimal Container -> 1.9.4),\n Map(Package -> microdnf, Container -> , Minimal Container -> 3.10.0), Map(Packa\nge -> microdnf-dnf, Container -> , Minimal Container -> 3.10.0), Map(Package -> \nmpfr, Container -> 4.1.0, Minimal Container -> 4.1.0), Map(Package -> ncurses-ba\nse, Container -> 6.2, Minimal Container -> 6.2), Map(Package -> ncurses-libs, Co\nntainer -> 6.2, Minimal Container -> 6.2), Map(Package -> npth, Container -> 1.6\n, Minimal Container -> 1.6), Map(Package -> openssl-libs, Container -> 3.0.8, Mi\nnimal Container -> 3.0.8), Map(Package -> p11-kit, Container -> 0.24.1, Minimal \nContainer -> 0.24.1), Map(Package -> p11-kit-trust, Container -> 0.24.1, Minimal\n Container -> 0.24.1), Map(Package -> pcre2, Container -> 10.40, Minimal Contain\ner -> 10.40), Map(Package -> pcre2-syntax, Container -> 10.40, Minimal Container\n -> 10.40), Map(Package -> popt, Container -> 1.18, Minimal Container -> 1.18), \nMap(Package -> publicsuffix-list-dafsa, Container -> 20240212, Minimal Container\n -> 20240212), Map(Package -> python3, Container -> 3.9.16, Minimal Container ->\n ), Map(Package -> python3-dnf, Container -> 4.14.0, Minimal Container -> ), Map\n(Package -> python3-gpg, Container -> 1.15.1, Minimal Container -> ), Map(Packag\ne -> python3-hawkey, Container -> 0.69.0, Minimal Container -> ), Map(Package ->\n python3-libcomps, Container -> 0.1.20, Minimal Container -> ), Map(Package -> p\nython3-libdnf, Container -> 0.69.0, Minimal Container -> ), Map(Package -> pytho\nn3-libs, Container -> 3.9.16, Minimal Container -> ), Map(Package -> python3-pip\n-wheel, Container -> 21.3.1, Minimal Container -> ), Map(Package -> python3-rpm,\n Container -> 4.16.1.3, Minimal Container -> ), Map(Package -> python3-setuptool\ns-wheel, Container -> 59.6.0, Minimal Container -> ), Map(Package -> readline, C\nontainer -> 8.1, Minimal Container -> 8.1), Map(Package -> rpm, Container -> 4.1\n6.1.3, Minimal Container -> 4.16.1.3), Map(Package -> rpm-build-libs, Container \n-> 4.16.1.3, Minimal Container -> ), Map(Package -> rpm-libs, Container -> 4.16.\n1.3, Minimal Container -> 4.16.1.3), Map(Package -> rpm-sign-libs, Container -> \n4.16.1.3, Minimal Container -> ), Map(Package -> sed, Container -> 4.8, Minimal \nContainer -> 4.8), Map(Package -> setup, Container -> 2.13.7, Minimal Container \n-> 2.13.7), Map(Package -> sqlite-libs, Container -> 3.40.0, Minimal Container -\n> 3.40.0), Map(Package -> system-release, Container -> 2023.6.20241031, Minimal \nContainer -> 2023.6.20241031), Map(Package -> tzdata, Container -> 2024a, Minima\nl Container -> ), Map(Package -> xz-libs, Container -> 5.2.5, Minimal Container \n-> 5.2.5), Map(Package -> yum, Container -> 4.14.0, Minimal Container -> ), Map(\nPackage -> zlib, Container -> 1.2.11, Minimal Container -> 1.2.11))",
  "code": "Map(code -> alternatives, language -> code)Map(code -> amazon-linux-repo-cdn, la\nnguage -> code)Map(code -> audit-libs, language -> code)Map(code -> basesystem, \nlanguage -> code)Map(code -> bash, language -> code)Map(code -> bzip2-libs, lang\nuage -> code)Map(code -> ca-certificates, language -> code)Map(code -> coreutils\n-single, language -> code)Map(code -> crypto-policies, language -> code)Map(code\n -> curl-minimal, language -> code)Map(code -> dnf, language -> code)Map(code ->\n dnf-data, language -> code)Map(code -> elfutils-default-yama-scope, language ->\n code)Map(code -> elfutils-libelf, language -> code)Map(code -> elfutils-libs, l\nanguage -> code)Map(code -> expat, language -> code)Map(code -> file-libs, langu\nage -> code)Map(code -> filesystem, language -> code)Map(code -> gawk, language \n-> code)Map(code -> gdbm-libs, language -> code)Map(code -> glib2, language -> c\node)Map(code -> glibc, language -> code)Map(code -> glibc-common, language -> co\nde)Map(code -> glibc-minimal-langpack, language -> code)Map(code -> gmp, languag\ne -> code)Map(code -> gnupg2-minimal, language -> code)Map(code -> gobject-intro\nspection, language -> code)Map(code -> gpgme, language -> code)Map(code -> grep,\n language -> code)Map(code -> json-c, language -> code)Map(code -> keyutils-libs\n, language -> code)Map(code -> krb5-libs, language -> code)Map(code -> libacl, l\nanguage -> code)Map(code -> libarchive, language -> code)Map(code -> libassuan, \nlanguage -> code)Map(code -> libattr, language -> code)Map(code -> libblkid, lan\nguage -> code)Map(code -> libcap, language -> code)Map(code -> libcap-ng, langua\nge -> code)Map(code -> libcom_err, language -> code)Map(code -> libcomps, langua\nge -> code)Map(code -> libcurl-minimal, language -> code)Map(code -> libdnf, lan\nguage -> code)Map(code -> libffi, language -> code)Map(code -> libgcc, language \n-> code)Map(code -> libgcrypt, language -> code)Map(code -> libgomp, language ->\n code)Map(code -> libgpg-error, language -> code)Map(code -> libidn2, language -\n> code)Map(code -> libmodulemd, language -> code)Map(code -> libmount, language \n-> code)Map(code -> libnghttp2, language -> code)Map(code -> libpeas, language -\n> code)Map(code -> libpsl, language -> code)Map(code -> librepo, language -> cod\ne)Map(code -> libreport-filesystem, language -> code)Map(code -> libselinux, lan\nguage -> code)Map(code -> libsepol, language -> code)Map(code -> libsigsegv, lan\nguage -> code)Map(code -> libsmartcols, language -> code)Map(code -> libsolv, la\nnguage -> code)Map(code -> libstdc++, language -> code)Map(code -> libtasn1, lan\nguage -> code)Map(code -> libunistring, language -> code)Map(code -> libuuid, la\nnguage -> code)Map(code -> libverto, language -> code)Map(code -> libxcrypt, lan\nguage -> code)Map(code -> libxml2, language -> code)Map(code -> libyaml, languag\ne -> code)Map(code -> libzstd, language -> code)Map(code -> lua-libs, language -\n> code)Map(code -> lz4-libs, language -> code)Map(code -> microdnf, language -> \ncode)Map(code -> microdnf-dnf, language -> code)Map(code -> mpfr, language -> co\nde)Map(code -> ncurses-base, language -> code)Map(code -> ncurses-libs, language\n -> code)Map(code -> npth, language -> code)Map(code -> openssl-libs, language -\n> code)Map(code -> p11-kit, language -> code)Map(code -> p11-kit-trust, language\n -> code)Map(code -> pcre2, language -> code)Map(code -> pcre2-syntax, language \n-> code)Map(code -> popt, language -> code)Map(code -> publicsuffix-list-dafsa, \nlanguage -> code)Map(code -> python3, language -> code)Map(code -> python3-dnf, \nlanguage -> code)Map(code -> python3-gpg, language -> code)Map(code -> python3-h\nawkey, language -> code)Map(code -> python3-libcomps, language -> code)Map(code \n-> python3-libdnf, language -> code)Map(code -> python3-libs, language -> code)M\nap(code -> python3-pip-wheel, language -> code)Map(code -> python3-rpm, language\n -> code)Map(code -> python3-setuptools-wheel, language -> code)Map(code -> read\nline, language -> code)Map(code -> rpm, language -> code)Map(code -> rpm-build-l\nibs, language -> code)Map(code -> rpm-libs, language -> code)Map(code -> rpm-sig\nn-libs, language -> code)Map(code -> sed, language -> code)Map(code -> setup, la\nnguage -> code)Map(code -> sqlite-libs, language -> code)Map(code -> system-rele\nase, language -> code)Map(code -> tzdata, language -> code)Map(code -> xz-libs, \nlanguage -> code)Map(code -> yum, language -> code)Map(code -> zlib, language ->\n code)",
  "table": ""
}
{
  "url": "https://docs.aws.amazon.com/AmazonECR/latest/userguide/repository-policies.html",
  "pageType": "UserGuidePage",
  "title": "Private repository policies in Amazon ECR - Amazon ECR AWSDocumentationAmazon EC\nRUser Guide Repository policies vs IAM policies Private repository policies in A\nmazon ECR Amazon ECR uses resource-based permissions to control access to reposi\ntories. Resource-based permissions let you specify which users or roles have acc\ness to a repository and what actions they can perform on the repository. By defa\nult, only the AWS account that created the repository has access to the reposito\nry. You can apply a repository policy that allows additional access to your repo\nsitory. Topics Repository policies vs IAM policies Private repository policy exa\nmples in Amazon ECR Setting a private repository policy statement in Amazon ECR \nRepository policies vs IAM policies Amazon ECR repository policies are a subset \nof IAM policies that are scoped for, and specifically used for, controlling acce\nss to individual Amazon ECR repositories. IAM policies are generally used to app\nly permissions for the entire Amazon ECR service but can also be used to control\n access to specific resources as well. Both Amazon ECR repository policies and I\nAM policies are used when determining which actions a specific user or role may \nperform on a repository. If a user or role is allowed to perform an action throu\ngh a repository policy but is denied permission through an IAM policy (or vice v\nersa) then the action will be denied. A user or role only needs to be allowed pe\nrmission for an action through either a repository policy or an IAM policy but n\not both for the action to be allowed. Important Amazon ECR requires that users h\nave permission to make calls to the ecr:GetAuthorizationToken API through an IAM\n policy before they can authenticate to a registry and push or pull any images f\nrom any Amazon ECR repository. Amazon ECR provides several managed IAM policies \nto control user access at varying levels; for more information, see Amazon Elast\nic Container Registry Identity-based policy examples. You can use either of thes\ne policy types to control access to your repositories, as shown in the following\n examples. This example shows an Amazon ECR repository policy, which allows for \na specific user to describe the repository and the images within the repository.\n {    \\\"Version\\\": \\\"2012-10-17\\\",    \\\"Statement\\\": [        {            \\\"Sid\n\\\": \\\"ECRRepositoryPolicy\\\",            \\\"Effect\\\": \\\"Allow\\\",            \\\"Prin\ncipal\\\": {\\\"AWS\\\": \\\"arn:aws:iam::account-id:user/username\\\"},            \\\"Acti\non\\\": [                \\\"ecr:DescribeImages\\\",                \\\"ecr:DescribeRepo\nsitories\\\"            ]        }    ]} This example shows an IAM policy that ach\nieves the same goal as above, by scoping the policy to a repository (specified b\ny the full ARN of the repository) using the resource parameter. For more informa\ntion about Amazon Resource Name (ARN) format, see Resources. {    \\\"Version\\\": \\\n\"2012-10-17\\\",    \\\"Statement\\\": [        {            \\\"Sid\\\": \\\"AllowDescribeR\nepoImage\\\",            \\\"Effect\\\": \\\"Allow\\\",            \\\"Action\\\": [          \n      \\\"ecr:DescribeImages\\\",                \\\"ecr:DescribeRepositories\\\"       \n     ],            \\\"Resource\\\": [\\\"arn:aws:ecr:region:account-id:repository/rep\nository-name\\\"]        }    ]} Javascript is disabled or is unavailable in your \nbrowser. To use the Amazon Web Services Documentation, Javascript must be enable\nd. Please refer to your browser's Help pages for instructions. Document Conventi\nons Deleting a repository Repository policy examples Did this page help you? - Y\nes Thanks for letting us know we're doing a good job! If you've got a moment, pl\nease tell us what we did right so we can do more of it. Did this page help you? \n- No Thanks for letting us know this page needs work. We're sorry we let you dow\nn. If you've got a moment, please tell us how we can make the documentation bett\ner.",
  "body": "",
  "code": "Map(code -> ecr:GetAuthorizationToken, language -> code)Map(code -> {    \\\"Versi\non\\\": \\\"2012-10-17\\\",    \\\"Statement\\\": [        {            \\\"Sid\\\": \\\"ECRRepo\nsitoryPolicy\\\",            \\\"Effect\\\": \\\"Allow\\\",            \\\"Principal\\\": {\\\"A\nWS\\\": \\\"arn:aws:iam::account-id:user/username\\\"},            \\\"Action\\\": [      \n          \\\"ecr:DescribeImages\\\",                \\\"ecr:DescribeRepositories\\\"   \n         ]        }    ]}, language -> programlisting)Map(code -> {    \\\"Version\n\\\": \\\"2012-10-17\\\",    \\\"Statement\\\": [        {            \\\"Sid\\\": \\\"ECRReposi\ntoryPolicy\\\",            \\\"Effect\\\": \\\"Allow\\\",            \\\"Principal\\\": {\\\"AWS\n\\\": \\\"arn:aws:iam::account-id:user/username\\\"},            \\\"Action\\\": [        \n        \\\"ecr:DescribeImages\\\",                \\\"ecr:DescribeRepositories\\\"     \n       ]        }    ]}, language -> JSON)Map(code -> account-id, language -> re\nplaceable)Map(code -> username, language -> replaceable)Map(code -> {    \\\"Versi\non\\\": \\\"2012-10-17\\\",    \\\"Statement\\\": [        {            \\\"Sid\\\": \\\"AllowDe\nscribeRepoImage\\\",            \\\"Effect\\\": \\\"Allow\\\",            \\\"Action\\\": [   \n             \\\"ecr:DescribeImages\\\",                \\\"ecr:DescribeRepositories\\\"\n            ],            \\\"Resource\\\": [\\\"arn:aws:ecr:region:account-id:reposit\nory/repository-name\\\"]        }    ]}, language -> programlisting)Map(code -> { \n   \\\"Version\\\": \\\"2012-10-17\\\",    \\\"Statement\\\": [        {            \\\"Sid\\\":\n \\\"AllowDescribeRepoImage\\\",            \\\"Effect\\\": \\\"Allow\\\",            \\\"Acti\non\\\": [                \\\"ecr:DescribeImages\\\",                \\\"ecr:DescribeRepo\nsitories\\\"            ],            \\\"Resource\\\": [\\\"arn:aws:ecr:region:account-\nid:repository/repository-name\\\"]        }    ]}, language -> JSON)Map(code -> re\ngion, language -> replaceable)Map(code -> account-id, language -> replaceable)Ma\np(code -> repository-name, language -> replaceable)",
  "table": ""
}
{
  "url": "https://docs.aws.amazon.com/AmazonECR/latest/userguide/set-repository-policy.html",
  "pageType": "UserGuidePage",
  "title": "Setting a private repository policy statement in Amazon ECR - Amazon ECR AWSDocu\nmentationAmazon ECRUser Guide Setting a private repository policy statement in A\nmazon ECR You can add an access policy statement to a repository in the AWS Mana\ngement Console by following the steps below. You can add multiple policy stateme\nnts per repository. For example policies, see Private repository policy examples\n in Amazon ECR. Important Amazon ECR requires that users have permission to make\n calls to the ecr:GetAuthorizationToken API through an IAM policy before they ca\nn authenticate to a registry and push or pull any images from any Amazon ECR rep\nository. Amazon ECR provides several managed IAM policies to control user access\n at varying levels; for more information, see Amazon Elastic Container Registry \nIdentity-based policy examples. To set a repository policy statement Open the Am\nazon ECR console at https://console.aws.amazon.com/ecr/repositories. From the na\nvigation bar, choose the Region that contains the repository to set a policy sta\ntement on. In the navigation pane, choose Repositories. On the Repositories page\n, choose the repository to set a policy statement on to view the contents of the\n repository. From the repository image list view, in the navigation pane, choose\n Permissions, Edit. Note If you don't see the Permissions option in the navigati\non pane, ensure that you are in the repository image list view. On the Edit perm\nissions page, choose Add statement. For Statement name, enter a name for the sta\ntement. For Effect, choose whether the policy statement will result in an allow \nor an explicit deny. For Principal, choose the scope to apply the policy stateme\nnt to. For more information, see AWS JSON Policy Elements: Principal in the IAM \nUser Guide. You can apply the statement to all authenticated AWS users by select\ning the Everyone (*) check box. For Service principal, specify the service princ\nipal name (for example, ecs.amazonaws.com) to apply the statement to a specific \nservice. For AWS Account IDs, specify an AWS account number (for example, 111122\n223333) to apply the statement to all users under a specific AWS account. Multip\nle accounts can be specified by using a comma delimited list. Important The acco\nunt you are granting permissions to must have the Region you are creating the re\npository policy in enabled, otherwise an error will occur. For IAM Entities, sel\nect the roles or users under your AWS account to apply the statement to. Note Fo\nr more complicated repository policies that are not currently supported in the A\nWS Management Console, you can apply the policy with the set-repository-policy A\nWS CLI command. For Actions, choose the scope of the Amazon ECR API operations t\nhat the policy statement should apply to from the list of individual API operati\nons. When you are finished, choose Save to set the policy. Repeat the previous s\ntep for each repository policy to add. Javascript is disabled or is unavailable \nin your browser. To use the Amazon Web Services Documentation, Javascript must b\ne enabled. Please refer to your browser's Help pages for instructions. Document \nConventions Repository policy examples Tagging a repository Did this page help y\nou? - Yes Thanks for letting us know we're doing a good job! If you've got a mom\nent, please tell us what we did right so we can do more of it. Did this page hel\np you? - No Thanks for letting us know this page needs work. We're sorry we let \nyou down. If you've got a moment, please tell us how we can make the documentati\non better.",
  "body": "",
  "code": "Map(code -> ecr:GetAuthorizationToken, language -> code)Map(code -> ecs.amazonaw\ns.com, language -> code)Map(code -> 111122223333, language -> code)",
  "table": ""
}
{
  "url": "https://docs.aws.amazon.com/ROSA/latest/userguide/getting-started.html",
  "pageType": "UserGuidePage",
  "title": "Get started with ROSA - Red Hat OpenShift Service on AWS AWSDocumentationRed Hat\n OpenShift Service on AWSUser Guide Get started with ROSA Red Hat OpenShift Serv\nice on AWS (ROSA) is a managed service that you can use to build, scale, and dep\nloy containerized applications with the Red Hat OpenShift enterprise Kubernetes \nplatform on AWS. You can use the following guides to create your first ROSA clus\nter, grant user access, deploy your first application, and learn how to revoke u\nser access and delete your cluster. Create a ROSA with HCP cluster using the ROS\nA CLI - Create your first ROSA with HCP cluster using AWS STS and the ROSA CLI. \nCreate a ROSA classic cluster that uses AWS PrivateLink - Create your first ROSA\n classic cluster using AWS PrivateLink. Create a ROSA classic cluster using the \nROSA CLI - Create your first ROSA classic cluster using AWS STS and the ROSA CLI\n. Javascript is disabled or is unavailable in your browser. To use the Amazon We\nb Services Documentation, Javascript must be enabled. Please refer to your brows\ner's Help pages for instructions. Document Conventions Architecture Set up Did t\nhis page help you? - Yes Thanks for letting us know we're doing a good job! If y\nou've got a moment, please tell us what we did right so we can do more of it. Di\nd this page help you? - No Thanks for letting us know this page needs work. We'r\ne sorry we let you down. If you've got a moment, please tell us how we can make \nthe documentation better.",
  "body": "",
  "code": "",
  "table": ""
}
